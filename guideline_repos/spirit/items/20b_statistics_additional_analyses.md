---
id: 20b_statistics_additional_analyses
title: "20b. Statistics: additional analyses"
---
Methods for any additional analyses (eg, subgroup and adjusted analyses)

## Read More

Subgroup analysis
Subgroup analyses explore whether estimated treatment effects vary significantly between subcategories of trial participants. As these data can help tailor healthcare decisions to individual patients, a modest number of prespecified subgroup analyses can be sensible.

However, subgroup analyses are problematic if they are inappropriately conducted or selectively reported. Subgroup analyses described in protocols or grant applications do not match those reported in subsequent publications for more than two thirds of randomised trials, suggesting that subgroup analyses are often selectively reported or not prespecified.6 7 305 Post hoc (data driven) analyses have a high risk of spurious findings and are discouraged.306 Conducting a large number of subgroup comparisons leads to issues of multiplicity, even when all of the comparisons have been pre-specified. Furthermore, when subgroups are based on variables measured after randomisation, the analyses are particularly susceptible to bias.307

Preplanned subgroup analyses should be clearly specified in the protocol with respect to the precise baseline variables to be examined, the definition of the subgroup categories (including cut-off boundaries for continuous or ordinal variables), the statistical method to be used, and the hypothesised direction of the subgroup effect based on plausibility.308 309

Adjusted analysis
Some trials prespecify adjusted analyses to account for imbalances between study groups (eg, chance imbalance across study groups in small trials), improve power, or account for a known prognostic variable. Adjustment is often recommended for any variables used in the allocation process (eg, in stratified randomisation), on the principle that the analysis strategy should match the design.310 Most trial protocols and publications do not adequately address issues of adjustment, particularly the description of variables.6 310

It is important that trial investigators indicate in the protocol if there is an intention to perform or consider adjusted analyses, explicitly specifying any variables for adjustment and how continuous variables will be handled. When both unadjusted and adjusted analyses are intended, the main analysis should be identified (Item 20a). It may not always be clear, in advance, which variables will be important for adjustment. In such situations, the objective criteria to be used to select variables should be prespecified. As with subgroup analyses, adjustment variables based on post-randomisation data rather than baseline data can introduce bias.311 312

## Examples

> We plan to conduct two subgroup analyses, both with strong biological rationale and possible interaction effects. The first will compare hazard ratios of re-operation based upon the degree of soft tissue injury (Gustilo-Anderson Type I/II open fractures vs. Gustilo-Anderson Type IIIA/B open fractures). The second will compare hazard ratios of re-operation between fractures of the upper and lower extremity. We will test if the treatment effects differ with fracture types and extremities by putting their main effect and interaction terms in the Cox regression. For the comparison of pressure, we anticipate that the low/gravity flow will be more effective in the Type IIIA-B open fracture than in the Type I/II open fracture, and be more effective in the upper extremity than the lower extremity. For the comparison of solution, we anticipate that soap will do better in the Type IIIA-B open fracture than in the Type I/II open fracture, and better in the upper extremity than the lower extremity.

> A secondary analysis of the primary endpoint will adjust for those pre-randomization variables which might reasonably be expected to be predictive of favorable outcomes. Generalized linear models will be used to model the proportion of subjects with neurologically intact (MRS ≤ 3 [Modified Rankin Score]) survival to hospital discharge by ITD [impedance threshold device]/sham device group adjusted for site (dummy variables modeling the 11 ROC [Resuscitation Outcomes Consortium] sites), patient sex, patient age (continuous variable), witness status (dummy variables modeling the three categories of unwitnessed arrest, non-EMS [emergency medical services] witnessed arrest, and EMS witnessed arrest), location of arrest (public versus non-public), time or response (continuous variable modeling minutes between call to 911 and arrival of EMS providers on scene), presenting rhythm (dummy variables modeling asystole, PEA [pulseless electrical activity], VT/VF [ventricular tachycardia/fibrillation], or unknown), and treatment assignment in the Analyze Late vs. Analyze Early intervention. The test statistic used to assess any benefit of the ITD relative to the sham device will be computed as the generalized linear model regression coefficient divided by the estimated “robust” standard error based on the Huber- White sandwich estimator[reference] in order to account for within group variability which might depart from the classical assumptions. Statistical inference will be based on one-sided P values and 95% confidence intervals which adjust for the stopping rule used for the primary analysis.