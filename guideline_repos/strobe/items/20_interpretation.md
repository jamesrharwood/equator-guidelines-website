---
id: interpretation
title: "20. Interpretation"
checklist: 
    text: Give a cautious overall interpretation considering objectives, limitations, multiplicity of analyses, results from similar studies, and other relevant evidence.
---

## What to write

Give a cautious overall interpretation considering objectives, limitations, multiplicity of analyses, results from similar studies, and other relevant evidence.

## Explanation

The heart of the discussion section is the interpretation of a study's
results. Over-interpretation is common and human: even when we try hard
to give an objective assessment, reviewers often rightly point out that
we went too far in some respects. When interpreting results, authors
should consider the nature of the study on the discovery to verification
continuum and potential sources of bias, including loss to follow-up and
non-participation (see also items [{{< meta items.bias.title >}}]({{< meta items.bias.web_path >}}), [{{< meta items.statistical-methods-loss-to-follow-up.title >}}]({{< meta items.statistical-methods-loss-to-follow-up.web_path >}}) and [{{< meta items.limitations.title >}}]({{< meta items.limitations.web_path >}})). Due consideration
should be given to confounding (see [{{< meta items.main-results.title >}}]({{< meta items.main-results.web_path >}})), the results of relevant
sensitivity analyses, and to the issue of multiplicity and subgroup
analyses ([{{< meta items.other-analyses.title >}}]({{< meta items.other-analyses.web_path >}})). Authors should also consider residual confounding
due to unmeasured variables or imprecise measurement of confounders. For
example, socioeconomic status (SES) is associated with many health
outcomes and often differs between groups being compared. Variables used
to measure SES (income, education, or occupation) are surrogates for
other undefined and unmeasured exposures, and the true confounder will
by definition be measured with error [@pmed-0040297-b208]. Authors
should address the real range of uncertainty in estimates, which is
larger than the statistical uncertainty reflected in confidence
intervals. The latter do not take into account other uncertainties that
arise from a study's design, implementation, and methods of measurement
[@pmed-0040297-b209].

To guide thinking and conclusions about causality, some may find
criteria proposed by Bradford Hill in 1965 helpful
[@pmed-0040297-b164]. How strong is the association with the
exposure? Did it precede the onset of disease? Is the association
consistently observed in different studies and settings? Is there
supporting evidence from experimental studies, including laboratory and
animal studies? How specific is the exposure's putative effect, and is
there a dose-response relationship? Is the association biologically
plausible? These criteria should not, however, be applied mechanically.
For example, some have argued that relative risks below 2 or 3 should be
ignored [@pmed-0040297-b210; @pmed-0040297-b211]. This is a
reversal of the point by Cornfield et al. about the strength of large
relative risks (see [{{< meta items.statistical-methods-subgroups-interactions.title >}}]({{< meta items.statistical-methods-subgroups-interactions.web_path >}})) [@pmed-0040297-b127]. Although a
causal effect is more likely with a relative risk of 9, it does not
follow that one below 3 is necessarily spurious. For instance, the small
increase in the risk of childhood leukaemia after intrauterine
irradiation is credible because it concerns an adverse effect of a
medical procedure for which no alternative explanations are obvious
[@pmed-0040297-b212]. Moreover, the carcinogenic effects of
radiation are well established. The doubling in the risk of ovarian
cancer associated with eating 2 to 4 eggs per week is not immediately
credible, since dietary habits are associated with a large number of
lifestyle factors as well as SES [@pmed-0040297-b213]. In contrast,
the credibility of much debated epidemiologic findings of a difference
in thrombosis risk between different types of oral contraceptives was
greatly enhanced by the differences in coagulation found in a randomised
cross-over trial [@pmed-0040297-b214]. A discussion of the existing
external evidence, from different types of studies, should always be
included, but may be particularly important for studies reporting small
increases in risk. Further, authors should put their results in context
with similar studies and explain how the new study affects the existing
body of evidence, ideally by referring to a systematic review.

## Examples

> "Any explanation for an association between death from myocardial
infarction and use of second generation oral contraceptives must be
conjectural. There is no published evidence to suggest a direct biologic
mechanism, and there are no other epidemiologic studies with relevant
results. (...) The increase in absolute risk is very small and probably
applies predominantly to smokers. Due to the lack of corroborative
evidence, and because the analysis is based on relatively small numbers,
more evidence on the subject is needed. We would not recommend any
change in prescribing practice on the strength of these results"
[@pmed-0040297-b120].