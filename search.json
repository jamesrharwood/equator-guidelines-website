[
  {
    "objectID": "guidelines/moose/index.html#about-this-guideline",
    "href": "guidelines/moose/index.html#about-this-guideline",
    "title": "The MOOSE guideline for writing a meta-analysis of observational studies.",
    "section": "About this guideline",
    "text": "About this guideline\n\nThis guideline is relevant to studies reporting meta-analyses of observational studies"
  },
  {
    "objectID": "guidelines/moose/index.html#download-resources",
    "href": "guidelines/moose/index.html#download-resources",
    "title": "The MOOSE guideline for writing a meta-analysis of observational studies.",
    "section": "Download Resources",
    "text": "Download Resources\nReporting guidelines are best used early:\n\nUse a template to write quickly and avoid the blank page\nUse a checklist to double-check and reassure others that your work is described transparently\n\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list"
  },
  {
    "objectID": "guidelines/moose/index.html#guidance",
    "href": "guidelines/moose/index.html#guidance",
    "title": "The MOOSE guideline for writing a meta-analysis of observational studies.",
    "section": "Guidance",
    "text": "Guidance\nApprox. 1 min read\n\nTitle\n\n\n1. Title\n\n\n\n\n\n\n\nIdentify the study as a meta-analysis of observational research\n\n\nAbstract\n\n\n2. Abstract\n\n\n\n\n\n\n\nProvide a structured summary including, as applicable: background; objectives; data sources; study eligibility criteria, participants, and interventions; study appraisal and synthesis methods; results; limitations; conclusions and implications of key findings; systematic review registration number (From PRISMA checklist)\n\n\nBackground\n\n\n3a. Background\n\n\n\n\n\n\n\nProblem definition\n\n\n3b. Background\n\n\n\n\n\n\n\nHypothesis statement\n\n\n3c. Background\n\n\n\n\n\n\n\nDescription of study outcomes\n\n\n3d. Background\n\n\n\n\n\n\n\nType of exposure or intervention used\n\n\n3e. Background\n\n\n\n\n\n\n\nType of study designs used\n\n\n3f. Background\n\n\n\n\n\n\n\nStudy population\n\n\nMethods\n\n\n4a. Search strategy\n\n\n\n\n\n\n\nQualifications of searchers (eg, librarians and investigators)\n\n\n4b. Search strategy\n\n\n\n\n\n\n\nSearch strategy, including time period included in the synthesis and keywords\n\n\n4c. Search strategy\n\n\n\n\n\n\n\nEffort to include all available studies, including contact with authors\n\n\n4d. Search strategy\n\n\n\n\n\n\n\nDatabases and registries searched\n\n\n4e. Search strategy\n\n\n\n\n\n\n\nSearch software used, name and version, including special features used (eg, explosion)\n\n\n4f. Search strategy\n\n\n\n\n\n\n\nUse of hand searching (eg, reference lists of obtained articles)\n\n\n4g. Search strategy\n\n\n\n\n\n\n\nList of citations located and those excluded, including justification\n\n\n4h. Search strategy\n\n\n\n\n\n\n\nMethod of addressing articles published in languages other than English\n\n\n4i. Search strategy\n\n\n\n\n\n\n\nMethod of handling abstracts and unpublished studies\n\n\n4j. Search strategy\n\n\n\n\n\n\n\nDescription of any contact with authors\n\n\n5a. Methods\n\n\n\n\n\n\n\nDescription of relevance or appropriateness of studies gathered for assessing the hypothesis to be tested\n\n\n5b. Methods\n\n\n\n\n\n\n\nRationale for the selection and coding of data (eg, sound clinical principles or convenience)\n\n\n5c. Methods\n\n\n\n\n\n\n\nDocumentation of how data were classified and coded (eg, multiple raters, blinding, and interrater reliability)\n\n\n5d. Methods\n\n\n\n\n\n\n\nAssessment of confounding (eg, comparability of cases and controls in studies where appropriate)\n\n\n5e. Methods\n\n\n\n\n\n\n\nAssessment of study quality, including blinding of quality assessors; stratification or regression on possible predictors of study results\n\n\n5f. Methods\n\n\n\n\n\n\n\nAssessment of heterogeneity\n\n\n5g. Methods\n\n\n\n\n\n\n\nDescription of statistical methods (eg, complete description of fixed or random effects models, justification of whether the chosen models account for predictors of study results, dose-response models, or cumulative meta-analysis) in sufficient detail to be replicated\n\n\n5h. Methods\n\n\n\n\n\n\n\nProvision of appropriate tables and graphics\n\n\nResults\n\n\n6a. Results\n\n\n\n\n\n\n\nGraphic summarizing individual study estimates and overall estimate\n\n\n6b. Results\n\n\n\n\n\n\n\nTable giving descriptive information for each study included\n\n\n6c. Results\n\n\n\n\n\n\n\nResults of sensitivity testing (eg, subgroup analysis)\n\n\n6d. Results\n\n\n\n\n\n\n\nIndication of statistical uncertainty of findings\n\n\nDiscussion\n\n\n7a. Discussion\n\n\n\n\n\n\n\nQuantitative assessment of bias (eg. publication bias)\n\n\n7b. Discussion\n\n\n\n\n\n\n\nJustification for exclusion (eg, exclusion of non–English-language citations)\n\n\n7c. Discussion\n\n\n\n\n\n\n\nAssessment of quality of included studies\n\n\nConclusion\n\n\n8a. Conclusion\n\n\n\n\n\n\n\nConsideration of alternative explanations for observed results\n\n\n8b. Conclusion\n\n\n\n\n\n\n\nGeneralization of the conclusions (ie, appropriate for the data presented and within the domain of the literature review)\n\n\n8c. Conclusion\n\n\n\n\n\n\n\nGuidelines for future research\n\n\n8d. Conclusion\n\n\n\n\n\n\n\nDisclosure of funding source"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#translations",
    "href": "guidelines/SRQR-slim/index.html#translations",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Translations",
    "text": "Translations\nThis guidance is also available in French."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#when-to-use-this-guidance",
    "href": "guidelines/SRQR-slim/index.html#when-to-use-this-guidance",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "When to use this guidance",
    "text": "When to use this guidance\n\n\n\n\n\n\nUse this guidance for reporting qualitative research studies.\nThe SRQR items reflect information essential for inclusion in a qualitative research report, but should not be viewed as prescribing a rigid format or standardized content. Consider each item and prioritize elements that are most relevant to your study, findings, context, and readership.\nYou can also use this guideline for:\n\nfor writing protocols (use the items within the Introduction and Method sections).\nreviewing the reporting of an article, but not for appraising its quality."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#download-resources",
    "href": "guidelines/SRQR-slim/index.html#download-resources",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Download Resources",
    "text": "Download Resources\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#guidance",
    "href": "guidelines/SRQR-slim/index.html#guidance",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Guidance",
    "text": "Guidance\nApprox. 2 min read\n\n\n1. Title\n\n\n\n\n\n\n\nConcise description of the nature and topic of the study. Identifying the study as qualitative or indicating the approach (e.g., ethnography, grounded theory) or data collection methods (e.g., interview, focus group) is recommended.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nThe authors should provide a title that clearly conveys the topic of the study. We suggest that the title indicate that the study is qualitative or include a commonly used term that identifies the approach (e.g., ethnographic study, grounded theory) or data collection methods (e.g., interviews, focus groups, observations). This allows readers and reviewers to quickly identify the type of study.\n\n\nExamples\n\nResidents learning from a narrative experience with dying patients: a qualitative study.\n\n\nMedical students’ perceptions of the factors influencing their academic performance: an exploratory interview study with high-achieving and re-sitting medical students.\n\n\nUndergraduate rural medical education program development: focus group consultation with the NRHA Rural Medical Educators Group.\n\nBack to top”\n\n\n\n\n\n\n2. Abstract\n\n\n\n\n\n\n\nSummary of key elements of the study using the abstract format of the intended publication; typically includes background, purpose, methods, results, and conclusions.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExample\n\n\nRead more\nA reader should be able to read the abstract independent of the manuscript and get a sense of the background, purpose, methods, main results and implications that will be described in greater detail in the manuscript. The information presented in the abstract should be consistent with the information presented in the full text.\nThe abstract’s structure typically needs to conform to journal guidelines, but authors should attempt to include the following:\n\nBackground about the problem or phenomenon of interest\nDescription of the study purpose or research question;\nMethods, including the approach or perspective (e.g., general inductive, grounded theory), context (setting, time period), sample (number and key characteristics of participants, events, documents), data collection strategies (e g., observation, interview, focus group) and data analysis techniques\nDescription of main findings (e.g., themes or inferences) related to the study purpose and/or research question\nStudy implications\n\nIn some cases the journal’s structured abstract format aligns more with positivist paradigms and quantitative approaches than with qualitative traditions, so translation may be necessary. For example, what might be labelled “findings” in many qualitative research traditions could be reported as “results” in the abstract.\n\n\nExample\nPurpose: Although academic centers rely on assessments from medical trainees regarding the effectiveness of their faculty as teachers, little is known about how trainees conceptualize and approach their role as assessors of their clinical supervisors\nMethod: In 2010, using a constructivist grounded theory approach, five focus group interviews were conducted with 19 residents from an internal medicine residency program. A constant comparative analysis of emergent themes was conducted.\nResults: Residents viewed clinical teaching assessment (CTA) as a time-consuming task with little reward. They reported struggling throughout the academic year to meet their CTA obligations and described several shortcut strategies they used to reduce their burden. Rather than conceptualizing their assessments as a conduit for both formative and summative feedback, residents perceived CTA as useful for the surveillance of clinical supervisors at the extremes of the spectrum of teaching effectiveness. They put the most effort, including the crafting of written comments, into the CTAs of these outliers. Trainees desired greater transparency in the CTA process and were sceptical regarding the anonymity and perceived validity of their faculty appraisals.\nConclusions: Individual and system-based factors conspire to influence postgraduate medical trainees’ motivation for generating high-quality appraisals of clinical teaching. Academic centers need to address these factors if they want to maximize the usefulness of these assessments.\nBack to top”\n\n\n\n\n\nIntroduction\n\n\n3. Problem Formulation\n\n\n\n\n\n\n\nDescription and significance of the problem/phenomenon studied; review of relevant theory and empirical work; problem statement.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExample\n\n\nRead more\nThe problem formulation typically appears in the introduction and describes the theoretical and/or practical issues or concerns that make the study necessary. It should provide an overview of what is known about the problem, highlight gaps in current knowledge (the problem statement), and define the scope of the research problem or phenomena addressed in the study (what will and will not be included). It should include a review of theoretical and/or empirical work directly relevant to the problem or phenomena studied. The problem formulation should be described in a way that suggests the need for a qualitative approach (e.g., to elucidate poorly defined or previously unexplored constructs, to generate theories or to develop causal explanations connecting processes and outcomes, to understand phenomena as they naturally occur and the role of context, to explore problems involving high complexity, to gain insight into participants’ perspectives when such insight is lacking).\n\n\nExample\n\nRegulatory focus theory may therefore offer insight into the variability in responses to feedback, but how well do these experimental findings translate to real clinical situations in which the reality of responsiveness to feedback seems frustratingly complex? …. In order to better elaborate a theory to account for this variability in learner response to feedback, the present study was undertaken. We aimed, in this study, to determine how readily clinical learning events could be classified as activating a promotion or a prevention focus, and to explore, through a careful analysis of doctors’ descriptions of their feedback experiences, the predictive value of regulatory focus theory in the context of real clinical learning situations.\n\nBack to top”\n\n\n\n\n\n\n4. Purpose or research question\n\n\n\n\n\n\n\nPurpose of the study and specific objectives or questions\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExample\n\n\nRead more\nIn qualitative research, as in all types of research, the authors should include a statement of study intent. This statement can be framed as one or more research questions, purposes, goals, or objectives. Qualitative studies often explore “how” and “why” questions related to a social or human problems or phenomenon, and they are designed to enhance readers’ understanding of a problem or phenomenon. By clearly stating the purpose of the study, authors set readers’ expectations for the methods, findings and discussion sections of the manuscript.\n\n\nExample\n\nThe purposes of this study were to investigate how medical students recognize, respond to and utilise feedback, and to determine whether there are maturational differences in understandings of the role of feedback across academic years in medical school.\n\nBack to top”\n\n\n\n\n\n\nMethods\n\n\n5. Qualitative approach and research paradigm\n\n\n\n\n\n\n\nQualitative approach (e.g., ethnography, grounded theory, case study, phenomenology, narrative research) and guiding theory if appropriate; identifying the research paradigm (e.g., post-positivist, constructivist/interpretivist) is also recommended.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nThe research paradigm is the set of beliefs and assumptions that guide the research process. These commonly include positivist, post-positivist, constructivist or interpretivist, and critical theory. Qualitative research generally draws from a post-positivist or constructivist/interpretivist paradigm. We recommend identifying the research paradigm so that readers understand whether the researcher assumes that there is a single, objective reality (positivist or post-positivist) and has thus designed the study to describe this reality or whether the researcher assumes multiple, subjective realities and designed the study to describe these multiple realities, with no attempt to merge or reconcile these realities (constructivist/interpretivist). The paradigm has implications for the study design, approach, methods, and techniques to ensure rigor and trustworthiness.\nQualitative research includes an array of approaches and methodologies, both general (e.g., qualitative content analysis, general inductive approach) and specific (e.g., ethnography, grounded theory, phenomenography). Since the research paradigm does not necessarily dictate particular approaches or methods, the approach should also be clearly defined. Stating the approach provides readers the opportunity to evaluate the fidelity of the research approach to the research question(s) and consider the rationale for modifications and deviations from the selected approach. Qualitative research also includes an array of methods that can be used across paradigms and approaches. (See also Item 10) The researcher should explain why the selected approach is appropriate for the research question, and provide references to theories or traditions that guide the use of the approach as needed.\n\n\nExamples\n\nThe study was performed from a constructivist point of view using an interpretative phenomenological epistemology. Based on the notion that social phenomena are constructed by the communal making of meaning about the underlying phenomena, we aimed to construct insightful accounts of lead consultants’ approaches to educational change, rather than to identify the ‘true’ nature of these approaches. Because the management of change by lead consultants is an under-researched area, we conducted an exploratory qualitative study…\n\n\nGiven the relative dearth of explanatory theories about factors affecting medical students’ emotional reactions, we chose to develop one by applying methods associated with grounded theory, specifically constant comparative analysis, to qualitative data obtained from learning logs and interviews. Our approach was constructivist, deliberately using researchers’ own experiences and acquired knowledge to enhance theoretical sensitivity and enrich theory development.\n\nBack to top”\n\n\n\n\n\n\n6. Researcher characteristics and reflexivity\n\n\n\n\n\n\n\nResearchers’ characteristics that may influence the research, including personal attributes, qualifications/experience, relationship with participants, assumptions, and/or presuppositions; potential or actual interaction between researchers’ characteristics and the research questions, approach, methods, results and/or transferability.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nReflexivity refers to intentional, systematic consideration of the potential or actual effects of the researcher(s) on all aspects of the study process. In positivist and post-positivist paradigms, personal characteristics and perspectives of researchers might be viewed as biases that limit the credibility of study findings, while in constructivist or interpretivist paradigms the characteristics and perspectives of the researchers are important contextual factors that are an accepted part of the study design, data collection, and data analysis. These characteristics and perspectives may explain how the researcher(s) obtained access to the site or participants included in the study or may add valuable insight during data analysis.\nTo demonstrate reflexivity, authors should describe important personal characteristics and perspectives of members of the research team that may influence design, data collection, and data analysis. Relevant personal characteristics might include cultural background, occupation, experience, training, position/ power dynamics, gender, race/ethnicity, and sponsoring institution. Authors should also describe the perspectives, assumptions, prior knowledge, preliminary hypotheses, and/or motives (the “stance”) of the members of the research team.\nAuthors also should describe the researchers’ relationships to participants in the study and what decisions were made in light of these relationships. For example, were any members of the research team part of the sample of potential participants in the study? Do any members of the team teach, supervise, or have any authority over participants in the study? If so, how do these characteristics influence choices about their roles in data collection and analysis? For observational research (e.g., ethnography), it is also important to identify the role of the researcher along a spectrum from passive observer (no involvement in the activity studied) to participant-observer (ranging from some limited involvement in the activity to full involvement).\nThere is no expectation that the study could be precisely replicated; these characteristics and perspectives of the researcher should not be mentioned in the limitation section. (See also Item 14.)\n\n\nExamples\n\nReflexivity was maintained by the research team through the analysis and writing by recording, discussing and challenging established assumptions. In addition both EH and SV kept reflexive diaries.\n\n\nThe first author conducted all interviews and discussion groups. Her own medical undergraduate training took place between 1995 and 2000. She was not known to the participants of this research prior to undertaking the study and deliberately did not undertake any clinical or teaching activities locally alongside this research. Whilst it was useful to ‘know’ (from her own background) what the students were talking about medically (and in terms of detecting items of significance), as a researcher she made conscious efforts not to accept potentially common assumptions at face value.\n\nBack to top”\n\n\n\n\n\n\n7. Context\n\n\n\n\n\n\n\nSetting/site and salient contextual factors; rationale.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExample\n\n\nRead more\nThe authors should describe the setting/site(s) in which the study was conducted, the reason(s) why the setting/site(s) was selected, and the salient cultural, political, historical, economic and/or other external factors that influence the study. This information helps readers interpret the meaning and significance of the study findings by situating them in social, cultural, temporal and other relevant contexts. Additional context may be reported with findings (i.e., the Results section) to add evidence for interpretations and to enhance discussion of transferability.\n\n\nExample\n\nWe conducted the study among hospital-based clinical teachers of students in years 4 to 6 of a six-year undergraduate medical program at Maastricht University Medical School. Years 4 to 6 are devoted to clerkships in the academic hospital and affiliated regional hospitals. Rotations differ in duration depending on the type of rotation and the discipline, and the sequence of rotations differs among students. During rotations, students spend time in the wards, the outpatient clinics, and the accident and emergency department. Clerkships in years 4 and 5 last between 4 and 10 weeks (“regular clerkship”), whereas students in year 6 undertake an 18-week “senior clerkship” in a discipline of their choice.\n\nBack to top”\n\n\n\n\n\n\n8. Sampling strategy\n\n\n\n\n\n\n\nHow and why research participants, documents, or events were selected; criteria for deciding when no further sampling was necessary (e.g., sampling saturation); rationale.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nThe authors should describe how and why research participants, documents, and/or events were selected for inclusion in (and, if appropriate, exclusion from) the study, along with a justification for this strategy. We recommend that authors describe the sampling strategy rather than simply labeling the strategy (e.g., “purposive” or “snowball”), since such labels do not have a universally accepted definition and, more importantly, since procedures tend to be study- specific. Several sampling strategies are commonly used in qualitative research, although most fall under the umbrella of purposeful (or purposive) sampling. Purposeful sampling means that participants, documents, or events are selected for their relevance to the research question, based on guiding theory or experiences and assumptions of the researchers. Over the course of the research process, researchers may determine that additional or different participants, documents, or events should be included to address the research question. Other sampling techniques, such as theoretical sampling (seeking examples of theoretical constructs), snowball sampling (using study participants to identify additional participants who meet study criteria), and convenience sampling (including any volunteers with no or minimal criteria for inclusion) may be appropriate depending on the question and approach, so long as the authors provide explanation and justification.\nAlthough investigators often do not determine sample size a priori in qualitative research, they should nonetheless describe how they established the final sample size. When appropriate (e.g., when a flexible sampling strategy was used), they should explain the criteria used to decide when no further sampling was necessary. If data collection ends at the point when the researchers determine that “saturation” has been reached, then the specific criteria used to define saturation should be described.\nProcedures used to recruit participants should also be described, including who was involved in recruitment, what their relationship was to participants, how and when recruitment occurred, and why these procedures were selected. (See also Item 6)\n\n\nExamples\n\nAs students’ perceptions were previously shown to be related to gender, age, prior experience and place of attachment,[REF] we purposely selected respondents with different backgrounds. This sampling strategy led to the diversity of gender, age, prior patient experience and place of attachment shown in Table 1.\n\n\nPurposive sampling was directed towards achieving maximum variation in age and specialty, using a snowball approach (‘a non-probabilistic form of sampling in which persons initially chosen for the sample are used as informants to locate other persons having necessary characteristics making them eligible for the sample’).[REF ]\n\n\nPotential participants were all medical students in Years 1 and 2 at the University of Toronto in 2004. Following research ethics board approval, recruitment was conducted via e- mail to class listservs. Participant responses were sent directly to the research assistant, who was unknown to participants, so that the principal investigators did not know who did or did not participate. This process was engaged to protect participants’ anonymity and to avoid any impression of coercion because the lead researcher (SG) was involved in the administration of the undergraduate curriculum at the time. Sample size was estimated to be sufficient based on the principle of theoretical saturation [REF] and our previous experience with this methodology (i.e., with a relatively homogeneous population, we expected to reach saturation with approximately 15 interviews per group). There were no exclusion criteria and we accepted the first 15 students from each class who volunteered.\n\nBack to top”\n\n\n\n\n\n\n9. Ethical issues pertaining to human subjects\n\n\n\n\n\n\n\nDocumentation of approval by an appropriate ethics review board and participant consent, or explanation for lack thereof; other confidentiality and data security issues.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nQualitative research often involves interaction between researchers and research participants. Correspondingly, researchers should ensure that participants are fully aware of their participation in a research study, the risks and benefits associated with the study, the steps and precautions the researchers will take to minimize risks, such as loss of privacy and confidentiality, and how the researchers plan to use the data. Authors should report approval for the study from an appropriate institutional review board for research associated with human subjects. They should describe procedures used to protect participants, including data collection (e.g., recruitment and informed consent) analysis (e.g., data security and integrity) and reporting of findings (e.g., anonymization of excerpts). If researchers provided compensation or offered incentives to facilitate participation, this should be reported.\n\n\nExamples\n\nEthical approval was granted by the University of Otago and student participants were invited to attend each focus group discussion by the university representatives of New Zealand Medical Students Association (NZMSA). Usually, a key concern when collecting data from students is that students may feel vulnerable when sharing their experiences with academic staff during a focus group discussion. However, this potential harm was removed as each group discussion was facilitated by a fellow student, the discussions were transcribed by a professional transcribing service, and only the primary researchers [Names] had access to the raw data.\n\nBack to top”\n\n\n\n\n\n\n10. Data collection methods\n\n\n\n\n\n\n\nTypes of data collected; details of data collection procedures including (as appropriate) start and stop dates of data collection and analysis, iterative process, triangulation of sources/methods, and modification of procedures in response to evolving study findings.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nQualitative research encompasses an array of data collection methods appropriate for various paradigms and approaches, including (but not limited to) interviews, focus groups, observations (direct or indirect via video), and review of written text, photographs, and other documents or materials. Researchers may choose to use information from multiple sources, contexts, and/or time points depending on their approach and research question(s). (See Item 11 for triangulation.) Given this diversity of methods, authors should describe in detail their data collection design and method(s) and justify them in relation to the research question(s), paradigm, approach, and other methods. Methods used to decide when to end data collection should also be described (see Item 8).\nQualitative research often occurs as an iterative process, meaning that researchers begin data analysis before they complete data collection. The data collection and analysis process may occur in phases or stages, and thus authors must clearly describe the iterative process of data collection and analysis. As part of an iterative collection-analysis process, researchers will often alter their data collection methods to explore their preliminary impressions in greater depth and/or actively pursue confirming and disconfirming perspectives. If such changes occur during the research process, authors should describe how and why study procedures changed in response to evolving study findings.\nThe study period (start and end dates for data collection and analysis) should be identified so that readers can place the study in temporal context and identify factors not mentioned by the authors that might affect findings, interpretation, and implications. (See Item 8 for ending data collection.)\nAuthors should describe important characteristics of the individuals conducting interviews, observations or focus groups, and methods used to train these individuals. This information clarifies the relationship between the individuals involved in data collection and the participants in the research and also explains what efforts were made to ensure consistency in the data collection process (See Items 6 and 15.)\n\n\nExamples\n\nFurther, it was decided that group interviews, also known as focus group discussions would be the best means of data collection. This is a method of data collection that enables group members to feed off each other’s ideas and an effective moderator will maintain group focus whilst at the same time permitting flexibility in the direction those aspects of the discussion might take. [REF]\n\n\nAdjustments to the interview protocol were made according to early experience and information participants had provided (i.e. redundant questions were eliminated; questions were reworded to improve flow and clarity; additional probes were included).\n\n\nFaculty staff were then interviewed individually by a trained study investigator in a 15-minute, semi-structured interview. This sequence was repeated with other video encounters. Table 2 presents examples of interview questions. Each faculty member was interviewed by at least three interviewers over their various interviews. Interviewers were chosen based on their experience in interviewing. All were trained during a half-day meeting to interpret and deliver the interview guide in the same manner in order to elicit information of a consistent type.\n\nBack to top”\n\n\n\n\n\n\n11. Data collection instruments and technologies\n\n\n\n\n\n\n\nDescription of instruments (e.g., interview guides, questionnaires) and devices (e.g., audio recorders) used for data collection; if/how the instrument(s) changed over the course of the study.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nData collection for qualitative research draws upon a variety of instruments or tools, including (but not limited to) interview or focus group guides, observational protocols and prompts for field notes, and data extraction or coding protocols for selection and analysis of documents, photographs, videos, or other artifacts. The authors should describe all such instruments, guides, and protocols, including their development and cite relevant literatures, theories or conceptual frameworks as appropriate. It is often helpful for authors to provide access to the data collection instrument(s) or a detailed description of them.\nThe authors should also describe the use of equipment for audio or video recording, reproduction of paper documents or computer files, or other processes in data collection. This is relevant so readers understand the full context in which data collection occurred and how this context might have affected data collection (e.g., the influence of recording devices on participants’ behaviors; the nature of inferences drawn from live vs. recorded events).\n\n\nExamples\n\nTo facilitate the discussion and to maintain consistency over different sets of discussions, key trigger questions were devised prior to the discussion. The opening trigger question was: ‘Thinking back to some of your best clinical learning placements in 4th and 5th year. What was it about those clinical placements that provided good opportunities for learning?’\n\n\nInterviews included discussion of the expectations, processes and consequences of AEE [authentic early experiences]. The interview schedule was derived following identification of questions that could not be fully answered in a systematic review of previous empirical or theoretical literature. It comprised a sequence of topic areas including experiences in action, and areas of frustration in Medical Education such as the learning of content knowledge, achieving functional knowledge, and transfer of knowledge.[REF]… Interested readers can request a copy of the schedules from the corresponding author. Interviews lasted between 20 and 90 min. and discussion groups between 60 and 90 min. All interviews and discussion groups were conducted in private rooms at the participant’s workplace—the medical school for students and faculty, and individual places of work for workplace supervisors (except for one who chose to be interviewed at the medical school). All data were audio-recorded, and transcribed verbatim.\n\nBack to top”\n\n\n\n\n\n\n12. Units of study\n\n\n\n\n\n\n\nNumber and relevant characteristics of participants, documents, or events included in the study; level of participation.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExample\n\n\nRead more\nAuthors should describe the participants, documents, or events included in the study (the units of study). The sampling item (Item 8) describes the target or ideal participants, documents, or events selected for the study. By contrast, Item 12 focuses on description of the actual participants, documents or events included in the study. Authors should describe how the actual participants, documents, or events differ from the targeted sample, why these differences may have occurred, and how this might affect the findings.\nAuthors should describe characteristics of the participants, documents or events that are relevant to the study purpose and research question(s).1 For participants, this might include age, gender, profession, institution, year of training, or relationship to the researcher and/or other participants in the study. For documents, this might include the source, intended audience, date, or type of document. For events, this might include the location, date(s), length, characteristics of attendees or participants in the event, or mood or emotional climate. If the degree of participation varied among individuals (e.g., multiple occasions; interviews and observations), the authors should describe different levels of participation. For example, if some participants were observed and interviewed and others only interviewed, or if some participants completed multiple interviews and others completed a single interview, these variations should be explained. Authors should also explain the reasons for these differences (i.e., the researchers’ choice or the participants’ preferences) and how these different levels of participation were taken into account in the analysis. Authors should also include the dates or timeframe for participation.\nThis information about participants could appear in the Methods section as part of the description of the sample, or at the beginning of the Results section to provide context for the findings presented.\n\n\nExample\n\nOf the 70 Mindful Communication program participants, 46 met the eligibility requirements to participate in the in-depth interviews. We randomly chose and then contacted 22 participants, of whom 20 agreed to be interviewed within six months of completing the program: 15 in person and 5 by telephone. Two declined for lack of time. On reaching saturation after 20 interviews, no further attempts to contact the remaining 24 participants were made.\n\n\n\n\n\nThere were 31 nursing handovers covering 137 patients, and 21 resident handovers covering 101 patients included in this study.\n\nBack to top”\n\n\n\n\n\n\n13. Data processing\n\n\n\n\n\n\n\nMethods for processing data prior to and during analysis, including transcription, data entry, data management and security, verification of data integrity, data coding and anonymization / de-identification of excerpts.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nAuthors should describe the ways in which data are prepared for analysis and managed throughout the analysis process. These activities might include transcription, coding, data entry, and organization of data. When processing audio or video recordings, relevant details might include indication of verbatim transcription of dialogue, additional notes to capture non- verbal information (especially for group interviews or focus groups), and annotations to indicate vocal inflections and utterances, as appropriate for the analytic approach. Authors should also describe procedures used to check transcripts for accuracy.\nAuthors should describe the processes used to organize, compile, and categorize data (e.g., field notes, transcripts, documents, photographs, artifacts) for analysis.\nAuthors should describe procedures used to maintain data security and protect the privacy of participants, as specified in the human subjects protocols. For example, if data are anonymized, the authors should explain how and at what point in the process this occurred. Authors may choose to use anonymous labels or identifiers to represent quotes or excerpts from unique participants, documents or events, in order to reflect the variety of sources from which such data were derived.\n\n\nExamples\n\nInterviews were anonymised and each participant was given a code number.\n\n\nThe interviewers and another member of the research team (H.B.) reviewed transcripts for accuracy.\n\n\nWe collected data throughout the admission process through direct observation, audio- recording, and chart extraction. We audio-recorded, transcribed, and anonymized both the overnight and morning case review discussions. We also observed the morning case review discussions in person and collected field notes. For each case review discussion, we copied the admission notes from the patient’s record and de-identified all data.\n\nBack to top”\n\n\n\n\n\n\n14. Data analysis\n\n\n\n\n\n\n\nProcess by which inferences, themes, etc. were identified and developed, including the researchers involved in data analysis; usually references a specific paradigm or approach.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nTechniques used for data analysis will depend on the paradigm, approach, and/or data collection methods selected by the researchers. Correspondingly, authors should be as transparent as possible about the analytic process so that readers can follow the logic of inquiry from the research question(s) to the analysis and findings. For example, this description may involve characterizing the processes and decisions made for initial classification or segmentation of data, pattern identification and description, and/or development of in-depth interpretations.1 If the researchers used an approach that has a well-defined process for data analysis (e.g., grounded theory, discourse analysis, phenomenography), the authors should cite the guiding literature and describe their processes in sufficient detail so readers can judge the extent to which the processes align with the guiding approach. If modification to or deviations from the guiding approach occurred, the authors should explain and justify these modifications.\nAuthors should specify the unit of analysis.1 In qualitative research, the unit of analysis is not necessarily the same as the unit of sampling (e.g., individual participants or events). Instead, some approaches use specific events as the unit of analysis, such as mentions of a particular topic or experience, or observations of a particular behavior or phenomenon, while others use groups rather than individual group participants. This specification has implications for how the data are organized and analyzed as well as the inferences drawn from the data.\nAuthors should explain the rationale underlying different decisions made throughout the data analysis process to provide as much transparency as possible. In some approaches researchers use memoing or bracketing to make their reflections, interpretations, and links among passages explicit and more transparent to others. In some types of analysis, participants’ perspectives or observations that contrast or deviate from the concepts or themes identified by the researchers are an important part of the analysis. In such cases, the authors must describe how these discrepancies were handled during the analysis.\nDuring the analysis process, researchers may draw upon a theoretical perspective or framework, which may have been identified early in the conception of the study or may be identified by the researchers after reviewing some or all of their data. Either way, the authors should describe theoretical or other influences on their analysis scheme or categories if they exist. Sometimes these are referred to as “sensitizing concepts” to acknowledge that the approach is inductive, but with influence from relevant theory, models, or organizational schemes. Alternatively, themes may be developed from the data with no external influences.\nAuthors should describe which members of the research team are involved in data analysis and what perspective(s) they bring to the analysis. Authors should also indicate if any software was used to assist with data analysis and how it was used (e.g., used to apply codes after the final coding scheme was developed; to extract coded passages for further synthesis and identification of themes; or to identify passages with key words). Simply stating that software was used is insufficient.\n\n\nExamples\n\n…we brought sensitizing concepts to the analysis while we conducted an open, inductive analysis.[REF]In this case the sensitizing concepts arose, a priori to analysis, from a framework derived from the literature [REF] (as described above), in which participants’ motivations to act are based on principles of professionalism, internal affect, or potential implications of their actions.[REF]\n\n\nThrough an iterative process of listening, discussing, and relistening, the team identified and consensually validated emerging themes[REF] and appended segments of dialogue supporting the proposed themes. Recruitment stopped when saturation was reached (no new themes were identified). The team systematically reviewed the themes and sorted them into content domains. The team used an analytic matrix to identify patterns and connections amongst the domains. Two of us not involved in the qualitative coding process (R.E., M.K.) audited the analytic matrix, choice of quotes, and thematic analysis.\n\n\nThe analysis started after the first interview. All data were analyzed with the aid of the audio- coding facility of the NVivo 8: QSR International Pty Ltd, Doncaster, Vic, Australia programme. First, [name] and [name] coded independently from one another, making sure to stay semantically close to the participants’ wording. Then we discussed these open codes and defined axial codes.[REF] New insights about the impact of CST were written down in memos.\n\n\nVideotapes were analysed using immersion/crystallisation methods of qualitative data analysis.[REF] With no pre-existing framework developed in advance for analysis, an inductive approach was used to discover patterns of NVB in the data. A team of six researchers met weekly for 18 months to view videos together. Using a consensus-building approach based on a combination of field notes, ‘opportunistic’ interviews with the participants, and repeated viewing of the same material, sometimes many months apart, we eventually achieved consensus on verbal, non-verbal, and physical themes and patterns observed in the data. Finally, as a test of ‘goodness-of-fit,’ we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\n\nAll transcripts were coded thematically by four of the five authors, who met regularly to identify areas of convergence until full agreement was reached. One of the interviewers (P.M.) maintained an audit trail to track the team’s developing thinking. A process of dialectical empiricism[REF] was used to categorise the emergent themes into more abstract concepts…\n\nBack to top”\n\n\n\n\n\n\n15. Techniques to enhance trustworthiness\n\n\n\n\n\n\n\nTechniques to enhance trustworthiness and credibility of data analysis,(e.g., member checking, triangulation, audit trail); rationale.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nAuthors should describe methods used to ensure trustworthiness and credibility throughout the data collection and analysis process. Such methods will depend on the paradigm, approach, and/or methods used. Correspondingly, the authors should explain their choice of techniques and why these are appropriate for the particular study.\nCommonly used techniques to enhance trustworthiness include: member checking; triangulation of data sources, methods, and/or researchers; creation of an explicit audit trail; and immersion in the site of data collection for an extended period of time (especially for research in which an observer’s presence is likely to disrupt the phenomenon under investigation). Member checking involves sharing findings, such as descriptions of key phenomena, themes, or an explanatory model, with participants and asking them to verify the accuracy or resonance with their perspectives. Triangulation involves using more than one data source, method, or researcher to add diverse perspectives on the findings of the study and, in some approaches, to test the transferability or generalizability of a model. An audit trail involves careful documentation of all decisions made throughout the study, from initial conceptualization to study design, sampling, analysis, and reporting, to provide transparency and to enable an external researcher to review all the steps involved in the study.\n\n\nExamples\nMember checking\n\nMember checks [REF] with an external TBL expert (R.L.) supported the validity of these analyses.\n\nTriangulation of data types and data sources\n\nThe interview data were triangulated with the data of 11 student and supervisor focus groups of a previous study, and more specifically, with those data that concern in particular the influence of CST [Communication Skills Training] on the development of patient-centredness…. Triangulation with the focus group data allowed us to broaden the in-depth information from the interviews in the analysis and to ‘share and compare’ this with information from students and doctors with varying levels of CST (no, limited, full programme) and from two universities (Universities of Antwerp and Ghent). Moreover, this enabled us to better explore the evolution over time, given that the focus groups included participants at different stages of their study: before clerkships (year 4, undergraduate), during clerkships (year 6, undergraduate), after clerkships (year 7, undergraduate) and postgraduate (general practice trainees, and supervising specialists and GPs; Table 1).\n\n\n\n\n\nFinally, as a test of ‘goodness-of-fit’, we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\nTriangulation of Researchers + Audit trail\n\nTo ensure rigor and increase authenticity in our methodology, we used two kinds of triangulation—investigator triangulation and data triangulation.[REF] We sought analytical rigor using an audit trail and multiple coders; our coding team included an experienced clinician (M.G.) as well as a nonclinician with expertise in medical communication and team dynamics (L.L.).\n\nBack to top”\n\n\n\n\n\n\nResults\n\n\n16. Synthesis and interpretation\n\n\n\n\n\n\n\nMain findings (e.g., interpretations, inferences, and themes); might include development of a theory or model, or integration with prior research or theory.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nIn qualitative research the distinction between results and discussion tends to blur because analysis often involves interpretation, inference, and synthesis. Although most journals require separate sections for Results and Discussion, many elements of Items 16-19 could reasonably be reported in either section. As such, we defer to authors and editors to determine where to report these essential elements.\nAuthors should identify the main analytic findings (e.g., interpretations, inferences, narratives, themes, models). The nature of these findings and how they are reported will depend on the approach and methodology selected and thus should be in alignment with the approach and methods.\nIn most cases, the authors should report a synthesis of their data along with specific quotes, examples, or illustrations derived from their data. Authors might also report frequency, variety, representativeness, counter-examples, concrete details, contextualization, conditions, and qualifications related to their findings. Frequency counts (e.g., the frequency of specific themes or codes) play a limited role in qualitative research, and need not be reported unless they play a meaningful role in interpretation of the data.\nFindings might also include integration with prior literature or theory and/or the development of a theory, model or meta-narrative. Judicious use of tables and figures can help communicate such findings.\n\n\nExamples\n\nWe identified four patterns of NVB (non-verbal behavior) that relate to handover quality and have dubbed them: (1) joint focus of attention; (2) ‘the poker hand’; (3) parallel play; and (4) kerbside consultation. Each pattern constitutes a ‘transfix,’ or systematic way of participating non-verbally in the care transfer process. And, although there are variations in each pattern, we have been able to code virtually every handover we have observed in nursing, medicine and surgery into one of these four categories.\n\n\nBecause our participants came from similar educational backgrounds, had studied medicine as their tertiary course, were embedded in the culture of medicine, and were associated in meaningful ways with a single medical school, we approached their transcripts with the assumption that they belonged to a loosely formed discourse community. Although their graduation dates ranged over a period of 50 years and their collective sphere of practice included 10 different specialty areas, there were many similarities in their experiences of enculturation during and after medical school.\n\n\nTheir three major (often overlapping) areas of concern were epistemic (acquiring knowledge and skill), interpersonal (relating to patients, families, colleagues and administrators) and personal (achieving work–life balance). In each of these areas, medical enculturation was achieved by two overlapping processes, ‘absorption’ and ‘assimilation’, each of which may have distinct implications for postgraduate medical education.\n\nBack to top”\n\n\n\n\n\n\n17. Links to empirical data\n\n\n\n\n\n\n\nEvidence (e.g., quotes, field notes, text excerpts, photographs) to substantiate analytic findings.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nThe authors should provide evidence (e.g., quotes, field notes, text excerpts, photographs) to substantiate the more general and abstract concepts or inferences they present as findings. Such evidence is typically de-identified to protect the privacy of study participants, settings, and/or institutions. The evidence may be presented in a variety of ways such as in a table or figure, incorporated into a narrative description of findings, as a stand-alone narrative, or in text blocks embedded in the manuscript text. If word limits or media limitations (e.g.. video) limit the authors’ ability to provide sufficient representation of supporting data, an appendix, supplemental material, or web-based repository could be used to provide access to additional data.\n\n\nExamples\nSee Frankel et al. for an excellent example of how to use photographs (or snapshots from video) to illustrate and provide supporting evidence for patterns of behavior identified in the analysis. http://qualitysafety.bmj.com/content/21/Suppl_1/i121.\n\nWe identified five interruption types: (1) probing for further data, (2) prompting for expected sequence, (3) teaching around the case, (4) thinking out loud, and (5) providing direction (see Table 1). Several interruption types served both goals of the case review discussions—teaching and patient care. For example, when thinking out loud, supervisors reasoned through problems and taught the team: “So that’s the big question, did she have a mechanical fall, or did she have a medicine-related fall?” (Case 2). Supervisors prompted for expected sequence, preventing presenters from skipping over information while simultaneously allowing the supervisor to instruct the team on presentation style: “So now you can tell me what the rest of his test results are because I haven’t heard those” (Case 16).\n\nBack to top”\n\n\n\n\n\n\nDiscussion\n\n\n18. Integration with prior work, implications, transferability, and contribution(s) to the field\n\n\n\n\n\n\n\nShort summary of main findings, explanation of how findings and conclusions connect to, support, elaborate on, or challenge conclusions of earlier scholarship; discussion of scope of application/generalizability; identification of unique contribution(s) to scholarship in a discipline or field.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExamples\n\n\nRead more\nThe authors should begin the Discussion with a short summary of the main findings. The short summary reminds readers of the main findings and may help them assess whether the subsequent interpretation and implications formulated by the authors are supported by the findings.\nThe authors’ description of their findings or results should include some interpretation of the data in the context of previous findings, experiences, theory, or a guiding paradigm or approach. The discussion provides authors an opportunity to elaborate on their findings in relation to their research question(s) and study purpose(s); connect their findings to prior empirical work, theories, and/or frameworks; and discuss implications. The authors should explicitly describe how their findings contribute to or advance the field. Implications may include transferability, or specifying the appropriate scope for generalization of the findings beyond the study (e.g., to other settings, populations, time periods, circumstances).\n\n\nExamples\n\nThis study contributes to the understanding and discussion of the complexity of involving patients in healthcare education. It shows that integrating patient-led teaching into initiatives that are partly faculty-led influences the way in which students perceive learning from and with PIs. What is not known, however, is whether perceptions are also affected by type of health profession and the students’ different orientation towards logics of care and science, and issues of authority and power relations.\n\nFor complete examples of Discussions, see:\n\nHenriksen & Ringsted, 2013\nWesterman et al., 2013.\n\nBack to top”\n\n\n\n\n\n\n19. Limitations\n\n\n\n\n\n\n\nTrustworthiness and limitations of findings\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead more\nExample\n\n\nRead more\nAuthors should describe techniques used to ensure trustworthiness in the Methods section of the manuscript. In the Discussion, authors should identify problems or gaps in their efforts to ensure trustworthiness and the potential implications. For example, if researchers intended to interview individuals with certain characteristics, or who might offer different perspectives, but were unsuccessful in recruiting any willing participants, they should explain this issue and describe possible consequences for transferability. (See also Item 18.)\nAll research paradigms and approaches have strengths and weaknesses, and authors should explicitly discuss how the paradigm, approach, and methods they used will influence the situations to which their findings may reasonably apply. (See also Item 18.) In addition, they should explain how specific decisions or events in the conduct of the study strengthen or weaken the rigor of their findings.\n\n\nExample\n\nThe study has several limitations. One is that the focus group interview method reveals students’ perceptions rather than their actual behaviors. Observations of the patient-led teaching encounter may have illuminated an understanding of the relationship between patient instructors and medical students. Another limitation is that the PI-led teaching is optional rather than mandatory, which may have influenced students’ attitudes in a positive direction. Moreover, students who are eager to take on extra-curricular activities may not be representative of the whole population. That only 23 out of 39 students signed up for this study might also have influenced results if the missing group of students represented other perceptions than those present in the focus groups. However the received data from the focus groups were rich in information and diverse perceptions were present. Another limitation is the overrepresentation of women over men in our sample. Even though women are also overrepresented in medical school this might potentially have influenced results, but gender differences in perceptions were nevertheless not identified in the data.\n\nBack to top”\n\n\n\n\n\n\nOther\n\n\n20. Conflicts of interest\n\n\n\n\n\n\n\nPotential sources of influence or perceived influence on study conduct and conclusions; how these were managed.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead more\nAuthors should identify any real or potential conflicts of interest that might have influenced or could appear to have influenced the research. Authors should also explain how these conflicts were managed in the conduct of the study, and describe the potential impact on study findings and/or conclusions. Some aspects may be mentioned as part of reflexivity (see Item 6).\n\n\n\n\n\n21. Funding\n\n\n\n\n\n\n\nSources of funding and other support; role of funders in data collection, interpretation, and reporting.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead more\nThe authors should describe any sources of funding and other support for the study and the role of funders in data collection, data analysis, and reporting if applicable.\n\n\n\n\n\n\nEthnography\n\n\n\n\n\n\nOccaecat mollit deserunt excepteur consectetur proident. Anim Lorem ipsum anim nisi velit magna duis Lorem consequat aliquip eu ullamco consequat amet. Magna labore in consequat ad aliquip Lorem elit do in. Esse minim consectetur ut commodo sunt cupidatat voluptate sint voluptate nisi.\nExercitation eu mollit consequat ipsum non ullamco. Velit velit dolor cupidatat proident in laboris eiusmod incididunt mollit nisi laborum minim. Eiusmod et voluptate veniam exercitation sit ex labore.\nLearn more\n\n\n\n\n\n\nGrounded theory\n\n\n\n\n\n\nEt eu labore qui non dolore nulla. Ipsum aliqua laboris commodo deserunt cillum excepteur dolore adipisicing occaecat nostrud anim elit officia amet. Commodo incididunt ad et velit do minim dolore. Ullamco eiusmod Lorem proident tempor laborum nulla incididunt non pariatur irure officia ad. Elit deserunt commodo laboris adipisicing duis amet et dolore nulla nostrud. Nostrud excepteur exercitation elit consequat consequat.\n\n\n\n\n\n\nInterview\n\n\n\n\n\n\nNon exercitation commodo incididunt tempor veniam magna excepteur est reprehenderit Lorem. Exercitation enim et quis velit pariatur mollit fugiat dolore ullamco eu eu. Do ullamco eu culpa sint ad est. Proident veniam sint eu cupidatat minim voluptate officia anim laborum qui aliqua. Enim minim non mollit elit ipsum fugiat dolore cupidatat. Magna adipisicing labore do dolor voluptate non ipsum sint eiusmod aute proident proident ullamco. Excepteur cupidatat occaecat enim culpa cillum laboris ex incididunt officia.\n\n\n\n\n\n\nFocus group\n\n\n\n\n\n\nCommodo commodo labore eu laboris commodo excepteur eu et id deserunt enim id minim cupidatat. Fugiat deserunt eiusmod eiusmod culpa velit dolore ex voluptate anim pariatur. Nostrud cillum cillum culpa exercitation. Labore laboris ex commodo nostrud excepteur eiusmod veniam in esse est exercitation Lorem proident dolor. Labore aliqua fugiat id qui sit qui sit aliquip incididunt labore irure Lorem voluptate. Eiusmod ea ex ea cillum exercitation laboris laborum incididunt labore. Ea officia aliqua id velit nostrud velit amet.\n\n\n\n\n\n\nGeneral inductive\n\n\n\n\n\n\nLaboris ea eu elit irure ex reprehenderit sunt commodo non eiusmod tempor. Eiusmod occaecat mollit consequat dolore voluptate officia exercitation voluptate velit nostrud duis ad consectetur. Magna magna in occaecat nostrud tempor tempor incididunt commodo officia reprehenderit irure aliqua.\n\n\n\n\n\n\nContext\n\n\n\n\n\n\nEiusmod sit cillum sint duis mollit non amet consectetur minim in sunt aliquip laboris ipsum. Culpa ullamco laborum et veniam laborum anim ut aliqua dolore. Aliquip dolore sit tempor velit officia. Aute do nostrud reprehenderit pariatur sint qui. Occaecat consequat ut et sint. Officia aliquip non minim do est minim.\n\n\n\n\n\n\nSetting\n\n\n\n\n\n\nExercitation consectetur ipsum sit sit magna nostrud do commodo aute ad. Elit ea ea aliqua eu commodo. Enim est pariatur tempor non exercitation officia aliquip ut veniam laborum. Eu ea aliqua laborum elit voluptate officia ex ipsum amet.\n\n\n\n\n\n\nSample\n\n\n\n\n\n\nEst irure ipsum laborum ad consectetur. Incididunt dolor duis excepteur proident. Ut ullamco amet aliqua sint fugiat exercitation amet anim magna dolor ullamco. Officia dolore dolore ad laborum. Dolore reprehenderit non deserunt dolore voluptate in Lorem nulla laborum ipsum occaecat eiusmod. Incididunt minim magna sint non veniam incididunt sint consectetur amet qui. Voluptate enim deserunt Lorem proident reprehenderit mollit magna adipisicing reprehenderit laboris nisi qui cupidatat id.\n\n\n\n\n\n\nThemes\n\n\n\n\n\n\nEt et aliquip elit aliquip cillum. Mollit enim ullamco ea ullamco eu ex officia ut culpa cillum laborum ad. Nulla id mollit magna deserunt deserunt eu. Qui esse sint fugiat excepteur consectetur velit incididunt aliquip labore consequat aute Lorem laboris. Cupidatat irure ex minim adipisicing commodo Lorem elit. Sit fugiat dolor dolore pariatur exercitation in duis nostrud cillum id magna non tempor. Duis reprehenderit ex cupidatat reprehenderit duis cillum.\n\n\n\n\n\n\nInferences\n\n\n\n\n\n\nOccaecat qui non aute ut quis aliqua ut sint ipsum enim Lorem. Laborum nostrud esse voluptate dolore exercitation. Excepteur pariatur id pariatur ullamco ea esse do. Aute aute minim veniam reprehenderit id enim aliqua dolor ullamco. Sit tempor nostrud tempor minim. Qui irure laborum consectetur duis do quis laboris eiusmod consequat.\n\n\n\n\n\n\nPositivist\n\n\n\n\n\n\nTempor aliquip minim commodo nisi et aliqua ea mollit esse. Tempor aute consequat exercitation excepteur et. Aliquip dolor duis fugiat incididunt sint ipsum adipisicing eiusmod. Aliqua ea ipsum Lorem amet. Excepteur do dolore commodo veniam Lorem eiusmod cillum cupidatat Lorem minim nulla est ipsum. Eu laboris anim laboris mollit aute quis mollit est duis elit sit voluptate nisi. Amet dolor pariatur dolore culpa.\n\n\n\n\n\n\nPost-positivist\n\n\n\n\n\n\nProident est commodo exercitation ex occaecat ullamco anim ut reprehenderit deserunt dolor voluptate in. Consequat culpa reprehenderit consequat enim dolore officia tempor proident duis eiusmod consequat minim incididunt id. Ad proident qui aute ea.\n\n\n\n\n\n\nConstructs\n\n\n\n\n\n\nId sunt enim dolore nostrud laboris quis quis sint anim ullamco et ut proident. Ipsum pariatur sit eu quis irure eiusmod quis adipisicing velit cillum sit reprehenderit enim. Quis magna sint officia irure cillum irure est. Nostrud nostrud enim commodo magna mollit et eu amet mollit occaecat amet.\n\n\n\n\n\n\nCase study\n\n\n\n\n\n\nLaboris quis ad laboris eu amet. Deserunt enim ad do aliqua qui labore. Anim aute esse fugiat labore reprehenderit quis et eiusmod. Dolore consequat sunt consequat veniam qui nisi magna qui non amet eu. Aute nulla anim culpa enim magna amet adipisicing. Ea eu officia minim minim duis ea reprehenderit Lorem ullamco. Minim et aliqua amet id proident est eiusmod.\n\n\n\n\n\n\nPhenomenology\n\n\n\n\n\n\nEnim ea voluptate ad dolore et commodo in id eiusmod ea. Irure culpa pariatur veniam culpa velit Lorem exercitation ea ut nulla minim non esse reprehenderit. Ipsum do cupidatat culpa ipsum in ea consequat. Dolor sint laborum proident labore nulla fugiat esse sit enim irure anim. Id ex proident et tempor enim est nostrud. Ullamco ex do irure amet proident nulla proident non exercitation esse ullamco est dolor. Exercitation proident mollit nostrud dolore reprehenderit nostrud officia in magna eiusmod.\n\n\n\n\n\n\nNarrative research\n\n\n\n\n\n\nNisi pariatur in sunt est anim sit sint cillum occaecat ut enim commodo amet ullamco. Lorem nulla ut in nulla. Nisi aute cillum ad duis aliqua commodo velit incididunt aliquip.\n\n\n\n\n\n\nConstructivist\n\n\n\n\n\n\nNulla fugiat labore voluptate velit ipsum elit velit nulla laborum cillum minim. Esse laboris adipisicing proident non ipsum adipisicing consequat do do proident ea. Irure minim fugiat proident irure adipisicing. Ea ad consectetur fugiat qui id consectetur nostrud amet elit sit non cupidatat laboris nostrud. Est officia velit sit fugiat ut pariatur consequat incididunt in velit nulla do proident. Reprehenderit pariatur adipisicing mollit mollit consectetur. Lorem consectetur nisi est aute reprehenderit elit amet et deserunt sit pariatur sunt dolore excepteur.\n\n\n\n\n\n\nInterpretivist\n\n\n\n\n\n\nMinim ad fugiat ex magna occaecat nostrud officia est dolor duis tempor quis. Voluptate dolore dolore labore irure ipsum esse do labore excepteur est elit. Excepteur irure veniam cillum sit est aliqua occaecat sunt eu dolor dolor. Adipisicing est mollit aute consequat proident adipisicing minim est ad. Duis cupidatat est enim ex labore sit eu pariatur."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-title-1",
    "href": "guidelines/SRQR-slim/index.html#sec-title-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe authors should provide a title that clearly conveys the topic of the study. We suggest that the title indicate that the study is qualitative or include a commonly used term that identifies the approach (e.g., ethnographic study, grounded theory) or data collection methods (e.g., interviews, focus groups, observations). This allows readers and reviewers to quickly identify the type of study."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-title-2",
    "href": "guidelines/SRQR-slim/index.html#sec-title-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nResidents learning from a narrative experience with dying patients: a qualitative study.\n\n\nMedical students’ perceptions of the factors influencing their academic performance: an exploratory interview study with high-achieving and re-sitting medical students.\n\n\nUndergraduate rural medical education program development: focus group consultation with the NRHA Rural Medical Educators Group.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-abstract-1",
    "href": "guidelines/SRQR-slim/index.html#sec-abstract-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nA reader should be able to read the abstract independent of the manuscript and get a sense of the background, purpose, methods, main results and implications that will be described in greater detail in the manuscript. The information presented in the abstract should be consistent with the information presented in the full text.\nThe abstract’s structure typically needs to conform to journal guidelines, but authors should attempt to include the following:\n\nBackground about the problem or phenomenon of interest\nDescription of the study purpose or research question;\nMethods, including the approach or perspective (e.g., general inductive, grounded theory), context (setting, time period), sample (number and key characteristics of participants, events, documents), data collection strategies (e g., observation, interview, focus group) and data analysis techniques\nDescription of main findings (e.g., themes or inferences) related to the study purpose and/or research question\nStudy implications\n\nIn some cases the journal’s structured abstract format aligns more with positivist paradigms and quantitative approaches than with qualitative traditions, so translation may be necessary. For example, what might be labelled “findings” in many qualitative research traditions could be reported as “results” in the abstract."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-abstract-2",
    "href": "guidelines/SRQR-slim/index.html#sec-abstract-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\nPurpose: Although academic centers rely on assessments from medical trainees regarding the effectiveness of their faculty as teachers, little is known about how trainees conceptualize and approach their role as assessors of their clinical supervisors\nMethod: In 2010, using a constructivist grounded theory approach, five focus group interviews were conducted with 19 residents from an internal medicine residency program. A constant comparative analysis of emergent themes was conducted.\nResults: Residents viewed clinical teaching assessment (CTA) as a time-consuming task with little reward. They reported struggling throughout the academic year to meet their CTA obligations and described several shortcut strategies they used to reduce their burden. Rather than conceptualizing their assessments as a conduit for both formative and summative feedback, residents perceived CTA as useful for the surveillance of clinical supervisors at the extremes of the spectrum of teaching effectiveness. They put the most effort, including the crafting of written comments, into the CTAs of these outliers. Trainees desired greater transparency in the CTA process and were sceptical regarding the anonymity and perceived validity of their faculty appraisals.\nConclusions: Individual and system-based factors conspire to influence postgraduate medical trainees’ motivation for generating high-quality appraisals of clinical teaching. Academic centers need to address these factors if they want to maximize the usefulness of these assessments.\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-problem-formulation-1",
    "href": "guidelines/SRQR-slim/index.html#sec-problem-formulation-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe problem formulation typically appears in the introduction and describes the theoretical and/or practical issues or concerns that make the study necessary. It should provide an overview of what is known about the problem, highlight gaps in current knowledge (the problem statement), and define the scope of the research problem or phenomena addressed in the study (what will and will not be included). It should include a review of theoretical and/or empirical work directly relevant to the problem or phenomena studied. The problem formulation should be described in a way that suggests the need for a qualitative approach (e.g., to elucidate poorly defined or previously unexplored constructs, to generate theories or to develop causal explanations connecting processes and outcomes, to understand phenomena as they naturally occur and the role of context, to explore problems involving high complexity, to gain insight into participants’ perspectives when such insight is lacking)."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-problem-formulation-2",
    "href": "guidelines/SRQR-slim/index.html#sec-problem-formulation-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nRegulatory focus theory may therefore offer insight into the variability in responses to feedback, but how well do these experimental findings translate to real clinical situations in which the reality of responsiveness to feedback seems frustratingly complex? …. In order to better elaborate a theory to account for this variability in learner response to feedback, the present study was undertaken. We aimed, in this study, to determine how readily clinical learning events could be classified as activating a promotion or a prevention focus, and to explore, through a careful analysis of doctors’ descriptions of their feedback experiences, the predictive value of regulatory focus theory in the context of real clinical learning situations.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-purpose-1",
    "href": "guidelines/SRQR-slim/index.html#sec-purpose-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nIn qualitative research, as in all types of research, the authors should include a statement of study intent. This statement can be framed as one or more research questions, purposes, goals, or objectives. Qualitative studies often explore “how” and “why” questions related to a social or human problems or phenomenon, and they are designed to enhance readers’ understanding of a problem or phenomenon. By clearly stating the purpose of the study, authors set readers’ expectations for the methods, findings and discussion sections of the manuscript."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-purpose-2",
    "href": "guidelines/SRQR-slim/index.html#sec-purpose-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nThe purposes of this study were to investigate how medical students recognize, respond to and utilise feedback, and to determine whether there are maturational differences in understandings of the role of feedback across academic years in medical school.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-qualitative-approach-1",
    "href": "guidelines/SRQR-slim/index.html#sec-qualitative-approach-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe research paradigm is the set of beliefs and assumptions that guide the research process. These commonly include positivist, post-positivist, constructivist or interpretivist, and critical theory. Qualitative research generally draws from a post-positivist or constructivist/interpretivist paradigm. We recommend identifying the research paradigm so that readers understand whether the researcher assumes that there is a single, objective reality (positivist or post-positivist) and has thus designed the study to describe this reality or whether the researcher assumes multiple, subjective realities and designed the study to describe these multiple realities, with no attempt to merge or reconcile these realities (constructivist/interpretivist). The paradigm has implications for the study design, approach, methods, and techniques to ensure rigor and trustworthiness.\nQualitative research includes an array of approaches and methodologies, both general (e.g., qualitative content analysis, general inductive approach) and specific (e.g., ethnography, grounded theory, phenomenography). Since the research paradigm does not necessarily dictate particular approaches or methods, the approach should also be clearly defined. Stating the approach provides readers the opportunity to evaluate the fidelity of the research approach to the research question(s) and consider the rationale for modifications and deviations from the selected approach. Qualitative research also includes an array of methods that can be used across paradigms and approaches. (See also Item 10) The researcher should explain why the selected approach is appropriate for the research question, and provide references to theories or traditions that guide the use of the approach as needed."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-qualitative-approach-2",
    "href": "guidelines/SRQR-slim/index.html#sec-qualitative-approach-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nThe study was performed from a constructivist point of view using an interpretative phenomenological epistemology. Based on the notion that social phenomena are constructed by the communal making of meaning about the underlying phenomena, we aimed to construct insightful accounts of lead consultants’ approaches to educational change, rather than to identify the ‘true’ nature of these approaches. Because the management of change by lead consultants is an under-researched area, we conducted an exploratory qualitative study…\n\n\nGiven the relative dearth of explanatory theories about factors affecting medical students’ emotional reactions, we chose to develop one by applying methods associated with grounded theory, specifically constant comparative analysis, to qualitative data obtained from learning logs and interviews. Our approach was constructivist, deliberately using researchers’ own experiences and acquired knowledge to enhance theoretical sensitivity and enrich theory development.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-researcher-characteristics-and-reflexivity-1",
    "href": "guidelines/SRQR-slim/index.html#sec-researcher-characteristics-and-reflexivity-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nReflexivity refers to intentional, systematic consideration of the potential or actual effects of the researcher(s) on all aspects of the study process. In positivist and post-positivist paradigms, personal characteristics and perspectives of researchers might be viewed as biases that limit the credibility of study findings, while in constructivist or interpretivist paradigms the characteristics and perspectives of the researchers are important contextual factors that are an accepted part of the study design, data collection, and data analysis. These characteristics and perspectives may explain how the researcher(s) obtained access to the site or participants included in the study or may add valuable insight during data analysis.\nTo demonstrate reflexivity, authors should describe important personal characteristics and perspectives of members of the research team that may influence design, data collection, and data analysis. Relevant personal characteristics might include cultural background, occupation, experience, training, position/ power dynamics, gender, race/ethnicity, and sponsoring institution. Authors should also describe the perspectives, assumptions, prior knowledge, preliminary hypotheses, and/or motives (the “stance”) of the members of the research team.\nAuthors also should describe the researchers’ relationships to participants in the study and what decisions were made in light of these relationships. For example, were any members of the research team part of the sample of potential participants in the study? Do any members of the team teach, supervise, or have any authority over participants in the study? If so, how do these characteristics influence choices about their roles in data collection and analysis? For observational research (e.g., ethnography), it is also important to identify the role of the researcher along a spectrum from passive observer (no involvement in the activity studied) to participant-observer (ranging from some limited involvement in the activity to full involvement).\nThere is no expectation that the study could be precisely replicated; these characteristics and perspectives of the researcher should not be mentioned in the limitation section. (See also Item 14.)"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-researcher-characteristics-and-reflexivity-2",
    "href": "guidelines/SRQR-slim/index.html#sec-researcher-characteristics-and-reflexivity-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nReflexivity was maintained by the research team through the analysis and writing by recording, discussing and challenging established assumptions. In addition both EH and SV kept reflexive diaries.\n\n\nThe first author conducted all interviews and discussion groups. Her own medical undergraduate training took place between 1995 and 2000. She was not known to the participants of this research prior to undertaking the study and deliberately did not undertake any clinical or teaching activities locally alongside this research. Whilst it was useful to ‘know’ (from her own background) what the students were talking about medically (and in terms of detecting items of significance), as a researcher she made conscious efforts not to accept potentially common assumptions at face value.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-context-1",
    "href": "guidelines/SRQR-slim/index.html#sec-context-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe authors should describe the setting/site(s) in which the study was conducted, the reason(s) why the setting/site(s) was selected, and the salient cultural, political, historical, economic and/or other external factors that influence the study. This information helps readers interpret the meaning and significance of the study findings by situating them in social, cultural, temporal and other relevant contexts. Additional context may be reported with findings (i.e., the Results section) to add evidence for interpretations and to enhance discussion of transferability."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-context-2",
    "href": "guidelines/SRQR-slim/index.html#sec-context-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nWe conducted the study among hospital-based clinical teachers of students in years 4 to 6 of a six-year undergraduate medical program at Maastricht University Medical School. Years 4 to 6 are devoted to clerkships in the academic hospital and affiliated regional hospitals. Rotations differ in duration depending on the type of rotation and the discipline, and the sequence of rotations differs among students. During rotations, students spend time in the wards, the outpatient clinics, and the accident and emergency department. Clerkships in years 4 and 5 last between 4 and 10 weeks (“regular clerkship”), whereas students in year 6 undertake an 18-week “senior clerkship” in a discipline of their choice.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-sampling-strategy-1",
    "href": "guidelines/SRQR-slim/index.html#sec-sampling-strategy-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe authors should describe how and why research participants, documents, and/or events were selected for inclusion in (and, if appropriate, exclusion from) the study, along with a justification for this strategy. We recommend that authors describe the sampling strategy rather than simply labeling the strategy (e.g., “purposive” or “snowball”), since such labels do not have a universally accepted definition and, more importantly, since procedures tend to be study- specific. Several sampling strategies are commonly used in qualitative research, although most fall under the umbrella of purposeful (or purposive) sampling. Purposeful sampling means that participants, documents, or events are selected for their relevance to the research question, based on guiding theory or experiences and assumptions of the researchers. Over the course of the research process, researchers may determine that additional or different participants, documents, or events should be included to address the research question. Other sampling techniques, such as theoretical sampling (seeking examples of theoretical constructs), snowball sampling (using study participants to identify additional participants who meet study criteria), and convenience sampling (including any volunteers with no or minimal criteria for inclusion) may be appropriate depending on the question and approach, so long as the authors provide explanation and justification.\nAlthough investigators often do not determine sample size a priori in qualitative research, they should nonetheless describe how they established the final sample size. When appropriate (e.g., when a flexible sampling strategy was used), they should explain the criteria used to decide when no further sampling was necessary. If data collection ends at the point when the researchers determine that “saturation” has been reached, then the specific criteria used to define saturation should be described.\nProcedures used to recruit participants should also be described, including who was involved in recruitment, what their relationship was to participants, how and when recruitment occurred, and why these procedures were selected. (See also Item 6)"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-sampling-strategy-2",
    "href": "guidelines/SRQR-slim/index.html#sec-sampling-strategy-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nAs students’ perceptions were previously shown to be related to gender, age, prior experience and place of attachment,[REF] we purposely selected respondents with different backgrounds. This sampling strategy led to the diversity of gender, age, prior patient experience and place of attachment shown in Table 1.\n\n\nPurposive sampling was directed towards achieving maximum variation in age and specialty, using a snowball approach (‘a non-probabilistic form of sampling in which persons initially chosen for the sample are used as informants to locate other persons having necessary characteristics making them eligible for the sample’).[REF ]\n\n\nPotential participants were all medical students in Years 1 and 2 at the University of Toronto in 2004. Following research ethics board approval, recruitment was conducted via e- mail to class listservs. Participant responses were sent directly to the research assistant, who was unknown to participants, so that the principal investigators did not know who did or did not participate. This process was engaged to protect participants’ anonymity and to avoid any impression of coercion because the lead researcher (SG) was involved in the administration of the undergraduate curriculum at the time. Sample size was estimated to be sufficient based on the principle of theoretical saturation [REF] and our previous experience with this methodology (i.e., with a relatively homogeneous population, we expected to reach saturation with approximately 15 interviews per group). There were no exclusion criteria and we accepted the first 15 students from each class who volunteered.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-ethics-1",
    "href": "guidelines/SRQR-slim/index.html#sec-ethics-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nQualitative research often involves interaction between researchers and research participants. Correspondingly, researchers should ensure that participants are fully aware of their participation in a research study, the risks and benefits associated with the study, the steps and precautions the researchers will take to minimize risks, such as loss of privacy and confidentiality, and how the researchers plan to use the data. Authors should report approval for the study from an appropriate institutional review board for research associated with human subjects. They should describe procedures used to protect participants, including data collection (e.g., recruitment and informed consent) analysis (e.g., data security and integrity) and reporting of findings (e.g., anonymization of excerpts). If researchers provided compensation or offered incentives to facilitate participation, this should be reported."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-ethics-2",
    "href": "guidelines/SRQR-slim/index.html#sec-ethics-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nEthical approval was granted by the University of Otago and student participants were invited to attend each focus group discussion by the university representatives of New Zealand Medical Students Association (NZMSA). Usually, a key concern when collecting data from students is that students may feel vulnerable when sharing their experiences with academic staff during a focus group discussion. However, this potential harm was removed as each group discussion was facilitated by a fellow student, the discussions were transcribed by a professional transcribing service, and only the primary researchers [Names] had access to the raw data.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-collection-methods-1",
    "href": "guidelines/SRQR-slim/index.html#sec-data-collection-methods-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nQualitative research encompasses an array of data collection methods appropriate for various paradigms and approaches, including (but not limited to) interviews, focus groups, observations (direct or indirect via video), and review of written text, photographs, and other documents or materials. Researchers may choose to use information from multiple sources, contexts, and/or time points depending on their approach and research question(s). (See Item 11 for triangulation.) Given this diversity of methods, authors should describe in detail their data collection design and method(s) and justify them in relation to the research question(s), paradigm, approach, and other methods. Methods used to decide when to end data collection should also be described (see Item 8).\nQualitative research often occurs as an iterative process, meaning that researchers begin data analysis before they complete data collection. The data collection and analysis process may occur in phases or stages, and thus authors must clearly describe the iterative process of data collection and analysis. As part of an iterative collection-analysis process, researchers will often alter their data collection methods to explore their preliminary impressions in greater depth and/or actively pursue confirming and disconfirming perspectives. If such changes occur during the research process, authors should describe how and why study procedures changed in response to evolving study findings.\nThe study period (start and end dates for data collection and analysis) should be identified so that readers can place the study in temporal context and identify factors not mentioned by the authors that might affect findings, interpretation, and implications. (See Item 8 for ending data collection.)\nAuthors should describe important characteristics of the individuals conducting interviews, observations or focus groups, and methods used to train these individuals. This information clarifies the relationship between the individuals involved in data collection and the participants in the research and also explains what efforts were made to ensure consistency in the data collection process (See Items 6 and 15.)"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-collection-methods-2",
    "href": "guidelines/SRQR-slim/index.html#sec-data-collection-methods-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nFurther, it was decided that group interviews, also known as focus group discussions would be the best means of data collection. This is a method of data collection that enables group members to feed off each other’s ideas and an effective moderator will maintain group focus whilst at the same time permitting flexibility in the direction those aspects of the discussion might take. [REF]\n\n\nAdjustments to the interview protocol were made according to early experience and information participants had provided (i.e. redundant questions were eliminated; questions were reworded to improve flow and clarity; additional probes were included).\n\n\nFaculty staff were then interviewed individually by a trained study investigator in a 15-minute, semi-structured interview. This sequence was repeated with other video encounters. Table 2 presents examples of interview questions. Each faculty member was interviewed by at least three interviewers over their various interviews. Interviewers were chosen based on their experience in interviewing. All were trained during a half-day meeting to interpret and deliver the interview guide in the same manner in order to elicit information of a consistent type.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-collection-instruments-1",
    "href": "guidelines/SRQR-slim/index.html#sec-data-collection-instruments-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nData collection for qualitative research draws upon a variety of instruments or tools, including (but not limited to) interview or focus group guides, observational protocols and prompts for field notes, and data extraction or coding protocols for selection and analysis of documents, photographs, videos, or other artifacts. The authors should describe all such instruments, guides, and protocols, including their development and cite relevant literatures, theories or conceptual frameworks as appropriate. It is often helpful for authors to provide access to the data collection instrument(s) or a detailed description of them.\nThe authors should also describe the use of equipment for audio or video recording, reproduction of paper documents or computer files, or other processes in data collection. This is relevant so readers understand the full context in which data collection occurred and how this context might have affected data collection (e.g., the influence of recording devices on participants’ behaviors; the nature of inferences drawn from live vs. recorded events)."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-collection-instruments-2",
    "href": "guidelines/SRQR-slim/index.html#sec-data-collection-instruments-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nTo facilitate the discussion and to maintain consistency over different sets of discussions, key trigger questions were devised prior to the discussion. The opening trigger question was: ‘Thinking back to some of your best clinical learning placements in 4th and 5th year. What was it about those clinical placements that provided good opportunities for learning?’\n\n\nInterviews included discussion of the expectations, processes and consequences of AEE [authentic early experiences]. The interview schedule was derived following identification of questions that could not be fully answered in a systematic review of previous empirical or theoretical literature. It comprised a sequence of topic areas including experiences in action, and areas of frustration in Medical Education such as the learning of content knowledge, achieving functional knowledge, and transfer of knowledge.[REF]… Interested readers can request a copy of the schedules from the corresponding author. Interviews lasted between 20 and 90 min. and discussion groups between 60 and 90 min. All interviews and discussion groups were conducted in private rooms at the participant’s workplace—the medical school for students and faculty, and individual places of work for workplace supervisors (except for one who chose to be interviewed at the medical school). All data were audio-recorded, and transcribed verbatim.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-units-of-study-1",
    "href": "guidelines/SRQR-slim/index.html#sec-units-of-study-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nAuthors should describe the participants, documents, or events included in the study (the units of study). The sampling item (Item 8) describes the target or ideal participants, documents, or events selected for the study. By contrast, Item 12 focuses on description of the actual participants, documents or events included in the study. Authors should describe how the actual participants, documents, or events differ from the targeted sample, why these differences may have occurred, and how this might affect the findings.\nAuthors should describe characteristics of the participants, documents or events that are relevant to the study purpose and research question(s).1 For participants, this might include age, gender, profession, institution, year of training, or relationship to the researcher and/or other participants in the study. For documents, this might include the source, intended audience, date, or type of document. For events, this might include the location, date(s), length, characteristics of attendees or participants in the event, or mood or emotional climate. If the degree of participation varied among individuals (e.g., multiple occasions; interviews and observations), the authors should describe different levels of participation. For example, if some participants were observed and interviewed and others only interviewed, or if some participants completed multiple interviews and others completed a single interview, these variations should be explained. Authors should also explain the reasons for these differences (i.e., the researchers’ choice or the participants’ preferences) and how these different levels of participation were taken into account in the analysis. Authors should also include the dates or timeframe for participation.\nThis information about participants could appear in the Methods section as part of the description of the sample, or at the beginning of the Results section to provide context for the findings presented."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-units-of-study-2",
    "href": "guidelines/SRQR-slim/index.html#sec-units-of-study-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nOf the 70 Mindful Communication program participants, 46 met the eligibility requirements to participate in the in-depth interviews. We randomly chose and then contacted 22 participants, of whom 20 agreed to be interviewed within six months of completing the program: 15 in person and 5 by telephone. Two declined for lack of time. On reaching saturation after 20 interviews, no further attempts to contact the remaining 24 participants were made.\n\n\n\n\n\nThere were 31 nursing handovers covering 137 patients, and 21 resident handovers covering 101 patients included in this study.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-processing-1",
    "href": "guidelines/SRQR-slim/index.html#sec-data-processing-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nAuthors should describe the ways in which data are prepared for analysis and managed throughout the analysis process. These activities might include transcription, coding, data entry, and organization of data. When processing audio or video recordings, relevant details might include indication of verbatim transcription of dialogue, additional notes to capture non- verbal information (especially for group interviews or focus groups), and annotations to indicate vocal inflections and utterances, as appropriate for the analytic approach. Authors should also describe procedures used to check transcripts for accuracy.\nAuthors should describe the processes used to organize, compile, and categorize data (e.g., field notes, transcripts, documents, photographs, artifacts) for analysis.\nAuthors should describe procedures used to maintain data security and protect the privacy of participants, as specified in the human subjects protocols. For example, if data are anonymized, the authors should explain how and at what point in the process this occurred. Authors may choose to use anonymous labels or identifiers to represent quotes or excerpts from unique participants, documents or events, in order to reflect the variety of sources from which such data were derived."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-processing-2",
    "href": "guidelines/SRQR-slim/index.html#sec-data-processing-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nInterviews were anonymised and each participant was given a code number.\n\n\nThe interviewers and another member of the research team (H.B.) reviewed transcripts for accuracy.\n\n\nWe collected data throughout the admission process through direct observation, audio- recording, and chart extraction. We audio-recorded, transcribed, and anonymized both the overnight and morning case review discussions. We also observed the morning case review discussions in person and collected field notes. For each case review discussion, we copied the admission notes from the patient’s record and de-identified all data.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-analysis-1",
    "href": "guidelines/SRQR-slim/index.html#sec-data-analysis-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nTechniques used for data analysis will depend on the paradigm, approach, and/or data collection methods selected by the researchers. Correspondingly, authors should be as transparent as possible about the analytic process so that readers can follow the logic of inquiry from the research question(s) to the analysis and findings. For example, this description may involve characterizing the processes and decisions made for initial classification or segmentation of data, pattern identification and description, and/or development of in-depth interpretations.1 If the researchers used an approach that has a well-defined process for data analysis (e.g., grounded theory, discourse analysis, phenomenography), the authors should cite the guiding literature and describe their processes in sufficient detail so readers can judge the extent to which the processes align with the guiding approach. If modification to or deviations from the guiding approach occurred, the authors should explain and justify these modifications.\nAuthors should specify the unit of analysis.1 In qualitative research, the unit of analysis is not necessarily the same as the unit of sampling (e.g., individual participants or events). Instead, some approaches use specific events as the unit of analysis, such as mentions of a particular topic or experience, or observations of a particular behavior or phenomenon, while others use groups rather than individual group participants. This specification has implications for how the data are organized and analyzed as well as the inferences drawn from the data.\nAuthors should explain the rationale underlying different decisions made throughout the data analysis process to provide as much transparency as possible. In some approaches researchers use memoing or bracketing to make their reflections, interpretations, and links among passages explicit and more transparent to others. In some types of analysis, participants’ perspectives or observations that contrast or deviate from the concepts or themes identified by the researchers are an important part of the analysis. In such cases, the authors must describe how these discrepancies were handled during the analysis.\nDuring the analysis process, researchers may draw upon a theoretical perspective or framework, which may have been identified early in the conception of the study or may be identified by the researchers after reviewing some or all of their data. Either way, the authors should describe theoretical or other influences on their analysis scheme or categories if they exist. Sometimes these are referred to as “sensitizing concepts” to acknowledge that the approach is inductive, but with influence from relevant theory, models, or organizational schemes. Alternatively, themes may be developed from the data with no external influences.\nAuthors should describe which members of the research team are involved in data analysis and what perspective(s) they bring to the analysis. Authors should also indicate if any software was used to assist with data analysis and how it was used (e.g., used to apply codes after the final coding scheme was developed; to extract coded passages for further synthesis and identification of themes; or to identify passages with key words). Simply stating that software was used is insufficient."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-data-analysis-2",
    "href": "guidelines/SRQR-slim/index.html#sec-data-analysis-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\n…we brought sensitizing concepts to the analysis while we conducted an open, inductive analysis.[REF]In this case the sensitizing concepts arose, a priori to analysis, from a framework derived from the literature [REF] (as described above), in which participants’ motivations to act are based on principles of professionalism, internal affect, or potential implications of their actions.[REF]\n\n\nThrough an iterative process of listening, discussing, and relistening, the team identified and consensually validated emerging themes[REF] and appended segments of dialogue supporting the proposed themes. Recruitment stopped when saturation was reached (no new themes were identified). The team systematically reviewed the themes and sorted them into content domains. The team used an analytic matrix to identify patterns and connections amongst the domains. Two of us not involved in the qualitative coding process (R.E., M.K.) audited the analytic matrix, choice of quotes, and thematic analysis.\n\n\nThe analysis started after the first interview. All data were analyzed with the aid of the audio- coding facility of the NVivo 8: QSR International Pty Ltd, Doncaster, Vic, Australia programme. First, [name] and [name] coded independently from one another, making sure to stay semantically close to the participants’ wording. Then we discussed these open codes and defined axial codes.[REF] New insights about the impact of CST were written down in memos.\n\n\nVideotapes were analysed using immersion/crystallisation methods of qualitative data analysis.[REF] With no pre-existing framework developed in advance for analysis, an inductive approach was used to discover patterns of NVB in the data. A team of six researchers met weekly for 18 months to view videos together. Using a consensus-building approach based on a combination of field notes, ‘opportunistic’ interviews with the participants, and repeated viewing of the same material, sometimes many months apart, we eventually achieved consensus on verbal, non-verbal, and physical themes and patterns observed in the data. Finally, as a test of ‘goodness-of-fit,’ we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\n\nAll transcripts were coded thematically by four of the five authors, who met regularly to identify areas of convergence until full agreement was reached. One of the interviewers (P.M.) maintained an audit trail to track the team’s developing thinking. A process of dialectical empiricism[REF] was used to categorise the emergent themes into more abstract concepts…\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-trustworthiness-1",
    "href": "guidelines/SRQR-slim/index.html#sec-trustworthiness-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nAuthors should describe methods used to ensure trustworthiness and credibility throughout the data collection and analysis process. Such methods will depend on the paradigm, approach, and/or methods used. Correspondingly, the authors should explain their choice of techniques and why these are appropriate for the particular study.\nCommonly used techniques to enhance trustworthiness include: member checking; triangulation of data sources, methods, and/or researchers; creation of an explicit audit trail; and immersion in the site of data collection for an extended period of time (especially for research in which an observer’s presence is likely to disrupt the phenomenon under investigation). Member checking involves sharing findings, such as descriptions of key phenomena, themes, or an explanatory model, with participants and asking them to verify the accuracy or resonance with their perspectives. Triangulation involves using more than one data source, method, or researcher to add diverse perspectives on the findings of the study and, in some approaches, to test the transferability or generalizability of a model. An audit trail involves careful documentation of all decisions made throughout the study, from initial conceptualization to study design, sampling, analysis, and reporting, to provide transparency and to enable an external researcher to review all the steps involved in the study."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-trustworthiness-2",
    "href": "guidelines/SRQR-slim/index.html#sec-trustworthiness-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\nMember checking\n\nMember checks [REF] with an external TBL expert (R.L.) supported the validity of these analyses.\n\nTriangulation of data types and data sources\n\nThe interview data were triangulated with the data of 11 student and supervisor focus groups of a previous study, and more specifically, with those data that concern in particular the influence of CST [Communication Skills Training] on the development of patient-centredness…. Triangulation with the focus group data allowed us to broaden the in-depth information from the interviews in the analysis and to ‘share and compare’ this with information from students and doctors with varying levels of CST (no, limited, full programme) and from two universities (Universities of Antwerp and Ghent). Moreover, this enabled us to better explore the evolution over time, given that the focus groups included participants at different stages of their study: before clerkships (year 4, undergraduate), during clerkships (year 6, undergraduate), after clerkships (year 7, undergraduate) and postgraduate (general practice trainees, and supervising specialists and GPs; Table 1).\n\n\n\n\n\nFinally, as a test of ‘goodness-of-fit’, we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\nTriangulation of Researchers + Audit trail\n\nTo ensure rigor and increase authenticity in our methodology, we used two kinds of triangulation—investigator triangulation and data triangulation.[REF] We sought analytical rigor using an audit trail and multiple coders; our coding team included an experienced clinician (M.G.) as well as a nonclinician with expertise in medical communication and team dynamics (L.L.).\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-synthesis-and-interpretation-1",
    "href": "guidelines/SRQR-slim/index.html#sec-synthesis-and-interpretation-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nIn qualitative research the distinction between results and discussion tends to blur because analysis often involves interpretation, inference, and synthesis. Although most journals require separate sections for Results and Discussion, many elements of Items 16-19 could reasonably be reported in either section. As such, we defer to authors and editors to determine where to report these essential elements.\nAuthors should identify the main analytic findings (e.g., interpretations, inferences, narratives, themes, models). The nature of these findings and how they are reported will depend on the approach and methodology selected and thus should be in alignment with the approach and methods.\nIn most cases, the authors should report a synthesis of their data along with specific quotes, examples, or illustrations derived from their data. Authors might also report frequency, variety, representativeness, counter-examples, concrete details, contextualization, conditions, and qualifications related to their findings. Frequency counts (e.g., the frequency of specific themes or codes) play a limited role in qualitative research, and need not be reported unless they play a meaningful role in interpretation of the data.\nFindings might also include integration with prior literature or theory and/or the development of a theory, model or meta-narrative. Judicious use of tables and figures can help communicate such findings."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-synthesis-and-interpretation-2",
    "href": "guidelines/SRQR-slim/index.html#sec-synthesis-and-interpretation-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nWe identified four patterns of NVB (non-verbal behavior) that relate to handover quality and have dubbed them: (1) joint focus of attention; (2) ‘the poker hand’; (3) parallel play; and (4) kerbside consultation. Each pattern constitutes a ‘transfix,’ or systematic way of participating non-verbally in the care transfer process. And, although there are variations in each pattern, we have been able to code virtually every handover we have observed in nursing, medicine and surgery into one of these four categories.\n\n\nBecause our participants came from similar educational backgrounds, had studied medicine as their tertiary course, were embedded in the culture of medicine, and were associated in meaningful ways with a single medical school, we approached their transcripts with the assumption that they belonged to a loosely formed discourse community. Although their graduation dates ranged over a period of 50 years and their collective sphere of practice included 10 different specialty areas, there were many similarities in their experiences of enculturation during and after medical school.\n\n\nTheir three major (often overlapping) areas of concern were epistemic (acquiring knowledge and skill), interpersonal (relating to patients, families, colleagues and administrators) and personal (achieving work–life balance). In each of these areas, medical enculturation was achieved by two overlapping processes, ‘absorption’ and ‘assimilation’, each of which may have distinct implications for postgraduate medical education.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-links-to-empirical-data-1",
    "href": "guidelines/SRQR-slim/index.html#sec-links-to-empirical-data-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe authors should provide evidence (e.g., quotes, field notes, text excerpts, photographs) to substantiate the more general and abstract concepts or inferences they present as findings. Such evidence is typically de-identified to protect the privacy of study participants, settings, and/or institutions. The evidence may be presented in a variety of ways such as in a table or figure, incorporated into a narrative description of findings, as a stand-alone narrative, or in text blocks embedded in the manuscript text. If word limits or media limitations (e.g.. video) limit the authors’ ability to provide sufficient representation of supporting data, an appendix, supplemental material, or web-based repository could be used to provide access to additional data."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-links-to-empirical-data-2",
    "href": "guidelines/SRQR-slim/index.html#sec-links-to-empirical-data-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\nSee Frankel et al. for an excellent example of how to use photographs (or snapshots from video) to illustrate and provide supporting evidence for patterns of behavior identified in the analysis. http://qualitysafety.bmj.com/content/21/Suppl_1/i121.\n\nWe identified five interruption types: (1) probing for further data, (2) prompting for expected sequence, (3) teaching around the case, (4) thinking out loud, and (5) providing direction (see Table 1). Several interruption types served both goals of the case review discussions—teaching and patient care. For example, when thinking out loud, supervisors reasoned through problems and taught the team: “So that’s the big question, did she have a mechanical fall, or did she have a medicine-related fall?” (Case 2). Supervisors prompted for expected sequence, preventing presenters from skipping over information while simultaneously allowing the supervisor to instruct the team on presentation style: “So now you can tell me what the rest of his test results are because I haven’t heard those” (Case 16).\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-integration-with-prior-work-1",
    "href": "guidelines/SRQR-slim/index.html#sec-integration-with-prior-work-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe authors should begin the Discussion with a short summary of the main findings. The short summary reminds readers of the main findings and may help them assess whether the subsequent interpretation and implications formulated by the authors are supported by the findings.\nThe authors’ description of their findings or results should include some interpretation of the data in the context of previous findings, experiences, theory, or a guiding paradigm or approach. The discussion provides authors an opportunity to elaborate on their findings in relation to their research question(s) and study purpose(s); connect their findings to prior empirical work, theories, and/or frameworks; and discuss implications. The authors should explicitly describe how their findings contribute to or advance the field. Implications may include transferability, or specifying the appropriate scope for generalization of the findings beyond the study (e.g., to other settings, populations, time periods, circumstances)."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-integration-with-prior-work-2",
    "href": "guidelines/SRQR-slim/index.html#sec-integration-with-prior-work-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nThis study contributes to the understanding and discussion of the complexity of involving patients in healthcare education. It shows that integrating patient-led teaching into initiatives that are partly faculty-led influences the way in which students perceive learning from and with PIs. What is not known, however, is whether perceptions are also affected by type of health profession and the students’ different orientation towards logics of care and science, and issues of authority and power relations.\n\nFor complete examples of Discussions, see:\n\nHenriksen & Ringsted, 2013\nWesterman et al., 2013.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-limitations-1",
    "href": "guidelines/SRQR-slim/index.html#sec-limitations-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nAuthors should describe techniques used to ensure trustworthiness in the Methods section of the manuscript. In the Discussion, authors should identify problems or gaps in their efforts to ensure trustworthiness and the potential implications. For example, if researchers intended to interview individuals with certain characteristics, or who might offer different perspectives, but were unsuccessful in recruiting any willing participants, they should explain this issue and describe possible consequences for transferability. (See also Item 18.)\nAll research paradigms and approaches have strengths and weaknesses, and authors should explicitly discuss how the paradigm, approach, and methods they used will influence the situations to which their findings may reasonably apply. (See also Item 18.) In addition, they should explain how specific decisions or events in the conduct of the study strengthen or weaken the rigor of their findings."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-limitations-2",
    "href": "guidelines/SRQR-slim/index.html#sec-limitations-2",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nThe study has several limitations. One is that the focus group interview method reveals students’ perceptions rather than their actual behaviors. Observations of the patient-led teaching encounter may have illuminated an understanding of the relationship between patient instructors and medical students. Another limitation is that the PI-led teaching is optional rather than mandatory, which may have influenced students’ attitudes in a positive direction. Moreover, students who are eager to take on extra-curricular activities may not be representative of the whole population. That only 23 out of 39 students signed up for this study might also have influenced results if the missing group of students represented other perceptions than those present in the focus groups. However the received data from the focus groups were rich in information and diverse perceptions were present. Another limitation is the overrepresentation of women over men in our sample. Even though women are also overrepresented in medical school this might potentially have influenced results, but gender differences in perceptions were nevertheless not identified in the data.\n\nBack to top”"
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-conflicts-of-interest-1",
    "href": "guidelines/SRQR-slim/index.html#sec-conflicts-of-interest-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nAuthors should identify any real or potential conflicts of interest that might have influenced or could appear to have influenced the research. Authors should also explain how these conflicts were managed in the conduct of the study, and describe the potential impact on study findings and/or conclusions. Some aspects may be mentioned as part of reflexivity (see Item 6)."
  },
  {
    "objectID": "guidelines/SRQR-slim/index.html#sec-funding-1",
    "href": "guidelines/SRQR-slim/index.html#sec-funding-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Read more",
    "text": "Read more\nThe authors should describe any sources of funding and other support for the study and the role of funders in data collection, data analysis, and reporting if applicable."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "ABCDE.html",
    "href": "ABCDE.html",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "",
    "text": "Ea ea velit dolore exercitation reprehenderit reprehenderit aute elit eu proident voluptate commodo adipisicing."
  },
  {
    "objectID": "ABCDE.html#translations",
    "href": "ABCDE.html#translations",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Translations",
    "text": "Translations\nThis guidance is available in language, language, and language"
  },
  {
    "objectID": "ABCDE.html#when-to-use-this-guidance",
    "href": "ABCDE.html#when-to-use-this-guidance",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "When to use this guidance",
    "text": "When to use this guidance\n\n\n\n\n\n\nUse this guidance for:\n\nEst qui exercitation est commodo irure\nCulpa ipsum exercitation culpa ea deserunt.\nUse a template for drafting\nUse a checklist to check and demonstrate compliance\nUse a to-do list for planning a manuscript\n\nIt can also be used for:\n\nEnim quis laborum dolor occaecat fugiat (use items #-#).\nQuis nostrud incididunt ipsum nisi eu laboris (use items #-#).\n\n\n\n\n\n\n\n\n\n\nDo not use this guidance for:\n\nwriting incididunt ipsum nisi, use BHUJSD-Cudhjs instead\nwriting incididunt ipsum nisi, use THUYGH instead\nwriting incididunt ipsum nisi\nappraising quality, consider using QWETY instead\n\n\n\n\n\n\n\n\n\n\nFor designing research consider:\n\nresource\nresource\n\nFor appraising research consider:\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#download-resources",
    "href": "ABCDE.html#download-resources",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Download Resources",
    "text": "Download Resources\n\n\n\nFor drafting\n\n\nTemplate\n\n\n\n\nFor checking\n\n\nChecklist\n\n\n\n\nFor planning\n\n\nTo-do list"
  },
  {
    "objectID": "ABCDE.html#guidance",
    "href": "ABCDE.html#guidance",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Guidance",
    "text": "Guidance\nApprox. 7 min read\n\nIntroduction\n\n\n1. Occaecat commodo\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n2. Commodo sint\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n3. Sint ea\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n4. Ea laborum\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n5. Laborum voluptate\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\nMethods\n\n\n6. Voluptate ut\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n7. Ut veniam\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n8. Veniam voluptate\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n9. Voluptate fugiat\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n10. Fugiat voluptate\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\nResults\n\n\n11. Voluptate qui\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n12. Qui minim\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n13. Minim sunt\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n14. Sunt esse\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n15. Esse non\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\nDiscussion\n\n\n16. Non et\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n17. Et ea\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n18. Ea pariatur\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n19. Pariatur nisi\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top\n\n\n\n\n\n\n20. Nisi et\n\n\n\n\n\n\n\nDescribe irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea exercitation elit Lorem ullamco proident reprehenderit. Ipsum consequat nisi ullamco consectetur anim voluptate.\nIf you did not do irure sint ipsum aute eiusmod irure laborum sunt minim. Irure aliquip do dolor do ea ipsum nostrud ea.\nIf [applicability criteria not met], describe nisi ullamco consectetur anim.\nYou can report this [options e.g., in the body, a table, a figure, supplement] with pros and cons for each [e.g., word count vs. discoverability].\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nExamples\nWhy readers need this information\nDesign & appraisal resources\nHow to do this item\nTraining\n\n\nExamples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco.\n\n\n\nWhy readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco.\n\n\nDesign and appraisal resouces\n\nresource\nresource\nresource\nresource\n\n\n\nHow to do [something]\n\nresource\nresource\n\n\n\nTraining\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-1",
    "href": "ABCDE.html#sec-1-1",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-1",
    "href": "ABCDE.html#sec-2-1",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-1",
    "href": "ABCDE.html#sec-3-1",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-1",
    "href": "ABCDE.html#sec-4-1",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-1",
    "href": "ABCDE.html#sec-5-1",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-2",
    "href": "ABCDE.html#sec-1-2",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-2",
    "href": "ABCDE.html#sec-2-2",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-2",
    "href": "ABCDE.html#sec-3-2",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-2",
    "href": "ABCDE.html#sec-4-2",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-2",
    "href": "ABCDE.html#sec-5-2",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-3",
    "href": "ABCDE.html#sec-1-3",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-3",
    "href": "ABCDE.html#sec-2-3",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-3",
    "href": "ABCDE.html#sec-3-3",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-3",
    "href": "ABCDE.html#sec-4-3",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-3",
    "href": "ABCDE.html#sec-5-3",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-4",
    "href": "ABCDE.html#sec-1-4",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-4",
    "href": "ABCDE.html#sec-2-4",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-4",
    "href": "ABCDE.html#sec-3-4",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-4",
    "href": "ABCDE.html#sec-4-4",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-4",
    "href": "ABCDE.html#sec-5-4",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-5",
    "href": "ABCDE.html#sec-1-5",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-5",
    "href": "ABCDE.html#sec-2-5",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-5",
    "href": "ABCDE.html#sec-3-5",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-5",
    "href": "ABCDE.html#sec-4-5",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-5",
    "href": "ABCDE.html#sec-5-5",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-6",
    "href": "ABCDE.html#sec-1-6",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-6",
    "href": "ABCDE.html#sec-2-6",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-6",
    "href": "ABCDE.html#sec-3-6",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-6",
    "href": "ABCDE.html#sec-4-6",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-6",
    "href": "ABCDE.html#sec-5-6",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-7",
    "href": "ABCDE.html#sec-1-7",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-7",
    "href": "ABCDE.html#sec-2-7",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-7",
    "href": "ABCDE.html#sec-3-7",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-7",
    "href": "ABCDE.html#sec-4-7",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-7",
    "href": "ABCDE.html#sec-5-7",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-8",
    "href": "ABCDE.html#sec-1-8",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-8",
    "href": "ABCDE.html#sec-2-8",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-8",
    "href": "ABCDE.html#sec-3-8",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-8",
    "href": "ABCDE.html#sec-4-8",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-8",
    "href": "ABCDE.html#sec-5-8",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-9",
    "href": "ABCDE.html#sec-1-9",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-9",
    "href": "ABCDE.html#sec-2-9",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-9",
    "href": "ABCDE.html#sec-3-9",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-9",
    "href": "ABCDE.html#sec-4-9",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-9",
    "href": "ABCDE.html#sec-5-9",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-10",
    "href": "ABCDE.html#sec-1-10",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-10",
    "href": "ABCDE.html#sec-2-10",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-10",
    "href": "ABCDE.html#sec-3-10",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-10",
    "href": "ABCDE.html#sec-4-10",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-10",
    "href": "ABCDE.html#sec-5-10",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-11",
    "href": "ABCDE.html#sec-1-11",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-11",
    "href": "ABCDE.html#sec-2-11",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-11",
    "href": "ABCDE.html#sec-3-11",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-11",
    "href": "ABCDE.html#sec-4-11",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-11",
    "href": "ABCDE.html#sec-5-11",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-12",
    "href": "ABCDE.html#sec-1-12",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-12",
    "href": "ABCDE.html#sec-2-12",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-12",
    "href": "ABCDE.html#sec-3-12",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-12",
    "href": "ABCDE.html#sec-4-12",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-12",
    "href": "ABCDE.html#sec-5-12",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-13",
    "href": "ABCDE.html#sec-1-13",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-13",
    "href": "ABCDE.html#sec-2-13",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-13",
    "href": "ABCDE.html#sec-3-13",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-13",
    "href": "ABCDE.html#sec-4-13",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-13",
    "href": "ABCDE.html#sec-5-13",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-14",
    "href": "ABCDE.html#sec-1-14",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-14",
    "href": "ABCDE.html#sec-2-14",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-14",
    "href": "ABCDE.html#sec-3-14",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-14",
    "href": "ABCDE.html#sec-4-14",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-14",
    "href": "ABCDE.html#sec-5-14",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-15",
    "href": "ABCDE.html#sec-1-15",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-15",
    "href": "ABCDE.html#sec-2-15",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-15",
    "href": "ABCDE.html#sec-3-15",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-15",
    "href": "ABCDE.html#sec-4-15",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-15",
    "href": "ABCDE.html#sec-5-15",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-16",
    "href": "ABCDE.html#sec-1-16",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-16",
    "href": "ABCDE.html#sec-2-16",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-16",
    "href": "ABCDE.html#sec-3-16",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-16",
    "href": "ABCDE.html#sec-4-16",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-16",
    "href": "ABCDE.html#sec-5-16",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-17",
    "href": "ABCDE.html#sec-1-17",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-17",
    "href": "ABCDE.html#sec-2-17",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-17",
    "href": "ABCDE.html#sec-3-17",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-17",
    "href": "ABCDE.html#sec-4-17",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-17",
    "href": "ABCDE.html#sec-5-17",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-18",
    "href": "ABCDE.html#sec-1-18",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-18",
    "href": "ABCDE.html#sec-2-18",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-18",
    "href": "ABCDE.html#sec-3-18",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-18",
    "href": "ABCDE.html#sec-4-18",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-18",
    "href": "ABCDE.html#sec-5-18",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-19",
    "href": "ABCDE.html#sec-1-19",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-19",
    "href": "ABCDE.html#sec-2-19",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-19",
    "href": "ABCDE.html#sec-3-19",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-19",
    "href": "ABCDE.html#sec-4-19",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-19",
    "href": "ABCDE.html#sec-5-19",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#sec-1-20",
    "href": "ABCDE.html#sec-1-20",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Examples",
    "text": "Examples\n✅  Good reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat.\n\nThis example is good because…\n\nEu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu.\n\nThis example is good because…\n❌  Bad reporting\n\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit.\n\nThis example is bad because it is missing X, Y, Z.\n\nEu cillum dolore ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-2-20",
    "href": "ABCDE.html#sec-2-20",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Why readers need this information",
    "text": "Why readers need this information\nEt fugiat velit consequat sunt officia sit veniam officia. Exercitation est nisi ex deserunt laboris reprehenderit ut sit nisi. Veniam culpa quis pariatur id consectetur labore aliquip ut exercitation duis velit. Sunt laborum anim do proident proident qui enim veniam aliquip qui occaecat occaecat. Eu cillum dolore aliquip voluptate et aliquip minim aute. Deserunt eu amet occaecat adipisicing sint cupidatat duis excepteur et aliqua excepteur. Do enim exercitation culpa enim in velit ullamco."
  },
  {
    "objectID": "ABCDE.html#sec-3-20",
    "href": "ABCDE.html#sec-3-20",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Design and appraisal resouces",
    "text": "Design and appraisal resouces\n\nresource\nresource\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-4-20",
    "href": "ABCDE.html#sec-4-20",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "How to do [something]",
    "text": "How to do [something]\n\nresource\nresource"
  },
  {
    "objectID": "ABCDE.html#sec-5-20",
    "href": "ABCDE.html#sec-5-20",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training",
    "text": "Training\n\nLink to relevant EQUATOR training\nLink to other relevant training\n\nBack to top"
  },
  {
    "objectID": "ABCDE.html#faqs",
    "href": "ABCDE.html#faqs",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "FAQs",
    "text": "FAQs\n\nHow this guidance was made\nExcepteur deserunt mollit enim fugiat reprehenderit. Fugiat veniam sunt nulla ullamco. Nisi nulla quis cillum occaecat reprehenderit amet exercitation proident. Et et et proident magna fugiat velit do occaecat in nulla. Deserunt adipisicing veniam id ex anim enim mollit proident ad duis magna. Ipsum officia laborum ad eiusmod culpa ullamco. Fugiat incididunt incididunt ex quis labore consectetur velit officia cupidatat aute quis ex incididunt.\n\n\nPublications related to this guidance\nView all related publications in the EQUATOR database.\n\n\nPariatur proident minim\nIncididunt voluptate fugiat aliqua esse. Esse ex voluptate anim aliqua voluptate consectetur minim. Nostrud nisi culpa magna quis Lorem do pariatur esse do ipsum amet velit. Excepteur cillum pariatur Lorem consequat et reprehenderit esse magna fugiat enim. Laboris magna et deserunt pariatur cupidatat culpa eu elit. Cillum consequat non nisi eu. Occaecat proident incididunt proident ea voluptate. Ex velit qui eu cillum.\n\n\nLaborum quis ad\nId quis irure eu officia qui. Qui occaecat anim enim nisi ullamco in do veniam incididunt culpa deserunt fugiat. Ut excepteur consectetur fugiat occaecat sit. Qui irure adipisicing sint nisi minim consectetur commodo. Mollit ad ad ipsum quis exercitation anim anim. Commodo aliquip irure ad consectetur."
  },
  {
    "objectID": "ABCDE.html#training-and-support",
    "href": "ABCDE.html#training-and-support",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Training and Support",
    "text": "Training and Support\nEsse aute consectetur mollit non pariatur deserunt occaecat elit officia. Deserunt amet est eu id qui in aliquip sunt commodo minim dolor. Dolor adipisicing ea sunt sit eiusmod mollit. Quis consequat occaecat nisi enim labore pariatur eu. Ipsum aliqua cillum dolore ipsum consequat. Dolor in ad sit commodo ipsum laboris Lorem qui exercitation amet do nulla. Eu in excepteur ad deserunt.\n\nAute pariatur excepteur\nTempor cupidatat\nElit ea adipisicing dolore."
  },
  {
    "objectID": "ABCDE.html#citation",
    "href": "ABCDE.html#citation",
    "title": "The ABCDE guidelines for writing XYZ",
    "section": "Citation",
    "text": "Citation\nExcepteur excepteur nulla excepteur Lorem incididunt ex velit quis excepteur et enim. Ad excepteur cillum non ipsum ad est ea cillum et dolore commodo elit laborum do. Lorem magna occaecat laboris nulla sint esse excepteur.\n\n\n\nIrure sint ipsum aute eiusmod\n\n\n\n\n\n\nQui duis consequat nisi anim ullamco officia dolore ut sunt. Consequat ad elit ex fugiat in eiusmod incididunt elit id ullamco. Quis ut minim et elit adipisicing ad cupidatat. Cupidatat dolore voluptate do qui consectetur adipisicing nulla. Ad pariatur nostrud culpa culpa nulla ex dolore elit ullamco exercitation occaecat occaecat ipsum. Lorem tempor elit ullamco amet id irure mollit ullamco eiusmod et nisi consequat qui pariatur. Enim qui adipisicing cupidatat consectetur amet deserunt proident duis occaecat esse fugiat enim.\nLearn more\n\n\n\n\n\n\nDiscussion for [item name]\n\n\n\n\n\n\nThis will be a discussion board for a specific reporting item. We could use something like giscus so that comments are linked to reporting item versions within github.\nLearn more about Giscus"
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#translations",
    "href": "guidelines/SRQR-1/index.html#translations",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Translations",
    "text": "Translations\nThis guidance is also available in French."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#when-to-use-this-guidance",
    "href": "guidelines/SRQR-1/index.html#when-to-use-this-guidance",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "When to use this guidance",
    "text": "When to use this guidance\n\n\n\n\n\n\nUse this guidance for reporting qualitative research studies.\nThe SRQR items reflect information essential for inclusion in a qualitative research report, but should not be viewed as prescribing a rigid format or standardized content. Consider each item and prioritize elements that are most relevant to your study, findings, context, and readership.\nYou can also use this guideline for:\n\nfor writing protocols (use the items within the Introduction and Method sections).\nreviewing the reporting of an article, but not for appraising its quality."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#download-resources",
    "href": "guidelines/SRQR-1/index.html#download-resources",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Download Resources",
    "text": "Download Resources\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list"
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#guidance",
    "href": "guidelines/SRQR-1/index.html#guidance",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Guidance",
    "text": "Guidance\nApprox. 25 min read\n\n\n1. Title\n\n\n\n\n\n\n\nConcise description of the nature and topic of the study. Identifying the study as qualitative or indicating the approach (e.g., ethnography, grounded theory) or data collection methods (e.g., interview, focus group) is recommended.\nThe authors should provide a title that clearly conveys the topic of the study. We suggest that the title indicate that the study is qualitative or include a commonly used term that identifies the approach (e.g., ethnographic study, grounded theory) or data collection methods (e.g., interviews, focus groups, observations). This allows readers and reviewers to quickly identify the type of study.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nResidents learning from a narrative experience with dying patients: a qualitative study.\n\n\nMedical students’ perceptions of the factors influencing their academic performance: an exploratory interview study with high-achieving and re-sitting medical students.\n\n\nUndergraduate rural medical education program development: focus group consultation with the NRHA Rural Medical Educators Group.\n\n\n\n\n\n\n2. Abstract\n\n\n\n\n\n\n\nSummary of key elements of the study using the abstract format of the intended publication; typically includes background, purpose, methods, results, and conclusions.\nA reader should be able to read the abstract independent of the manuscript and get a sense of the background, purpose, methods, main results and implications that will be described in greater detail in the manuscript. The information presented in the abstract should be consistent with the information presented in the full text.\nThe abstract’s structure typically needs to conform to journal guidelines, but authors should attempt to include the following:\n\nBackground about the problem or phenomenon of interest\nDescription of the study purpose or research question;\nMethods, including the approach or perspective (e.g., general inductive, grounded theory), context (setting, time period), sample (number and key characteristics of participants, events, documents), data collection strategies (e g., observation, interview, focus group) and data analysis techniques\nDescription of main findings (e.g., themes or inferences) related to the study purpose and/or research question\nStudy implications\n\nIn some cases the journal’s structured abstract format aligns more with positivist paradigms and quantitative approaches than with qualitative traditions, so translation may be necessary. For example, what might be labelled “findings” in many qualitative research traditions could be reported as “results” in the abstract.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExample\nPurpose: Although academic centers rely on assessments from medical trainees regarding the effectiveness of their faculty as teachers, little is known about how trainees conceptualize and approach their role as assessors of their clinical supervisors\nMethod: In 2010, using a constructivist grounded theory approach, five focus group interviews were conducted with 19 residents from an internal medicine residency program. A constant comparative analysis of emergent themes was conducted.\nResults: Residents viewed clinical teaching assessment (CTA) as a time-consuming task with little reward. They reported struggling throughout the academic year to meet their CTA obligations and described several shortcut strategies they used to reduce their burden. Rather than conceptualizing their assessments as a conduit for both formative and summative feedback, residents perceived CTA as useful for the surveillance of clinical supervisors at the extremes of the spectrum of teaching effectiveness. They put the most effort, including the crafting of written comments, into the CTAs of these outliers. Trainees desired greater transparency in the CTA process and were sceptical regarding the anonymity and perceived validity of their faculty appraisals.\nConclusions: Individual and system-based factors conspire to influence postgraduate medical trainees’ motivation for generating high-quality appraisals of clinical teaching. Academic centers need to address these factors if they want to maximize the usefulness of these assessments.\n\n\n\n\nIntroduction\n\n\n3. Problem Formulation\n\n\n\n\n\n\n\nDescription and significance of the problem/phenomenon studied; review of relevant theory and empirical work; problem statement.\nThe problem formulation typically appears in the introduction and describes the theoretical and/or practical issues or concerns that make the study necessary. It should provide an overview of what is known about the problem, highlight gaps in current knowledge (the problem statement), and define the scope of the research problem or phenomena addressed in the study (what will and will not be included). It should include a review of theoretical and/or empirical work directly relevant to the problem or phenomena studied. The problem formulation should be described in a way that suggests the need for a qualitative approach (e.g., to elucidate poorly defined or previously unexplored constructs, to generate theories or to develop causal explanations connecting processes and outcomes, to understand phenomena as they naturally occur and the role of context, to explore problems involving high complexity, to gain insight into participants’ perspectives when such insight is lacking).\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExample\n\nRegulatory focus theory may therefore offer insight into the variability in responses to feedback, but how well do these experimental findings translate to real clinical situations in which the reality of responsiveness to feedback seems frustratingly complex? …. In order to better elaborate a theory to account for this variability in learner response to feedback, the present study was undertaken. We aimed, in this study, to determine how readily clinical learning events could be classified as activating a promotion or a prevention focus, and to explore, through a careful analysis of doctors’ descriptions of their feedback experiences, the predictive value of regulatory focus theory in the context of real clinical learning situations.\n\n\n\n\n\n\n4. Purpose or research question\n\n\n\n\n\n\n\nPurpose of the study and specific objectives or questions\nIn qualitative research, as in all types of research, the authors should include a statement of study intent. This statement can be framed as one or more research questions, purposes, goals, or objectives. Qualitative studies often explore “how” and “why” questions related to a social or human problems or phenomenon, and they are designed to enhance readers’ understanding of a problem or phenomenon. By clearly stating the purpose of the study, authors set readers’ expectations for the methods, findings and discussion sections of the manuscript.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExample\n\nThe purposes of this study were to investigate how medical students recognize, respond to and utilise feedback, and to determine whether there are maturational differences in understandings of the role of feedback across academic years in medical school.\n\n\n\n\n\n\nMethods\n\n\n5. Qualitative approach and research paradigm\n\n\n\n\n\n\n\nQualitative approach (e.g., ethnography, grounded theory, case study, phenomenology, narrative research) and guiding theory if appropriate; identifying the research paradigm (e.g., post-positivist, constructivist/interpretivist) is also recommended; rationale.\nThe research paradigm is the set of beliefs and assumptions that guide the research process. These commonly include positivist, post-positivist, constructivist or interpretivist, and critical theory. Qualitative research generally draws from a post-positivist or constructivist/interpretivist paradigm. We recommend identifying the research paradigm so that readers understand whether the researcher assumes that there is a single, objective reality (positivist or post-positivist) and has thus designed the study to describe this reality or whether the researcher assumes multiple, subjective realities and designed the study to describe these multiple realities, with no attempt to merge or reconcile these realities (constructivist/interpretivist). The paradigm has implications for the study design, approach, methods, and techniques to ensure rigor and trustworthiness.\nQualitative research includes an array of approaches and methodologies, both general (e.g., qualitative content analysis, general inductive approach) and specific (e.g., ethnography, grounded theory, phenomenography). Since the research paradigm does not necessarily dictate particular approaches or methods, the approach should also be clearly defined. Stating the approach provides readers the opportunity to evaluate the fidelity of the research approach to the research question(s) and consider the rationale for modifications and deviations from the selected approach. Qualitative research also includes an array of methods that can be used across paradigms and approaches. (See also Item 10) The researcher should explain why the selected approach is appropriate for the research question, and provide references to theories or traditions that guide the use of the approach as needed.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nThe study was performed from a constructivist point of view using an interpretative phenomenological epistemology. Based on the notion that social phenomena are constructed by the communal making of meaning about the underlying phenomena, we aimed to construct insightful accounts of lead consultants’ approaches to educational change, rather than to identify the ‘true’ nature of these approaches. Because the management of change by lead consultants is an under-researched area, we conducted an exploratory qualitative study…\n\n\nGiven the relative dearth of explanatory theories about factors affecting medical students’ emotional reactions, we chose to develop one by applying methods associated with grounded theory, specifically constant comparative analysis, to qualitative data obtained from learning logs and interviews. Our approach was constructivist, deliberately using researchers’ own experiences and acquired knowledge to enhance theoretical sensitivity and enrich theory development.\n\n\n\n\n\n\n6. Researcher characteristics and reflexivity\n\n\n\n\n\n\n\nResearchers’ characteristics that may influence the research, including personal attributes, qualifications/experience, relationship with participants, assumptions, and/or presuppositions; potential or actual interaction between researchers’ characteristics and the research questions, approach, methods, results and/or transferability.\nReflexivity refers to intentional, systematic consideration of the potential or actual effects of the researcher(s) on all aspects of the study process. In positivist and post-positivist paradigms, personal characteristics and perspectives of researchers might be viewed as biases that limit the credibility of study findings, while in constructivist or interpretivist paradigms the characteristics and perspectives of the researchers are important contextual factors that are an accepted part of the study design, data collection, and data analysis. These characteristics and perspectives may explain how the researcher(s) obtained access to the site or participants included in the study or may add valuable insight during data analysis.\nTo demonstrate reflexivity, authors should describe important personal characteristics and perspectives of members of the research team that may influence design, data collection, and data analysis. Relevant personal characteristics might include cultural background, occupation, experience, training, position/ power dynamics, gender, race/ethnicity, and sponsoring institution. Authors should also describe the perspectives, assumptions, prior knowledge, preliminary hypotheses, and/or motives (the “stance”) of the members of the research team.\nAuthors also should describe the researchers’ relationships to participants in the study and what decisions were made in light of these relationships. For example, were any members of the research team part of the sample of potential participants in the study? Do any members of the team teach, supervise, or have any authority over participants in the study? If so, how do these characteristics influence choices about their roles in data collection and analysis? For observational research (e.g., ethnography), it is also important to identify the role of the researcher along a spectrum from passive observer (no involvement in the activity studied) to participant-observer (ranging from some limited involvement in the activity to full involvement).\nThere is no expectation that the study could be precisely replicated; these characteristics and perspectives of the researcher should not be mentioned in the limitation section. (See also Item 14.)\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nReflexivity was maintained by the research team through the analysis and writing by recording, discussing and challenging established assumptions. In addition both EH and SV kept reflexive diaries.\n\n\nThe first author conducted all interviews and discussion groups. Her own medical undergraduate training took place between 1995 and 2000. She was not known to the participants of this research prior to undertaking the study and deliberately did not undertake any clinical or teaching activities locally alongside this research. Whilst it was useful to ‘know’ (from her own background) what the students were talking about medically (and in terms of detecting items of significance), as a researcher she made conscious efforts not to accept potentially common assumptions at face value.\n\n\n\n\n\n\n7. Context\n\n\n\n\n\n\n\nSetting/site and salient contextual factors; rationale.\nThe authors should describe the setting/site(s) in which the study was conducted, the reason(s) why the setting/site(s) was selected, and the salient cultural, political, historical, economic and/or other external factors that influence the study. This information helps readers interpret the meaning and significance of the study findings by situating them in social, cultural, temporal and other relevant contexts. Additional context may be reported with findings (i.e., the Results section) to add evidence for interpretations and to enhance discussion of transferability.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExample\n\nWe conducted the study among hospital-based clinical teachers of students in years 4 to 6 of a six-year undergraduate medical program at Maastricht University Medical School. Years 4 to 6 are devoted to clerkships in the academic hospital and affiliated regional hospitals. Rotations differ in duration depending on the type of rotation and the discipline, and the sequence of rotations differs among students. During rotations, students spend time in the wards, the outpatient clinics, and the accident and emergency department. Clerkships in years 4 and 5 last between 4 and 10 weeks (“regular clerkship”), whereas students in year 6 undertake an 18-week “senior clerkship” in a discipline of their choice.\n\n\n\n\n\n\n8. Sampling strategy\n\n\n\n\n\n\n\nHow and why research participants, documents, or events were selected; criteria for deciding when no further sampling was necessary (e.g., sampling saturation); rationale.\nThe authors should describe how and why research participants, documents, and/or events were selected for inclusion in (and, if appropriate, exclusion from) the study, along with a justification for this strategy. We recommend that authors describe the sampling strategy rather than simply labeling the strategy (e.g., “purposive” or “snowball”), since such labels do not have a universally accepted definition and, more importantly, since procedures tend to be study- specific. Several sampling strategies are commonly used in qualitative research, although most fall under the umbrella of purposeful (or purposive) sampling. Purposeful sampling means that participants, documents, or events are selected for their relevance to the research question, based on guiding theory or experiences and assumptions of the researchers. Over the course of the research process, researchers may determine that additional or different participants, documents, or events should be included to address the research question. Other sampling techniques, such as theoretical sampling (seeking examples of theoretical constructs), snowball sampling (using study participants to identify additional participants who meet study criteria), and convenience sampling (including any volunteers with no or minimal criteria for inclusion) may be appropriate depending on the question and approach, so long as the authors provide explanation and justification.\nAlthough investigators often do not determine sample size a priori in qualitative research, they should nonetheless describe how they established the final sample size. When appropriate (e.g., when a flexible sampling strategy was used), they should explain the criteria used to decide when no further sampling was necessary. If data collection ends at the point when the researchers determine that “saturation” has been reached, then the specific criteria used to define saturation should be described.\nProcedures used to recruit participants should also be described, including who was involved in recruitment, what their relationship was to participants, how and when recruitment occurred, and why these procedures were selected. (See also Item 6)\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nAs students’ perceptions were previously shown to be related to gender, age, prior experience and place of attachment,[REF] we purposely selected respondents with different backgrounds. This sampling strategy led to the diversity of gender, age, prior patient experience and place of attachment shown in Table 1.\n\n\nPurposive sampling was directed towards achieving maximum variation in age and specialty, using a snowball approach (‘a non-probabilistic form of sampling in which persons initially chosen for the sample are used as informants to locate other persons having necessary characteristics making them eligible for the sample’).[REF ]\n\n\nPotential participants were all medical students in Years 1 and 2 at the University of Toronto in 2004. Following research ethics board approval, recruitment was conducted via e- mail to class listservs. Participant responses were sent directly to the research assistant, who was unknown to participants, so that the principal investigators did not know who did or did not participate. This process was engaged to protect participants’ anonymity and to avoid any impression of coercion because the lead researcher (SG) was involved in the administration of the undergraduate curriculum at the time. Sample size was estimated to be sufficient based on the principle of theoretical saturation [REF] and our previous experience with this methodology (i.e., with a relatively homogeneous population, we expected to reach saturation with approximately 15 interviews per group). There were no exclusion criteria and we accepted the first 15 students from each class who volunteered.\n\n\n\n\n\n\n9. Ethical issues pertaining to human subjects\n\n\n\n\n\n\n\nDocumentation of approval by an appropriate ethics review board and participant consent, or explanation for lack thereof; other confidentiality and data security issues.\nQualitative research often involves interaction between researchers and research participants. Correspondingly, researchers should ensure that participants are fully aware of their participation in a research study, the risks and benefits associated with the study, the steps and precautions the researchers will take to minimize risks, such as loss of privacy and confidentiality, and how the researchers plan to use the data. Authors should report approval for the study from an appropriate institutional review board for research associated with human subjects. They should describe procedures used to protect participants, including data collection (e.g., recruitment and informed consent) analysis (e.g., data security and integrity) and reporting of findings (e.g., anonymization of excerpts). If researchers provided compensation or offered incentives to facilitate participation, this should be reported.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nEthical approval was granted by the University of Otago and student participants were invited to attend each focus group discussion by the university representatives of New Zealand Medical Students Association (NZMSA). Usually, a key concern when collecting data from students is that students may feel vulnerable when sharing their experiences with academic staff during a focus group discussion. However, this potential harm was removed as each group discussion was facilitated by a fellow student, the discussions were transcribed by a professional transcribing service, and only the primary researchers [Names] had access to the raw data.\n\n\n\n\n\n\n10. Data collection methods\n\n\n\n\n\n\n\nTypes of data collected; details of data collection procedures including (as appropriate) start and stop dates of data collection and analysis, iterative process, triangulation of sources/methods, and modification of procedures in response to evolving study findings; rationale.\nQualitative research encompasses an array of data collection methods appropriate for various paradigms and approaches, including (but not limited to) interviews, focus groups, observations (direct or indirect via video), and review of written text, photographs, and other documents or materials. Researchers may choose to use information from multiple sources, contexts, and/or time points depending on their approach and research question(s). (See Item 11 for triangulation.) Given this diversity of methods, authors should describe in detail their data collection design and method(s) and justify them in relation to the research question(s), paradigm, approach, and other methods. Methods used to decide when to end data collection should also be described (see Item 8).\nQualitative research often occurs as an iterative process, meaning that researchers begin data analysis before they complete data collection. The data collection and analysis process may occur in phases or stages, and thus authors must clearly describe the iterative process of data collection and analysis. As part of an iterative collection-analysis process, researchers will often alter their data collection methods to explore their preliminary impressions in greater depth and/or actively pursue confirming and disconfirming perspectives. If such changes occur during the research process, authors should describe how and why study procedures changed in response to evolving study findings.\nThe study period (start and end dates for data collection and analysis) should be identified so that readers can place the study in temporal context and identify factors not mentioned by the authors that might affect findings, interpretation, and implications. (See Item 8 for ending data collection.)\nAuthors should describe important characteristics of the individuals conducting interviews, observations or focus groups, and methods used to train these individuals. This information clarifies the relationship between the individuals involved in data collection and the participants in the research and also explains what efforts were made to ensure consistency in the data collection process (See Items 6 and 15.)\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nFurther, it was decided that group interviews, also known as focus group discussions would be the best means of data collection. This is a method of data collection that enables group members to feed off each other’s ideas and an effective moderator will maintain group focus whilst at the same time permitting flexibility in the direction those aspects of the discussion might take. [REF]\n\n\nAdjustments to the interview protocol were made according to early experience and information participants had provided (i.e. redundant questions were eliminated; questions were reworded to improve flow and clarity; additional probes were included).\n\n\nFaculty staff were then interviewed individually by a trained study investigator in a 15-minute, semi-structured interview. This sequence was repeated with other video encounters. Table 2 presents examples of interview questions. Each faculty member was interviewed by at least three interviewers over their various interviews. Interviewers were chosen based on their experience in interviewing. All were trained during a half-day meeting to interpret and deliver the interview guide in the same manner in order to elicit information of a consistent type.\n\n\n\n\n\n\n11. Data collection instruments and technologies\n\n\n\n\n\n\n\nDescription of instruments (e.g., interview guides, questionnaires) and devices (e.g., audio recorders) used for data collection; if/how the instrument(s) changed over the course of the study.\nData collection for qualitative research draws upon a variety of instruments or tools, including (but not limited to) interview or focus group guides, observational protocols and prompts for field notes, and data extraction or coding protocols for selection and analysis of documents, photographs, videos, or other artifacts. The authors should describe all such instruments, guides, and protocols, including their development and cite relevant literatures, theories or conceptual frameworks as appropriate. It is often helpful for authors to provide access to the data collection instrument(s) or a detailed description of them.\nThe authors should also describe the use of equipment for audio or video recording, reproduction of paper documents or computer files, or other processes in data collection. This is relevant so readers understand the full context in which data collection occurred and how this context might have affected data collection (e.g., the influence of recording devices on participants’ behaviors; the nature of inferences drawn from live vs. recorded events).\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nTo facilitate the discussion and to maintain consistency over different sets of discussions, key trigger questions were devised prior to the discussion. The opening trigger question was: ‘Thinking back to some of your best clinical learning placements in 4th and 5th year. What was it about those clinical placements that provided good opportunities for learning?’\n\n\nInterviews included discussion of the expectations, processes and consequences of AEE [authentic early experiences]. The interview schedule was derived following identification of questions that could not be fully answered in a systematic review of previous empirical or theoretical literature. It comprised a sequence of topic areas including experiences in action, and areas of frustration in Medical Education such as the learning of content knowledge, achieving functional knowledge, and transfer of knowledge.[REF]… Interested readers can request a copy of the schedules from the corresponding author. Interviews lasted between 20 and 90 min. and discussion groups between 60 and 90 min. All interviews and discussion groups were conducted in private rooms at the participant’s workplace—the medical school for students and faculty, and individual places of work for workplace supervisors (except for one who chose to be interviewed at the medical school). All data were audio-recorded, and transcribed verbatim.\n\n\n\n\n\n\n12. Units of study\n\n\n\n\n\n\n\nNumber and relevant characteristics of participants, documents, or events included in the study; level of participation.\nAuthors should describe the participants, documents, or events included in the study (the units of study). The sampling item (Item 8) describes the target or ideal participants, documents, or events selected for the study. By contrast, Item 12 focuses on description of the actual participants, documents or events included in the study. Authors should describe how the actual participants, documents, or events differ from the targeted sample, why these differences may have occurred, and how this might affect the findings.\nAuthors should describe characteristics of the participants, documents or events that are relevant to the study purpose and research question(s).1 For participants, this might include age, gender, profession, institution, year of training, or relationship to the researcher and/or other participants in the study. For documents, this might include the source, intended audience, date, or type of document. For events, this might include the location, date(s), length, characteristics of attendees or participants in the event, or mood or emotional climate. If the degree of participation varied among individuals (e.g., multiple occasions; interviews and observations), the authors should describe different levels of participation. For example, if some participants were observed and interviewed and others only interviewed, or if some participants completed multiple interviews and others completed a single interview, these variations should be explained. Authors should also explain the reasons for these differences (i.e., the researchers’ choice or the participants’ preferences) and how these different levels of participation were taken into account in the analysis. Authors should also include the dates or timeframe for participation.\nThis information about participants could appear in the Methods section as part of the description of the sample, or at the beginning of the Results section to provide context for the findings presented.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExample\n\nOf the 70 Mindful Communication program participants, 46 met the eligibility requirements to participate in the in-depth interviews. We randomly chose and then contacted 22 participants, of whom 20 agreed to be interviewed within six months of completing the program: 15 in person and 5 by telephone. Two declined for lack of time. On reaching saturation after 20 interviews, no further attempts to contact the remaining 24 participants were made.\n\n\n\n\n\nThere were 31 nursing handovers covering 137 patients, and 21 resident handovers covering 101 patients included in this study.\n\n\n\n\n\n\n13. Data processing\n\n\n\n\n\n\n\nMethods for processing data prior to and during analysis, including transcription, data entry, data management and security, verification of data integrity, data coding and anonymization / de-identification of excerpts.\nAuthors should describe the ways in which data are prepared for analysis and managed throughout the analysis process. These activities might include transcription, coding, data entry, and organization of data. When processing audio or video recordings, relevant details might include indication of verbatim transcription of dialogue, additional notes to capture non- verbal information (especially for group interviews or focus groups), and annotations to indicate vocal inflections and utterances, as appropriate for the analytic approach. Authors should also describe procedures used to check transcripts for accuracy.\nAuthors should describe the processes used to organize, compile, and categorize data (e.g., field notes, transcripts, documents, photographs, artifacts) for analysis.\nAuthors should describe procedures used to maintain data security and protect the privacy of participants, as specified in the human subjects protocols. For example, if data are anonymized, the authors should explain how and at what point in the process this occurred. Authors may choose to use anonymous labels or identifiers to represent quotes or excerpts from unique participants, documents or events, in order to reflect the variety of sources from which such data were derived.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nInterviews were anonymised and each participant was given a code number.\n\n\nThe interviewers and another member of the research team (H.B.) reviewed transcripts for accuracy.\n\n\nWe collected data throughout the admission process through direct observation, audio- recording, and chart extraction. We audio-recorded, transcribed, and anonymized both the overnight and morning case review discussions. We also observed the morning case review discussions in person and collected field notes. For each case review discussion, we copied the admission notes from the patient’s record and de-identified all data.\n\n\n\n\n\n\n14. Data analysis\n\n\n\n\n\n\n\nProcess by which inferences, themes, etc. were identified and developed, including the researchers involved in data analysis; usually references a specific paradigm or approach; rationale.\nTechniques used for data analysis will depend on the paradigm, approach, and/or data collection methods selected by the researchers. Correspondingly, authors should be as transparent as possible about the analytic process so that readers can follow the logic of inquiry from the research question(s) to the analysis and findings. For example, this description may involve characterizing the processes and decisions made for initial classification or segmentation of data, pattern identification and description, and/or development of in-depth interpretations.1 If the researchers used an approach that has a well-defined process for data analysis (e.g., grounded theory, discourse analysis, phenomenography), the authors should cite the guiding literature and describe their processes in sufficient detail so readers can judge the extent to which the processes align with the guiding approach. If modification to or deviations from the guiding approach occurred, the authors should explain and justify these modifications.\nAuthors should specify the unit of analysis.1 In qualitative research, the unit of analysis is not necessarily the same as the unit of sampling (e.g., individual participants or events). Instead, some approaches use specific events as the unit of analysis, such as mentions of a particular topic or experience, or observations of a particular behavior or phenomenon, while others use groups rather than individual group participants. This specification has implications for how the data are organized and analyzed as well as the inferences drawn from the data.\nAuthors should explain the rationale underlying different decisions made throughout the data analysis process to provide as much transparency as possible. In some approaches researchers use memoing or bracketing to make their reflections, interpretations, and links among passages explicit and more transparent to others. In some types of analysis, participants’ perspectives or observations that contrast or deviate from the concepts or themes identified by the researchers are an important part of the analysis. In such cases, the authors must describe how these discrepancies were handled during the analysis.\nDuring the analysis process, researchers may draw upon a theoretical perspective or framework, which may have been identified early in the conception of the study or may be identified by the researchers after reviewing some or all of their data. Either way, the authors should describe theoretical or other influences on their analysis scheme or categories if they exist. Sometimes these are referred to as “sensitizing concepts” to acknowledge that the approach is inductive, but with influence from relevant theory, models, or organizational schemes. Alternatively, themes may be developed from the data with no external influences.\nAuthors should describe which members of the research team are involved in data analysis and what perspective(s) they bring to the analysis. Authors should also indicate if any software was used to assist with data analysis and how it was used (e.g., used to apply codes after the final coding scheme was developed; to extract coded passages for further synthesis and identification of themes; or to identify passages with key words). Simply stating that software was used is insufficient.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\n…we brought sensitizing concepts to the analysis while we conducted an open, inductive analysis.[REF]In this case the sensitizing concepts arose, a priori to analysis, from a framework derived from the literature [REF] (as described above), in which participants’ motivations to act are based on principles of professionalism, internal affect, or potential implications of their actions.[REF]\n\n\nThrough an iterative process of listening, discussing, and relistening, the team identified and consensually validated emerging themes[REF] and appended segments of dialogue supporting the proposed themes. Recruitment stopped when saturation was reached (no new themes were identified). The team systematically reviewed the themes and sorted them into content domains. The team used an analytic matrix to identify patterns and connections amongst the domains. Two of us not involved in the qualitative coding process (R.E., M.K.) audited the analytic matrix, choice of quotes, and thematic analysis.\n\n\nThe analysis started after the first interview. All data were analyzed with the aid of the audio- coding facility of the NVivo 8: QSR International Pty Ltd, Doncaster, Vic, Australia programme. First, [name] and [name] coded independently from one another, making sure to stay semantically close to the participants’ wording. Then we discussed these open codes and defined axial codes.[REF] New insights about the impact of CST were written down in memos.\n\n\nVideotapes were analysed using immersion/crystallisation methods of qualitative data analysis.[REF] With no pre-existing framework developed in advance for analysis, an inductive approach was used to discover patterns of NVB in the data. A team of six researchers met weekly for 18 months to view videos together. Using a consensus-building approach based on a combination of field notes, ‘opportunistic’ interviews with the participants, and repeated viewing of the same material, sometimes many months apart, we eventually achieved consensus on verbal, non-verbal, and physical themes and patterns observed in the data. Finally, as a test of ‘goodness-of-fit,’ we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\n\nAll transcripts were coded thematically by four of the five authors, who met regularly to identify areas of convergence until full agreement was reached. One of the interviewers (P.M.) maintained an audit trail to track the team’s developing thinking. A process of dialectical empiricism[REF] was used to categorise the emergent themes into more abstract concepts…\n\n\n\n\n\n\n15. Techniques to enhance trustworthiness\n\n\n\n\n\n\n\nTechniques to enhance trustworthiness and credibility of data analysis,(e.g., member checking, triangulation, audit trail); rationale.\nAuthors should describe methods used to ensure trustworthiness and credibility throughout the data collection and analysis process. Such methods will depend on the paradigm, approach, and/or methods used. Correspondingly, the authors should explain their choice of techniques and why these are appropriate for the particular study.\nCommonly used techniques to enhance trustworthiness include: member checking; triangulation of data sources, methods, and/or researchers; creation of an explicit audit trail; and immersion in the site of data collection for an extended period of time (especially for research in which an observer’s presence is likely to disrupt the phenomenon under investigation). Member checking involves sharing findings, such as descriptions of key phenomena, themes, or an explanatory model, with participants and asking them to verify the accuracy or resonance with their perspectives. Triangulation involves using more than one data source, method, or researcher to add diverse perspectives on the findings of the study and, in some approaches, to test the transferability or generalizability of a model. An audit trail involves careful documentation of all decisions made throughout the study, from initial conceptualization to study design, sampling, analysis, and reporting, to provide transparency and to enable an external researcher to review all the steps involved in the study.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\nMember checking\n\nMember checks [REF] with an external TBL expert (R.L.) supported the validity of these analyses.\n\nTriangulation of data types and data sources\n\nThe interview data were triangulated with the data of 11 student and supervisor focus groups of a previous study, and more specifically, with those data that concern in particular the influence of CST [Communication Skills Training] on the development of patient-centredness…. Triangulation with the focus group data allowed us to broaden the in-depth information from the interviews in the analysis and to ‘share and compare’ this with information from students and doctors with varying levels of CST (no, limited, full programme) and from two universities (Universities of Antwerp and Ghent). Moreover, this enabled us to better explore the evolution over time, given that the focus groups included participants at different stages of their study: before clerkships (year 4, undergraduate), during clerkships (year 6, undergraduate), after clerkships (year 7, undergraduate) and postgraduate (general practice trainees, and supervising specialists and GPs; Table 1).\n\n\n\n\n\nFinally, as a test of ‘goodness-of-fit’, we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\nTriangulation of Researchers + Audit trail\n\nTo ensure rigor and increase authenticity in our methodology, we used two kinds of triangulation—investigator triangulation and data triangulation.[REF] We sought analytical rigor using an audit trail and multiple coders; our coding team included an experienced clinician (M.G.) as well as a nonclinician with expertise in medical communication and team dynamics (L.L.).\n\n\n\n\n\n\nResults\n\n\n16. Synthesis and interpretation\n\n\n\n\n\n\n\nMain findings (e.g., interpretations, inferences, and themes); might include development of a theory or model, or integration with prior research or theory.\nIn qualitative research the distinction between results and discussion tends to blur because analysis often involves interpretation, inference, and synthesis. Although most journals require separate sections for Results and Discussion, many elements of Items 16-19 could reasonably be reported in either section. As such, we defer to authors and editors to determine where to report these essential elements.\nAuthors should identify the main analytic findings (e.g., interpretations, inferences, narratives, themes, models). The nature of these findings and how they are reported will depend on the approach and methodology selected and thus should be in alignment with the approach and methods.\nIn most cases, the authors should report a synthesis of their data along with specific quotes, examples, or illustrations derived from their data. Authors might also report frequency, variety, representativeness, counter-examples, concrete details, contextualization, conditions, and qualifications related to their findings. Frequency counts (e.g., the frequency of specific themes or codes) play a limited role in qualitative research, and need not be reported unless they play a meaningful role in interpretation of the data.\nFindings might also include integration with prior literature or theory and/or the development of a theory, model or meta-narrative. Judicious use of tables and figures can help communicate such findings.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nWe identified four patterns of NVB (non-verbal behavior) that relate to handover quality and have dubbed them: (1) joint focus of attention; (2) ‘the poker hand’; (3) parallel play; and (4) kerbside consultation. Each pattern constitutes a ‘transfix,’ or systematic way of participating non-verbally in the care transfer process. And, although there are variations in each pattern, we have been able to code virtually every handover we have observed in nursing, medicine and surgery into one of these four categories.\n\n\nBecause our participants came from similar educational backgrounds, had studied medicine as their tertiary course, were embedded in the culture of medicine, and were associated in meaningful ways with a single medical school, we approached their transcripts with the assumption that they belonged to a loosely formed discourse community. Although their graduation dates ranged over a period of 50 years and their collective sphere of practice included 10 different specialty areas, there were many similarities in their experiences of enculturation during and after medical school.\n\n\nTheir three major (often overlapping) areas of concern were epistemic (acquiring knowledge and skill), interpersonal (relating to patients, families, colleagues and administrators) and personal (achieving work–life balance). In each of these areas, medical enculturation was achieved by two overlapping processes, ‘absorption’ and ‘assimilation’, each of which may have distinct implications for postgraduate medical education.\n\n\n\n\n\n\n17. Links to empirical data\n\n\n\n\n\n\n\nEvidence (e.g., quotes, field notes, text excerpts, photographs) to substantiate analytic findings.\nThe authors should provide evidence (e.g., quotes, field notes, text excerpts, photographs) to substantiate the more general and abstract concepts or inferences they present as findings. Such evidence is typically de-identified to protect the privacy of study participants, settings, and/or institutions. The evidence may be presented in a variety of ways such as in a table or figure, incorporated into a narrative description of findings, as a stand-alone narrative, or in text blocks embedded in the manuscript text. If word limits or media limitations (e.g.. video) limit the authors’ ability to provide sufficient representation of supporting data, an appendix, supplemental material, or web-based repository could be used to provide access to additional data.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\nSee Frankel et al. for an excellent example of how to use photographs (or snapshots from video) to illustrate and provide supporting evidence for patterns of behavior identified in the analysis. http://qualitysafety.bmj.com/content/21/Suppl_1/i121.\n\nWe identified five interruption types: (1) probing for further data, (2) prompting for expected sequence, (3) teaching around the case, (4) thinking out loud, and (5) providing direction (see Table 1). Several interruption types served both goals of the case review discussions—teaching and patient care. For example, when thinking out loud, supervisors reasoned through problems and taught the team: “So that’s the big question, did she have a mechanical fall, or did she have a medicine-related fall?” (Case 2). Supervisors prompted for expected sequence, preventing presenters from skipping over information while simultaneously allowing the supervisor to instruct the team on presentation style: “So now you can tell me what the rest of his test results are because I haven’t heard those” (Case 16).\n\n\n\n\n\n\nDiscussion\n\n\n18. Integration with prior work, implications, transferability, and contribution(s) to the field\n\n\n\n\n\n\n\nShort summary of main findings, explanation of how findings and conclusions connect to, support, elaborate on, or challenge conclusions of earlier scholarship; discussion of scope of application/generalizability; identification of unique contribution(s) to scholarship in a discipline or field.\nThe authors should begin the Discussion with a short summary of the main findings. The short summary reminds readers of the main findings and may help them assess whether the subsequent interpretation and implications formulated by the authors are supported by the findings.\nThe authors’ description of their findings or results should include some interpretation of the data in the context of previous findings, experiences, theory, or a guiding paradigm or approach. The discussion provides authors an opportunity to elaborate on their findings in relation to their research question(s) and study purpose(s); connect their findings to prior empirical work, theories, and/or frameworks; and discuss implications. The authors should explicitly describe how their findings contribute to or advance the field. Implications may include transferability, or specifying the appropriate scope for generalization of the findings beyond the study (e.g., to other settings, populations, time periods, circumstances).\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExamples\n\nThis study contributes to the understanding and discussion of the complexity of involving patients in healthcare education. It shows that integrating patient-led teaching into initiatives that are partly faculty-led influences the way in which students perceive learning from and with PIs. What is not known, however, is whether perceptions are also affected by type of health profession and the students’ different orientation towards logics of care and science, and issues of authority and power relations.\n\nFor complete examples of Discussions, see:\n\nHenriksen & Ringsted, 2013\nWesterman et al., 2013.\n\n\n\n\n\n\n19. Limitations\n\n\n\n\n\n\n\nTrustworthiness and limitations of findings\nAuthors should describe techniques used to ensure trustworthiness in the Methods section of the manuscript. In the Discussion, authors should identify problems or gaps in their efforts to ensure trustworthiness and the potential implications. For example, if researchers intended to interview individuals with certain characteristics, or who might offer different perspectives, but were unsuccessful in recruiting any willing participants, they should explain this issue and describe possible consequences for transferability. (See also Item 18.)\nAll research paradigms and approaches have strengths and weaknesses, and authors should explicitly discuss how the paradigm, approach, and methods they used will influence the situations to which their findings may reasonably apply. (See also Item 18.) In addition, they should explain how specific decisions or events in the conduct of the study strengthen or weaken the rigor of their findings.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nExample\n\nThe study has several limitations. One is that the focus group interview method reveals students’ perceptions rather than their actual behaviors. Observations of the patient-led teaching encounter may have illuminated an understanding of the relationship between patient instructors and medical students. Another limitation is that the PI-led teaching is optional rather than mandatory, which may have influenced students’ attitudes in a positive direction. Moreover, students who are eager to take on extra-curricular activities may not be representative of the whole population. That only 23 out of 39 students signed up for this study might also have influenced results if the missing group of students represented other perceptions than those present in the focus groups. However the received data from the focus groups were rich in information and diverse perceptions were present. Another limitation is the overrepresentation of women over men in our sample. Even though women are also overrepresented in medical school this might potentially have influenced results, but gender differences in perceptions were nevertheless not identified in the data.\n\n\n\n\n\n\nOther\n\n\n20. Conflicts of interest\n\n\n\n\n\n\n\nPotential sources of influence or perceived influence on study conduct and conclusions; how these were managed.\nAuthors should identify any real or potential conflicts of interest that might have influenced or could appear to have influenced the research. Authors should also explain how these conflicts were managed in the conduct of the study, and describe the potential impact on study findings and/or conclusions. Some aspects may be mentioned as part of reflexivity (see Item 6).\n\n\n21. Funding\n\n\n\n\n\n\n\nSources of funding and other support; role of funders in data collection, interpretation, and reporting.\nThe authors should describe any sources of funding and other support for the study and the role of funders in data collection, data analysis, and reporting if applicable.\n\n\n\nEthnography\n\n\n\n\n\n\nOccaecat mollit deserunt excepteur consectetur proident. Anim Lorem ipsum anim nisi velit magna duis Lorem consequat aliquip eu ullamco consequat amet. Magna labore in consequat ad aliquip Lorem elit do in. Esse minim consectetur ut commodo sunt cupidatat voluptate sint voluptate nisi.\nExercitation eu mollit consequat ipsum non ullamco. Velit velit dolor cupidatat proident in laboris eiusmod incididunt mollit nisi laborum minim. Eiusmod et voluptate veniam exercitation sit ex labore.\nLearn more\n\n\n\n\n\n\nGrounded theory\n\n\n\n\n\n\nEt eu labore qui non dolore nulla. Ipsum aliqua laboris commodo deserunt cillum excepteur dolore adipisicing occaecat nostrud anim elit officia amet. Commodo incididunt ad et velit do minim dolore. Ullamco eiusmod Lorem proident tempor laborum nulla incididunt non pariatur irure officia ad. Elit deserunt commodo laboris adipisicing duis amet et dolore nulla nostrud. Nostrud excepteur exercitation elit consequat consequat.\n\n\n\n\n\n\nInterview\n\n\n\n\n\n\nNon exercitation commodo incididunt tempor veniam magna excepteur est reprehenderit Lorem. Exercitation enim et quis velit pariatur mollit fugiat dolore ullamco eu eu. Do ullamco eu culpa sint ad est. Proident veniam sint eu cupidatat minim voluptate officia anim laborum qui aliqua. Enim minim non mollit elit ipsum fugiat dolore cupidatat. Magna adipisicing labore do dolor voluptate non ipsum sint eiusmod aute proident proident ullamco. Excepteur cupidatat occaecat enim culpa cillum laboris ex incididunt officia.\n\n\n\n\n\n\nFocus group\n\n\n\n\n\n\nCommodo commodo labore eu laboris commodo excepteur eu et id deserunt enim id minim cupidatat. Fugiat deserunt eiusmod eiusmod culpa velit dolore ex voluptate anim pariatur. Nostrud cillum cillum culpa exercitation. Labore laboris ex commodo nostrud excepteur eiusmod veniam in esse est exercitation Lorem proident dolor. Labore aliqua fugiat id qui sit qui sit aliquip incididunt labore irure Lorem voluptate. Eiusmod ea ex ea cillum exercitation laboris laborum incididunt labore. Ea officia aliqua id velit nostrud velit amet.\n\n\n\n\n\n\nGeneral inductive\n\n\n\n\n\n\nLaboris ea eu elit irure ex reprehenderit sunt commodo non eiusmod tempor. Eiusmod occaecat mollit consequat dolore voluptate officia exercitation voluptate velit nostrud duis ad consectetur. Magna magna in occaecat nostrud tempor tempor incididunt commodo officia reprehenderit irure aliqua.\n\n\n\n\n\n\nContext\n\n\n\n\n\n\nEiusmod sit cillum sint duis mollit non amet consectetur minim in sunt aliquip laboris ipsum. Culpa ullamco laborum et veniam laborum anim ut aliqua dolore. Aliquip dolore sit tempor velit officia. Aute do nostrud reprehenderit pariatur sint qui. Occaecat consequat ut et sint. Officia aliquip non minim do est minim.\n\n\n\n\n\n\nSetting\n\n\n\n\n\n\nExercitation consectetur ipsum sit sit magna nostrud do commodo aute ad. Elit ea ea aliqua eu commodo. Enim est pariatur tempor non exercitation officia aliquip ut veniam laborum. Eu ea aliqua laborum elit voluptate officia ex ipsum amet.\n\n\n\n\n\n\nSample\n\n\n\n\n\n\nEst irure ipsum laborum ad consectetur. Incididunt dolor duis excepteur proident. Ut ullamco amet aliqua sint fugiat exercitation amet anim magna dolor ullamco. Officia dolore dolore ad laborum. Dolore reprehenderit non deserunt dolore voluptate in Lorem nulla laborum ipsum occaecat eiusmod. Incididunt minim magna sint non veniam incididunt sint consectetur amet qui. Voluptate enim deserunt Lorem proident reprehenderit mollit magna adipisicing reprehenderit laboris nisi qui cupidatat id.\n\n\n\n\n\n\nThemes\n\n\n\n\n\n\nEt et aliquip elit aliquip cillum. Mollit enim ullamco ea ullamco eu ex officia ut culpa cillum laborum ad. Nulla id mollit magna deserunt deserunt eu. Qui esse sint fugiat excepteur consectetur velit incididunt aliquip labore consequat aute Lorem laboris. Cupidatat irure ex minim adipisicing commodo Lorem elit. Sit fugiat dolor dolore pariatur exercitation in duis nostrud cillum id magna non tempor. Duis reprehenderit ex cupidatat reprehenderit duis cillum.\n\n\n\n\n\n\nInferences\n\n\n\n\n\n\nOccaecat qui non aute ut quis aliqua ut sint ipsum enim Lorem. Laborum nostrud esse voluptate dolore exercitation. Excepteur pariatur id pariatur ullamco ea esse do. Aute aute minim veniam reprehenderit id enim aliqua dolor ullamco. Sit tempor nostrud tempor minim. Qui irure laborum consectetur duis do quis laboris eiusmod consequat.\n\n\n\n\n\n\nPositivist\n\n\n\n\n\n\nTempor aliquip minim commodo nisi et aliqua ea mollit esse. Tempor aute consequat exercitation excepteur et. Aliquip dolor duis fugiat incididunt sint ipsum adipisicing eiusmod. Aliqua ea ipsum Lorem amet. Excepteur do dolore commodo veniam Lorem eiusmod cillum cupidatat Lorem minim nulla est ipsum. Eu laboris anim laboris mollit aute quis mollit est duis elit sit voluptate nisi. Amet dolor pariatur dolore culpa.\n\n\n\n\n\n\nPost-positivist\n\n\n\n\n\n\nProident est commodo exercitation ex occaecat ullamco anim ut reprehenderit deserunt dolor voluptate in. Consequat culpa reprehenderit consequat enim dolore officia tempor proident duis eiusmod consequat minim incididunt id. Ad proident qui aute ea.\n\n\n\n\n\n\nConstructs\n\n\n\n\n\n\nId sunt enim dolore nostrud laboris quis quis sint anim ullamco et ut proident. Ipsum pariatur sit eu quis irure eiusmod quis adipisicing velit cillum sit reprehenderit enim. Quis magna sint officia irure cillum irure est. Nostrud nostrud enim commodo magna mollit et eu amet mollit occaecat amet.\n\n\n\n\n\n\nCase study\n\n\n\n\n\n\nLaboris quis ad laboris eu amet. Deserunt enim ad do aliqua qui labore. Anim aute esse fugiat labore reprehenderit quis et eiusmod. Dolore consequat sunt consequat veniam qui nisi magna qui non amet eu. Aute nulla anim culpa enim magna amet adipisicing. Ea eu officia minim minim duis ea reprehenderit Lorem ullamco. Minim et aliqua amet id proident est eiusmod.\n\n\n\n\n\n\nPhenomenology\n\n\n\n\n\n\nEnim ea voluptate ad dolore et commodo in id eiusmod ea. Irure culpa pariatur veniam culpa velit Lorem exercitation ea ut nulla minim non esse reprehenderit. Ipsum do cupidatat culpa ipsum in ea consequat. Dolor sint laborum proident labore nulla fugiat esse sit enim irure anim. Id ex proident et tempor enim est nostrud. Ullamco ex do irure amet proident nulla proident non exercitation esse ullamco est dolor. Exercitation proident mollit nostrud dolore reprehenderit nostrud officia in magna eiusmod.\n\n\n\n\n\n\nNarrative research\n\n\n\n\n\n\nNisi pariatur in sunt est anim sit sint cillum occaecat ut enim commodo amet ullamco. Lorem nulla ut in nulla. Nisi aute cillum ad duis aliqua commodo velit incididunt aliquip.\n\n\n\n\n\n\nConstructivist\n\n\n\n\n\n\nNulla fugiat labore voluptate velit ipsum elit velit nulla laborum cillum minim. Esse laboris adipisicing proident non ipsum adipisicing consequat do do proident ea. Irure minim fugiat proident irure adipisicing. Ea ad consectetur fugiat qui id consectetur nostrud amet elit sit non cupidatat laboris nostrud. Est officia velit sit fugiat ut pariatur consequat incididunt in velit nulla do proident. Reprehenderit pariatur adipisicing mollit mollit consectetur. Lorem consectetur nisi est aute reprehenderit elit amet et deserunt sit pariatur sunt dolore excepteur.\n\n\n\n\n\n\nInterpretivist\n\n\n\n\n\n\nMinim ad fugiat ex magna occaecat nostrud officia est dolor duis tempor quis. Voluptate dolore dolore labore irure ipsum esse do labore excepteur est elit. Excepteur irure veniam cillum sit est aliqua occaecat sunt eu dolor dolor. Adipisicing est mollit aute consequat proident adipisicing minim est ad. Duis cupidatat est enim ex labore sit eu pariatur."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-title-1",
    "href": "guidelines/SRQR-1/index.html#sec-title-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nResidents learning from a narrative experience with dying patients: a qualitative study.\n\n\nMedical students’ perceptions of the factors influencing their academic performance: an exploratory interview study with high-achieving and re-sitting medical students.\n\n\nUndergraduate rural medical education program development: focus group consultation with the NRHA Rural Medical Educators Group."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-abstract-1",
    "href": "guidelines/SRQR-1/index.html#sec-abstract-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\nPurpose: Although academic centers rely on assessments from medical trainees regarding the effectiveness of their faculty as teachers, little is known about how trainees conceptualize and approach their role as assessors of their clinical supervisors\nMethod: In 2010, using a constructivist grounded theory approach, five focus group interviews were conducted with 19 residents from an internal medicine residency program. A constant comparative analysis of emergent themes was conducted.\nResults: Residents viewed clinical teaching assessment (CTA) as a time-consuming task with little reward. They reported struggling throughout the academic year to meet their CTA obligations and described several shortcut strategies they used to reduce their burden. Rather than conceptualizing their assessments as a conduit for both formative and summative feedback, residents perceived CTA as useful for the surveillance of clinical supervisors at the extremes of the spectrum of teaching effectiveness. They put the most effort, including the crafting of written comments, into the CTAs of these outliers. Trainees desired greater transparency in the CTA process and were sceptical regarding the anonymity and perceived validity of their faculty appraisals.\nConclusions: Individual and system-based factors conspire to influence postgraduate medical trainees’ motivation for generating high-quality appraisals of clinical teaching. Academic centers need to address these factors if they want to maximize the usefulness of these assessments."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-problem-formulation-1",
    "href": "guidelines/SRQR-1/index.html#sec-problem-formulation-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nRegulatory focus theory may therefore offer insight into the variability in responses to feedback, but how well do these experimental findings translate to real clinical situations in which the reality of responsiveness to feedback seems frustratingly complex? …. In order to better elaborate a theory to account for this variability in learner response to feedback, the present study was undertaken. We aimed, in this study, to determine how readily clinical learning events could be classified as activating a promotion or a prevention focus, and to explore, through a careful analysis of doctors’ descriptions of their feedback experiences, the predictive value of regulatory focus theory in the context of real clinical learning situations."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-purpose-1",
    "href": "guidelines/SRQR-1/index.html#sec-purpose-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nThe purposes of this study were to investigate how medical students recognize, respond to and utilise feedback, and to determine whether there are maturational differences in understandings of the role of feedback across academic years in medical school."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-qualitative-approach-1",
    "href": "guidelines/SRQR-1/index.html#sec-qualitative-approach-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nThe study was performed from a constructivist point of view using an interpretative phenomenological epistemology. Based on the notion that social phenomena are constructed by the communal making of meaning about the underlying phenomena, we aimed to construct insightful accounts of lead consultants’ approaches to educational change, rather than to identify the ‘true’ nature of these approaches. Because the management of change by lead consultants is an under-researched area, we conducted an exploratory qualitative study…\n\n\nGiven the relative dearth of explanatory theories about factors affecting medical students’ emotional reactions, we chose to develop one by applying methods associated with grounded theory, specifically constant comparative analysis, to qualitative data obtained from learning logs and interviews. Our approach was constructivist, deliberately using researchers’ own experiences and acquired knowledge to enhance theoretical sensitivity and enrich theory development."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-researcher-characteristics-and-reflexivity-1",
    "href": "guidelines/SRQR-1/index.html#sec-researcher-characteristics-and-reflexivity-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nReflexivity was maintained by the research team through the analysis and writing by recording, discussing and challenging established assumptions. In addition both EH and SV kept reflexive diaries.\n\n\nThe first author conducted all interviews and discussion groups. Her own medical undergraduate training took place between 1995 and 2000. She was not known to the participants of this research prior to undertaking the study and deliberately did not undertake any clinical or teaching activities locally alongside this research. Whilst it was useful to ‘know’ (from her own background) what the students were talking about medically (and in terms of detecting items of significance), as a researcher she made conscious efforts not to accept potentially common assumptions at face value."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-context-1",
    "href": "guidelines/SRQR-1/index.html#sec-context-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nWe conducted the study among hospital-based clinical teachers of students in years 4 to 6 of a six-year undergraduate medical program at Maastricht University Medical School. Years 4 to 6 are devoted to clerkships in the academic hospital and affiliated regional hospitals. Rotations differ in duration depending on the type of rotation and the discipline, and the sequence of rotations differs among students. During rotations, students spend time in the wards, the outpatient clinics, and the accident and emergency department. Clerkships in years 4 and 5 last between 4 and 10 weeks (“regular clerkship”), whereas students in year 6 undertake an 18-week “senior clerkship” in a discipline of their choice."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-sampling-strategy-1",
    "href": "guidelines/SRQR-1/index.html#sec-sampling-strategy-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nAs students’ perceptions were previously shown to be related to gender, age, prior experience and place of attachment,[REF] we purposely selected respondents with different backgrounds. This sampling strategy led to the diversity of gender, age, prior patient experience and place of attachment shown in Table 1.\n\n\nPurposive sampling was directed towards achieving maximum variation in age and specialty, using a snowball approach (‘a non-probabilistic form of sampling in which persons initially chosen for the sample are used as informants to locate other persons having necessary characteristics making them eligible for the sample’).[REF ]\n\n\nPotential participants were all medical students in Years 1 and 2 at the University of Toronto in 2004. Following research ethics board approval, recruitment was conducted via e- mail to class listservs. Participant responses were sent directly to the research assistant, who was unknown to participants, so that the principal investigators did not know who did or did not participate. This process was engaged to protect participants’ anonymity and to avoid any impression of coercion because the lead researcher (SG) was involved in the administration of the undergraduate curriculum at the time. Sample size was estimated to be sufficient based on the principle of theoretical saturation [REF] and our previous experience with this methodology (i.e., with a relatively homogeneous population, we expected to reach saturation with approximately 15 interviews per group). There were no exclusion criteria and we accepted the first 15 students from each class who volunteered."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-ethics-1",
    "href": "guidelines/SRQR-1/index.html#sec-ethics-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nEthical approval was granted by the University of Otago and student participants were invited to attend each focus group discussion by the university representatives of New Zealand Medical Students Association (NZMSA). Usually, a key concern when collecting data from students is that students may feel vulnerable when sharing their experiences with academic staff during a focus group discussion. However, this potential harm was removed as each group discussion was facilitated by a fellow student, the discussions were transcribed by a professional transcribing service, and only the primary researchers [Names] had access to the raw data."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-data-collection-methods-1",
    "href": "guidelines/SRQR-1/index.html#sec-data-collection-methods-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nFurther, it was decided that group interviews, also known as focus group discussions would be the best means of data collection. This is a method of data collection that enables group members to feed off each other’s ideas and an effective moderator will maintain group focus whilst at the same time permitting flexibility in the direction those aspects of the discussion might take. [REF]\n\n\nAdjustments to the interview protocol were made according to early experience and information participants had provided (i.e. redundant questions were eliminated; questions were reworded to improve flow and clarity; additional probes were included).\n\n\nFaculty staff were then interviewed individually by a trained study investigator in a 15-minute, semi-structured interview. This sequence was repeated with other video encounters. Table 2 presents examples of interview questions. Each faculty member was interviewed by at least three interviewers over their various interviews. Interviewers were chosen based on their experience in interviewing. All were trained during a half-day meeting to interpret and deliver the interview guide in the same manner in order to elicit information of a consistent type."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-data-collection-instruments-1",
    "href": "guidelines/SRQR-1/index.html#sec-data-collection-instruments-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nTo facilitate the discussion and to maintain consistency over different sets of discussions, key trigger questions were devised prior to the discussion. The opening trigger question was: ‘Thinking back to some of your best clinical learning placements in 4th and 5th year. What was it about those clinical placements that provided good opportunities for learning?’\n\n\nInterviews included discussion of the expectations, processes and consequences of AEE [authentic early experiences]. The interview schedule was derived following identification of questions that could not be fully answered in a systematic review of previous empirical or theoretical literature. It comprised a sequence of topic areas including experiences in action, and areas of frustration in Medical Education such as the learning of content knowledge, achieving functional knowledge, and transfer of knowledge.[REF]… Interested readers can request a copy of the schedules from the corresponding author. Interviews lasted between 20 and 90 min. and discussion groups between 60 and 90 min. All interviews and discussion groups were conducted in private rooms at the participant’s workplace—the medical school for students and faculty, and individual places of work for workplace supervisors (except for one who chose to be interviewed at the medical school). All data were audio-recorded, and transcribed verbatim."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-units-of-study-1",
    "href": "guidelines/SRQR-1/index.html#sec-units-of-study-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nOf the 70 Mindful Communication program participants, 46 met the eligibility requirements to participate in the in-depth interviews. We randomly chose and then contacted 22 participants, of whom 20 agreed to be interviewed within six months of completing the program: 15 in person and 5 by telephone. Two declined for lack of time. On reaching saturation after 20 interviews, no further attempts to contact the remaining 24 participants were made.\n\n\n\n\n\nThere were 31 nursing handovers covering 137 patients, and 21 resident handovers covering 101 patients included in this study."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-data-processing-1",
    "href": "guidelines/SRQR-1/index.html#sec-data-processing-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nInterviews were anonymised and each participant was given a code number.\n\n\nThe interviewers and another member of the research team (H.B.) reviewed transcripts for accuracy.\n\n\nWe collected data throughout the admission process through direct observation, audio- recording, and chart extraction. We audio-recorded, transcribed, and anonymized both the overnight and morning case review discussions. We also observed the morning case review discussions in person and collected field notes. For each case review discussion, we copied the admission notes from the patient’s record and de-identified all data."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-data-analysis-1",
    "href": "guidelines/SRQR-1/index.html#sec-data-analysis-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\n…we brought sensitizing concepts to the analysis while we conducted an open, inductive analysis.[REF]In this case the sensitizing concepts arose, a priori to analysis, from a framework derived from the literature [REF] (as described above), in which participants’ motivations to act are based on principles of professionalism, internal affect, or potential implications of their actions.[REF]\n\n\nThrough an iterative process of listening, discussing, and relistening, the team identified and consensually validated emerging themes[REF] and appended segments of dialogue supporting the proposed themes. Recruitment stopped when saturation was reached (no new themes were identified). The team systematically reviewed the themes and sorted them into content domains. The team used an analytic matrix to identify patterns and connections amongst the domains. Two of us not involved in the qualitative coding process (R.E., M.K.) audited the analytic matrix, choice of quotes, and thematic analysis.\n\n\nThe analysis started after the first interview. All data were analyzed with the aid of the audio- coding facility of the NVivo 8: QSR International Pty Ltd, Doncaster, Vic, Australia programme. First, [name] and [name] coded independently from one another, making sure to stay semantically close to the participants’ wording. Then we discussed these open codes and defined axial codes.[REF] New insights about the impact of CST were written down in memos.\n\n\nVideotapes were analysed using immersion/crystallisation methods of qualitative data analysis.[REF] With no pre-existing framework developed in advance for analysis, an inductive approach was used to discover patterns of NVB in the data. A team of six researchers met weekly for 18 months to view videos together. Using a consensus-building approach based on a combination of field notes, ‘opportunistic’ interviews with the participants, and repeated viewing of the same material, sometimes many months apart, we eventually achieved consensus on verbal, non-verbal, and physical themes and patterns observed in the data. Finally, as a test of ‘goodness-of-fit,’ we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\n\nAll transcripts were coded thematically by four of the five authors, who met regularly to identify areas of convergence until full agreement was reached. One of the interviewers (P.M.) maintained an audit trail to track the team’s developing thinking. A process of dialectical empiricism[REF] was used to categorise the emergent themes into more abstract concepts…"
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-trustworthiness-1",
    "href": "guidelines/SRQR-1/index.html#sec-trustworthiness-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\nMember checking\n\nMember checks [REF] with an external TBL expert (R.L.) supported the validity of these analyses.\n\nTriangulation of data types and data sources\n\nThe interview data were triangulated with the data of 11 student and supervisor focus groups of a previous study, and more specifically, with those data that concern in particular the influence of CST [Communication Skills Training] on the development of patient-centredness…. Triangulation with the focus group data allowed us to broaden the in-depth information from the interviews in the analysis and to ‘share and compare’ this with information from students and doctors with varying levels of CST (no, limited, full programme) and from two universities (Universities of Antwerp and Ghent). Moreover, this enabled us to better explore the evolution over time, given that the focus groups included participants at different stages of their study: before clerkships (year 4, undergraduate), during clerkships (year 6, undergraduate), after clerkships (year 7, undergraduate) and postgraduate (general practice trainees, and supervising specialists and GPs; Table 1).\n\n\n\n\n\nFinally, as a test of ‘goodness-of-fit’, we carefully reviewed the videotapes for any ‘deviant’ cases that did not fit the categories we had developed.\n\nTriangulation of Researchers + Audit trail\n\nTo ensure rigor and increase authenticity in our methodology, we used two kinds of triangulation—investigator triangulation and data triangulation.[REF] We sought analytical rigor using an audit trail and multiple coders; our coding team included an experienced clinician (M.G.) as well as a nonclinician with expertise in medical communication and team dynamics (L.L.)."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-synthesis-and-interpretation-1",
    "href": "guidelines/SRQR-1/index.html#sec-synthesis-and-interpretation-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nWe identified four patterns of NVB (non-verbal behavior) that relate to handover quality and have dubbed them: (1) joint focus of attention; (2) ‘the poker hand’; (3) parallel play; and (4) kerbside consultation. Each pattern constitutes a ‘transfix,’ or systematic way of participating non-verbally in the care transfer process. And, although there are variations in each pattern, we have been able to code virtually every handover we have observed in nursing, medicine and surgery into one of these four categories.\n\n\nBecause our participants came from similar educational backgrounds, had studied medicine as their tertiary course, were embedded in the culture of medicine, and were associated in meaningful ways with a single medical school, we approached their transcripts with the assumption that they belonged to a loosely formed discourse community. Although their graduation dates ranged over a period of 50 years and their collective sphere of practice included 10 different specialty areas, there were many similarities in their experiences of enculturation during and after medical school.\n\n\nTheir three major (often overlapping) areas of concern were epistemic (acquiring knowledge and skill), interpersonal (relating to patients, families, colleagues and administrators) and personal (achieving work–life balance). In each of these areas, medical enculturation was achieved by two overlapping processes, ‘absorption’ and ‘assimilation’, each of which may have distinct implications for postgraduate medical education."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-links-to-empirical-data-1",
    "href": "guidelines/SRQR-1/index.html#sec-links-to-empirical-data-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\nSee Frankel et al. for an excellent example of how to use photographs (or snapshots from video) to illustrate and provide supporting evidence for patterns of behavior identified in the analysis. http://qualitysafety.bmj.com/content/21/Suppl_1/i121.\n\nWe identified five interruption types: (1) probing for further data, (2) prompting for expected sequence, (3) teaching around the case, (4) thinking out loud, and (5) providing direction (see Table 1). Several interruption types served both goals of the case review discussions—teaching and patient care. For example, when thinking out loud, supervisors reasoned through problems and taught the team: “So that’s the big question, did she have a mechanical fall, or did she have a medicine-related fall?” (Case 2). Supervisors prompted for expected sequence, preventing presenters from skipping over information while simultaneously allowing the supervisor to instruct the team on presentation style: “So now you can tell me what the rest of his test results are because I haven’t heard those” (Case 16)."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-integration-with-prior-work-1",
    "href": "guidelines/SRQR-1/index.html#sec-integration-with-prior-work-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Examples",
    "text": "Examples\n\nThis study contributes to the understanding and discussion of the complexity of involving patients in healthcare education. It shows that integrating patient-led teaching into initiatives that are partly faculty-led influences the way in which students perceive learning from and with PIs. What is not known, however, is whether perceptions are also affected by type of health profession and the students’ different orientation towards logics of care and science, and issues of authority and power relations.\n\nFor complete examples of Discussions, see:\n\nHenriksen & Ringsted, 2013\nWesterman et al., 2013."
  },
  {
    "objectID": "guidelines/SRQR-1/index.html#sec-limitations-1",
    "href": "guidelines/SRQR-1/index.html#sec-limitations-1",
    "title": "The SRQR guidelines for writing qualitative research articles",
    "section": "Example",
    "text": "Example\n\nThe study has several limitations. One is that the focus group interview method reveals students’ perceptions rather than their actual behaviors. Observations of the patient-led teaching encounter may have illuminated an understanding of the relationship between patient instructors and medical students. Another limitation is that the PI-led teaching is optional rather than mandatory, which may have influenced students’ attitudes in a positive direction. Moreover, students who are eager to take on extra-curricular activities may not be representative of the whole population. That only 23 out of 39 students signed up for this study might also have influenced results if the missing group of students represented other perceptions than those present in the focus groups. However the received data from the focus groups were rich in information and diverse perceptions were present. Another limitation is the overrepresentation of women over men in our sample. Even though women are also overrepresented in medical school this might potentially have influenced results, but gender differences in perceptions were nevertheless not identified in the data."
  },
  {
    "objectID": "guidelines/cheers/index.html#about-this-guideline",
    "href": "guidelines/cheers/index.html#about-this-guideline",
    "title": "The CHEERS guideline for writing a economic evaluation of health interventions",
    "section": "About this guideline",
    "text": "About this guideline\n\nThis guideline is relevant to economic evaluations of health interventions"
  },
  {
    "objectID": "guidelines/cheers/index.html#download-resources",
    "href": "guidelines/cheers/index.html#download-resources",
    "title": "The CHEERS guideline for writing a economic evaluation of health interventions",
    "section": "Download Resources",
    "text": "Download Resources\nReporting guidelines are best used early:\n\nUse a template to write quickly and avoid the blank page\nUse a checklist to double-check and reassure others that your work is described transparently\n\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list\n\n\n\nTitle\n\n\n1. Title\n\n\n\n\n\n\n\nIdentify the study as an economic evaluation or use more specific terms such as “cost-effectiveness analysis”, and describe the interventions compared.\n\n\nAbstract\n\n\n2. Abstract\n\n\n\n\n\n\n\nProvide a structured summary of objectives, perspective, setting, methods (including study design and inputs), results (including base case and uncertainty analyses), and conclusions\n\n\nIntroduction\n\n\n3. Background and objectives\n\n\n\n\n\n\n\nProvide an explicit statement of the broader context for the study. Present the study question and its relevance for health policy or practice decisions\n\n\nMethods\n\n\n4. Target population and subgroups\n\n\n\n\n\n\n\nDescribe characteristics of the base case population and subgroups analysed, including why they were chosen.\n\n\n5. Setting and location\n\n\n\n\n\n\n\nState relevant aspects of the system(s) in which the decision(s) need(s) to be made.\n\n\n6. Study perspective\n\n\n\n\n\n\n\nDescribe the perspective of the study and relate this to the costs being evaluated.\n\n\n7. Comparators\n\n\n\n\n\n\n\nDescribe the interventions or strategies being compared and state why they were chosen.\n\n\n8. Time horizon\n\n\n\n\n\n\n\nState the time horizon(s) over which costs and consequences are being evaluated and say why appropriate.\n\n\n9. Discount rate\n\n\n\n\n\n\n\nReport the choice of discount rate(s) used for costs and outcomes and say why appropriate\n\n\n10. Choice of health outcomes\n\n\n\n\n\n\n\nDescribe what outcomes were used as the measure(s) of benefit in the evaluation and their relevance for the type of analysis performed\n\n\n11a. Meaurement of effectiveness\n\n\n\n\n\n\n\nSingle study-based estimates: Describe fully the design features of the single effectiveness study and why the single study was a sufficient source of clinical effectiveness data\n\n\n11b. Measurement of effectiveness\n\n\n\n\n\n\n\nSynthesis-based estimates: Describe fully the methods used for identification of included studies and synthesis of clinical effectiveness data\n\n\n12. Measurement and valuation of preference based outcomes\n\n\n\n\n\n\n\nIf applicable, describe the population and methods used to elicit preferences for outcomes.\n\n\nEstimating resources\nand costs\n\n\n13a. Estimating resources and costs\n\n\n\n\n\n\n\nSingle study-based economic evaluation: Describe approaches used to estimate resource use associated with the alternative interventions. Describe primary or secondary research methods for valuing each resource item in terms of its unit cost. Describe any adjustments made to approximate to opportunity costs\n\n\nMethods\n\n\n13b. Estimating resources and costs\n\n\n\n\n\n\n\nModel-based economic evaluation: Describe approaches and data sources used to estimate resource use associated with model health states. Describe primary or secondary research methods for valuing each resource item in terms of its unit cost. Describe any adjustments made to approximate to\nopportunity costs.\n\n\n14. Currency, price date, and conversion\n\n\n\n\n\n\n\nReport the dates of the estimated resource quantities and unit costs. Describe methods for adjusting estimated unit costs to the year of reported costs if necessary. Describe methods for converting costs into a common currency base and the exchange rate.\n\n\n15. Choice of model\n\n\n\n\n\n\n\nDescribe and give reasons for the specific type of decision analytical model used. Providing a figure to show model structure is strongly recommended.\n\n\n16. Assumptions\n\n\n\n\n\n\n\nDescribe all structural or other assumptions underpinning the decision-analytical model.\n\n\n17. Analytical methods\n\n\n\n\n\n\n\nDescribe all analytical methods supporting the evaluation. This could include methods for dealing with skewed, missing, or censored data; extrapolation methods; methods for pooling data; approaches to validate or make adjustments (such as half cycle corrections) to a model; and methods for handling population heterogeneity and uncertainty.\n\n\nResults\n\n\n18. Study parameters\n\n\n\n\n\n\n\nReport the values, ranges, references, and, if used, probability distributions for all parameters. Report reasons or sources for distributions used to represent uncertainty where appropriate. Providing a table to show the input values is strongly recommended.\n\n\n19. Incremental costs and outcomes\n\n\n\n\n\n\n\nFor each intervention, report mean values for the main categories of estimated costs and outcomes of interest, as well as mean differences between the comparator groups. If applicable, report incremental cost-effectiveness ratios.\n\n\n20a. Characterising uncertainty\n\n\n\n\n\n\n\nSingle study-based economic evaluation: Describe the effects of sampling uncertainty for the estimated incremental cost and incremental effectiveness parameters, together with the impact of methodological assumptions (such as discount rate, study perspective).\n\n\n20b. Characterising uncertainty\n\n\n\n\n\n\n\nModel-based economic evaluation: Describe the effects on the results of uncertainty for all input parameters, and uncertainty related to the structure of the model and assumptions.\n\n\n21. Characterising heterogeneity\n\n\n\n\n\n\n\nIf applicable, report differences in costs, outcomes, or cost effectiveness that can be explained by variations between subgroups of patients with different baseline characteristics or other observed variability in effects that are not reducible by\nmore information.\n\n\nDiscussion\n\n\n22. Study findings, limitations, generalisability, and current knowledge\n\n\n\n\n\n\n\nSummarise key study findings and describe how they support the conclusions reached. Discuss limitations and the generalisability of the findings and how the findings fit with current knowledge.\n\n\nOther\n\n\n23. Source of funding\n\n\n\n\n\n\n\nDescribe how the study was funded and the role of the funder in the identification, design, conduct, and reporting of the analysis. Describe other non-monetary sources of support\n\n\n24. Conflict of interest\n\n\n\n\n\n\n\nDescribe any potential for conflict of interest of study contributors in accordance with journal policy. In the absence of a journal policy, we recommend authors comply with International Committee of Medical Journal Editors recommendations"
  },
  {
    "objectID": "guidelines/coreq/index.html#about-this-guideline",
    "href": "guidelines/coreq/index.html#about-this-guideline",
    "title": "The COREQ guideline for writing a qualitative study.",
    "section": "About this guideline",
    "text": "About this guideline\n\nThis guideline is relevant to qualitative studies, especially those that use interviews, focus groups and surveys"
  },
  {
    "objectID": "guidelines/coreq/index.html#download-resources",
    "href": "guidelines/coreq/index.html#download-resources",
    "title": "The COREQ guideline for writing a qualitative study.",
    "section": "Download Resources",
    "text": "Download Resources\nReporting guidelines are best used early:\n\nUse a template to write quickly and avoid the blank page\nUse a checklist to double-check and reassure others that your work is described transparently\n\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list"
  },
  {
    "objectID": "guidelines/coreq/index.html#guidance",
    "href": "guidelines/coreq/index.html#guidance",
    "title": "The COREQ guideline for writing a qualitative study.",
    "section": "Guidance",
    "text": "Guidance\nApprox. 1 min read\n\nResearch team and reflexivity\n\n\n1. Personal Characteristics: Interviewer / facilitator\n\n\n\n\n\n\n\nWhich author / s conducted the interview or focus group?\n\n\n2. Personal Characteristics: Credentials\n\n\n\n\n\n\n\nWhat were the researcher’s credentials? E.g. PhD, MD\n\n\n3. Personal Characteristics: Occupation\n\n\n\n\n\n\n\nWhat was their occupation at the time of the study?\n\n\n4. Personal Characteristics: Gender\n\n\n\n\n\n\n\nWas the researcher male or female?\n\n\n5. Personal Characteristics: Experience and training\n\n\n\n\n\n\n\nWhat experience or training did the researcher have?\n\n\n6. Relationship with participants Relationship established\n\n\n\n\n\n\n\nWas a relationship established prior to study commencement?\n\n\nRelationship with participants\n\n\n7. Participant knowledge of the interviewer\n\n\n\n\n\n\n\nWhat did the participants know about the researcher? e.g. personal goals, reasons for doing the research\n\n\n8. Relationship with participants: Interviewer characteristics\n\n\n\n\n\n\n\nWhat characteristics were reported about the interviewer / facilitator? e.g. Bias, assumptions, reasons and interests in the research topic\n\n\nStudy design\n\n\n9. Theoretical framework: Methodological orientation and Theory\n\n\n\n\n\n\n\nWhat methodological orientation was stated to underpin the study? e.g. grounded theory, discourse analysis, ethnography, phenomenology, content analysis\n\n\n10. Participant selection: sampling\n\n\n\n\n\n\n\nHow were participants selected? e.g. purposive, convenience, consecutive, snowball\n\n\n11. Participant selection: method of approach\n\n\n\n\n\n\n\nHow were participants approached? e.g. face-to-face, telephone, mail, email\n\n\n12. Participant selection: sample size\n\n\n\n\n\n\n\nHow many participants were in the study?\n\n\n13. Participant selection: non-participation\n\n\n\n\n\n\n\nHow many people refused to participate or dropped out? Reasons?\n\n\n14. Setting: setting of data collection\n\n\n\n\n\n\n\nWhere was the data collected? e.g. home, clinic, workplace\n\n\n15. Setting: prescence of non participants\n\n\n\n\n\n\n\nWas anyone else present besides the participants and researchers?\n\n\n16. Setting: description of sample\n\n\n\n\n\n\n\nWhat are the important characteristics of the sample? e.g. demographic data, date\n\n\n17. Data collection: interview guide\n\n\n\n\n\n\n\nWere questions, prompts, guides provided by the authors? Was it pilot tested?\n\n\n18. Data collection: repeat interviews\n\n\n\n\n\n\n\nWere repeat interviews carried out? If yes, how many?\n\n\n19. Data collection: audio / visual recording\n\n\n\n\n\n\n\nDid the research use audio or visual recording to collect the data?\n\n\n20. Data collection: field notes\n\n\n\n\n\n\n\nWere field notes made during and / or after the interview or focus group?\n\n\n21. Data collection: duration\n\n\n\n\n\n\n\nWhat was the duration of the interviews or focus group?\n\n\n22. Data collection: data saturation\n\n\n\n\n\n\n\nWas data saturation discussed?\n\n\n23. Data collection: transcripts returned\n\n\n\n\n\n\n\nWere transcripts returned to participants for comment and / or correction?\n\n\nAnalysis and findings\n\n\n24. Data analysis: number of data coders\n\n\n\n\n\n\n\nHow many data coders coded the data?\n\n\n25. Data analysis: description of the coding tree\n\n\n\n\n\n\n\nDid authors provide a description of the coding tree?\n\n\n26. Data analysis: derivation of themes\n\n\n\n\n\n\n\nWere themes identified in advance or derived from the data?\n\n\n27. Data analysis: software\n\n\n\n\n\n\n\nWhat software, if applicable, was used to manage the data?\n\n\n28. Data analysis: participant checking\n\n\n\n\n\n\n\nDid participants provide feedback on the findings?\n\n\n29. Reporting: quotations presented\n\n\n\n\n\n\n\nWere participant quotations presented to illustrate the themes / findings? Was each quotation identified? e.g. participant number\n\n\n30. Reporting: data and findings consistent\n\n\n\n\n\n\n\nWas there consistency between the data presented and the findings?\n\n\n31. Reporting: clarity of major themes\n\n\n\n\n\n\n\nWere major themes clearly presented in the findings?\n\n\n32. Reporting: clarity of minor themes\n\n\n\n\n\n\n\nIs there a description of diverse cases or discussion of minor themes?"
  },
  {
    "objectID": "guidelines/strega/index.html#about-this-guideline",
    "href": "guidelines/strega/index.html#about-this-guideline",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "About this guideline",
    "text": "About this guideline\n\nThis guideline is relevant to studies reporting genetic associations"
  },
  {
    "objectID": "guidelines/strega/index.html#download-resources",
    "href": "guidelines/strega/index.html#download-resources",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Download Resources",
    "text": "Download Resources\nReporting guidelines are best used early:\n\nUse a template to write quickly and avoid the blank page\nUse a checklist to double-check and reassure others that your work is described transparently\n\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list"
  },
  {
    "objectID": "guidelines/strega/index.html#guidance",
    "href": "guidelines/strega/index.html#guidance",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Guidance",
    "text": "Guidance\nApprox. 5 min read\n\nTitle and abstract\n\n\n1a. Title\n\n\n\n\n\n\n\nIndicate the study’s design with a commonly used term in the title or the abstract\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nReaders should be able to easily identify the design that was used from the title or abstract. An explicit, commonly used term for the study design also helps ensure correct indexing of articles in electronic databases\n\n\n\n\n\n1b. Abstract\n\n\n\n\n\n\n\nProvide in the abstract an informative and balanced summary of what was done and what was found\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nThe abstract provides key information that enables readers to understand a study and decide whether to read the article. Typical components include a statement of the research question, a short description of methods and results, and a conclusion. Abstracts should summarize key details of studies and should only present information that is provided in the article. We advise presenting key results in a numerical form that includes numbers of participants, estimates of associations and appropriate measures of variability and uncertainty (e.g., odds ratios with confidence intervals). We regard it insufficient to state only that an exposure is or is not significantly associated with an outcome.\nA series of headings pertaining to the background, design, conduct, and analysis of a study may help readers acquire the essential information rapidly. Many journals require such structured abstracts, which tend to be of higher quality and more readily informative than unstructured summaries.\n\n\n\n\n\nBackground/rationale\n\n\n2. Background/rationale\n\n\n\n\n\n\n\nExplain the scientific background and rationale for the investigation being reported\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nThe scientific background of the study provides important context for readers. It sets the stage for the study and describes its focus. It gives an overview of what is known on a topic and what gaps in current knowledge are addressed by the study. Background material should note recent pertinent studies and any systematic reviews of pertinent studies.\n\n\n\n\n\nObjectives\n\n\n3. Objectives\n\n\n\n\n\n\n\nState specific objectives, including any prespecified hypotheses. State if the study is the first report of a genetic association, a replication effort, or both.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nObjectives are the detailed aims of the study. Well crafted objectives specify populations, exposures and outcomes, and parameters that will be estimated. They may be formulated as specific hypotheses or as questions that the study was designed to address. In some situations objectives may be less specific, for example, in early discovery phases. Regardless, the report should clearly reflect the investigators’ intentions. For example, if important subgroups or additional analyses were not the original aim of the study but arose during data analysis, they should be described accordingly (see also items 4, 17 and 20).\n\n\n\n\n\nStudy design\n\n\n4. Study design\n\n\n\n\n\n\n\nPresent key elements of study design early in the paper\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nWe advise presenting key elements of study design early in the methods section (or at the end of the introduction) so that readers can understand the basics of the study. For example, authors should indicate that the study was a cohort study, which followed people over a particular time period, and describe the group of persons that comprised the cohort and their exposure status. Similarly, if the investigation used a case-control design, the cases and controls and their source population should be described. If the study was a cross-sectional survey, the population and the point in time at which the cross-section was taken should be mentioned. When a study is a variant of the three main study types, there is an additional need for clarity. For instance, for a case-crossover study, one of the variants of the case-control design, a succinct description of the principles was given in the example above [28].\nWe recommend that authors refrain from simply calling a study ‘prospective’ or ‘retrospective’ because these terms are ill defined [29]. One usage sees cohort and prospective as synonymous and reserves the word retrospective for case-control studies [30]. A second usage distinguishes prospective and retrospective cohort studies according to the timing of data collection relative to when the idea for the study was developed [31]. A third usage distinguishes prospective and retrospective case-control studies depending on whether the data about the exposure of interest existed when cases were selected [32]. Some advise against using these terms [33], or adopting the alternatives ‘concurrent’ and ‘historical’ for describing cohort studies [34]. In STROBE, we do not use the words prospective and retrospective, nor alternatives such as concurrent and historical. We recommend that, whenever authors use these words, they define what they mean. Most importantly, we recommend that authors describe exactly how and when data collection took place.\nThe first part of the methods section might also be the place to mention whether the report is one of several from a study. If a new report is in line with the original aims of the study, this is usually indicated by referring to an earlier publication and by briefly restating the salient features of the study. However, the aims of a study may also evolve over time. Researchers often use data for purposes for which they were not originally intended, including, for example, official vital statistics that were collected primarily for administrative purposes, items in questionnaires that originally were only included for completeness, or blood samples that were collected for another purpose. For example, the Physicians’ Health Study, a randomized controlled trial of aspirin and carotene, was later used to demonstrate that a point mutation in the factor V gene was associated with an increased risk of venous thrombosis, but not of myocardial infarction or stroke [35]. The secondary use of existing data is a creative part of observational research and does not necessarily make results less credible or less important. However, briefly restating the original aims might help readers understand the context of the research and possible limitations in the data.\n\n\n\n\n\nSetting\n\n\n5. Setting\n\n\n\n\n\n\n\nDescribe the setting, locations, and relevant dates, including periods of recruitment, exposure, follow-up, and data collection\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nReaders need information on setting and locations to assess the context and generalisability of a study’s results. Exposures such as environmental factors and therapies can change over time. Also, study methods may evolve over time. Knowing when a study took place and over what period participants were recruited and followed up places the study in historical context and is important for the interpretation of results.\nInformation about setting includes recruitment sites or sources (e.g., electoral roll, outpatient clinic, cancer registry, or tertiary care centre). Information about location may refer to the countries, towns, hospitals or practices where the investigation took place. We advise stating dates rather than only describing the length of time periods. There may be different sets of dates for exposure, disease occurrence, recruitment, beginning and end of follow-up, and data collection. Of note, nearly 80% of 132 reports in oncology journals that used survival analysis included the starting and ending dates for accrual of patients, but only 24% also reported the date on which follow-up ended [37].\n\n\n\n\n\nEligibility criteria\n\n\n6a. Eligibility criteria\n\n\n\n\n\n\n\nCohort study – Give the eligibility criteria, and the sources and methods of selection of participants. Describe methods of follow-up.\nCase-control study – Give the eligibility criteria, and the sources and methods of case ascertainment and control selection. Give the rationale for the choice of cases and controls.\nCross-sectional study – Give the eligibility criteria, and the sources and methods of selection of participants.\nGive information on the criteria and methods for selection of subsets of participants from a larger study, when relevant.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nDetailed descriptions of the study participants help readers understand the applicability of the results. Investigators usually restrict a study population by defining clinical, demographic and other characteristics of eligible participants. Typical eligibility criteria relate to age, gender, diagnosis and comorbid conditions. Despite their importance, eligibility criteria often are not reported adequately. In a survey of observational stroke research, 17 of 49 reports (35%) did not specify eligibility criteria [5].\nEligibility criteria may be presented as inclusion and exclusion criteria, although this distinction is not always necessary or useful. Regardless, we advise authors to report all eligibility criteria and also to describe the group from which the study population was selected (e.g., the general population of a region or country), and the method of recruitment (e.g., referral or self-selection through advertisements).\nKnowing details about follow-up procedures, including whether procedures minimized non-response and loss to follow-up and whether the procedures were similar for all participants, informs judgments about the validity of results. For example, in a study that used IgM antibodies to detect acute infections, readers needed to know the interval between blood tests for IgM antibodies so that they could judge whether some infections likely were missed because the interval between blood tests was too long [41]. In other studies where follow-up procedures differed between exposed and unexposed groups, readers might recognize substantial bias due to unequal ascertainment of events or differences in non-response or loss to follow-up [42]. Accordingly, we advise that researchers describe the methods used for following participants and whether those methods were the same for all participants, and that they describe the completeness of ascertainment of variables (see also item 14).\nIn case-control studies, the choice of cases and controls is crucial to interpreting the results, and the method of their selection has major implications for study validity. In general, controls should reflect the population from which the cases arose. Various methods are used to sample controls, all with advantages and disadvantages: for cases that arise from a general population, population roster sampling, random digit dialling, neighbourhood or friend controls are used. Neighbourhood or friend controls may present intrinsic matching on exposure [17]. Controls with other diseases may have advantages over population-based controls, in particular for hospital-based cases, because they better reflect the catchment population of a hospital, have greater comparability of recall and ease of recruitment. However, they can present problems if the exposure of interest affects the risk of developing or being hospitalized for the control condition(s) [43,44]. To remedy this problem often a mixture of the best defensible control diseases is used [45].\n\n\n\n\n\n6b. Eligibility criteria\n\n\n\n\n\n\n\nCohort study – For matched studies, give matching criteria and number of exposed and unexposed.\nCase-control study – For matched studies, give matching criteria and the number of controls per case.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nMatching is much more common in case-control studies, but occasionally, investigators use matching in cohort studies to make groups comparable at the start of follow-up. Matching in cohort studies makes groups directly comparable for potential confounders and presents fewer intricacies than with case-control studies. For example, it is not necessary to take the matching into account for the estimation of the relative risk [48]. Because matching in cohort studies may increase statistical precision investigators might allow for the matching in their analyses and thus obtain narrower confidence intervals.\nIn case-control studies matching is done to increase a study’s efficiency by ensuring similarity in the distribution of variables between cases and controls, in particular the distribution of potential confounding variables [48,49]. Because matching can be done in various ways, with one or more controls per case, the rationale for the choice of matching variables and the details of the method used should be described. Commonly used forms of matching are frequency matching (also called group matching) and individual matching. In frequency matching, investigators choose controls so that the distribution of matching variables becomes identical or similar to that of cases. Individual matching involves matching one or several controls to each case. Although intuitively appealing and sometimes useful, matching in case-control studies has a number of disadvantages, is not always appropriate, and needs to be taken into account in the analysis\n\n\n\n\n\nVariables\n\n\n7a. Variables\n\n\n\n\n\n\n\nClearly define all outcomes, exposures, predictors, potential confounders, and effect modifiers. Give diagnostic criteria, if applicable\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nAuthors should define all variables considered for and included in the analysis, including outcomes, exposures, predictors, potential confounders and potential effect modifiers. Disease outcomes require adequately detailed description of the diagnostic criteria. This applies to criteria for cases in a case-control study, disease events during follow-up in a cohort study and prevalent disease in a cross-sectional study. Clear definitions and steps taken to adhere to them are particularly important for any disease condition of primary interest in the study.\nFor some studies, ‘determinant’ or ‘predictor’ may be appropriate terms for exposure variables and outcomes may be called ‘endpoints’. In multivariable models, authors sometimes use ‘dependent variable’ for an outcome and ‘independent variable’ or ‘explanatory variable’ for exposure and confounding variables. The latter is not precise as it does not distinguish exposures from confounders.\nIf many variables have been measured and included in exploratory analyses in an early discovery phase, consider providing a list with details on each variable in an appendix, additional table or separate publication. Of note, the International Journal of Epidemiology recently launched a new section with ‘cohort profiles’, that includes detailed information on what was measured at different points in time in particular studies [56,57]. Finally, we advise that authors declare all ‘candidate variables’ considered for statistical analysis, rather than selectively reporting only those included in the final models (see also item 16a) [58,59]\n\n\n\n\n\n7b. Variables\n\n\n\n\n\n\n\nClearly define genetic exposures (genetic variants) using a widely-used nomenclature system. Identify variables likely to be associated with population stratification (confounding by ethnic origin).\n\n\nData sources/measurement\n\n\n8a. Data sources/measurement\n\n\n\n\n\n\n\nFor each variable of interest give sources of data and details of methods of assessment (measurement). Describe comparability of assessment methods if there is more than one group. Give information separately for for exposed and unexposed groups if applicable.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nThe way in which exposures, confounders and outcomes were measured affects the reliability and validity of a study. Measurement error and misclassification of exposures or outcomes can make it more difficult to detect cause-effect relationships, or may produce spurious relationships. Error in measurement of potential confounders can increase the risk of residual confounding [62,63]. It is helpful, therefore, if authors report the findings of any studies of the validity or reliability of assessments or measurements, including details of the reference standard that was used. Rather than simply citing validation studies (as in the first example), we advise that authors give the estimated validity or reliability, which can then be used for measurement error adjustment or sensitivity analyses (see items 12e and 17).\nIn addition, it is important to know if groups being compared differed with respect to the way in which the data were collected. This may be important for laboratory examinations (as in the second example) and other situations. For instance, if an interviewer first questions all the cases and then the controls, or vice versa, bias is possible because of the learning curve; solutions such as randomising the order of interviewing may avoid this problem. Information bias may also arise if the compared groups are not given the same diagnostic tests or if one group receives more tests of the same kind than another (see also item 9).\n\n\n\n\n\n8b. Data sources/measurement\n\n\n\n\n\n\n\nDescribe laboratory methods, including source and storage of DNA, genotyping methods and platforms (including the allele calling algorithm used, and its version), error rates and call rates. State the laboratory / centre where genotyping was done. Describe comparability of laboratory methods if there is more than one group. Specify whether genotypes were assigned using all of the data from the study simultaneously or in smaller batches.\n\n\nBias\n\n\n9a. Bias\n\n\n\n\n\n\n\nDescribe any efforts to address potential sources of bias\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nBiased studies produce results that differ systematically from the truth (see also Box 3). It is important for a reader to know what measures were taken during the conduct of a study to reduce the potential of bias. Ideally, investigators carefully consider potential sources of bias when they plan their study. At the stage of reporting, we recommend that authors always assess the likelihood of relevant biases. Specifically, the direction and magnitude of bias should be discussed and, if possible, estimated. For instance, in case-control studies information bias can occur, but may be reduced by selecting an appropriate control group, as in the first example [64]. Differences in the medical surveillance of participants were a problem in the second example [65]. Consequently, the authors provide more detail about the additional data they collected to tackle this problem. When investigators have set up quality control programs for data collection to counter a possible “drift” in measurements of variables in longitudinal studies, or to keep variability at a minimum when multiple observers are used, these should be described.\nUnfortunately, authors often do not address important biases when reporting their results. Among 43 case-control and cohort studies published from 1990 to 1994 that investigated the risk of second cancers in patients with a history of cancer, medical surveillance bias was mentioned in only 5 articles [66]. A survey of reports of mental health research published during 1998 in three psychiatric journals found that only 13% of 392 articles mentioned response bias [67]. A survey of cohort studies in stroke research found that 14 of 49 (28%) articles published from 1999 to 2003 addressed potential selection bias in the recruitment of study participants and 35 (71%) mentioned the possibility that any type of bias may have affected results\n\n\n\n\n\n9b. Bias\n\n\n\n\n\n\n\nDescribe any efforts to address potential sources of bias\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nFor quantitative outcome variables, specify if any investigation of potential bias resulting from pharmacotherapy was undertaken. If relevant, describe the nature and magnitude of the potential bias, and explain what approach was used to deal with this.\n\n\n\n\n\nStudy size\n\n\n10. Study size\n\n\n\n\n\n\n\nExplain how the study size was arrived at\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nA study should be large enough to obtain a point estimate with a sufficiently narrow confidence interval to meaningfully answer a research question. Large samples are needed to distinguish a small association from no association. Small studies often provide valuable information, but wide confidence intervals may indicate that they contribute less to current knowledge in comparison with studies providing estimates with narrower confidence intervals. Also, small studies that show ‘interesting’ or ‘statistically significant’ associations are published more frequently than small studies that do not have ‘significant’ findings. While these studies may provide an early signal in the context of discovery, readers should be informed of their potential weaknesses.\nThe importance of sample size determination in observational studies depends on the context. If an analysis is performed on data that were already available for other purposes, the main question is whether the analysis of the data will produce results with sufficient statistical precision to contribute substantially to the literature, and sample size considerations will be informal. Formal, a priori calculation of sample size may be useful when planning a new study. Such calculations are associated with more uncertainty than implied by the single number that is generally produced. For example, estimates of the rate of the event of interest or other assumptions central to calculations are commonly imprecise, if not guesswork. The precision obtained in the final analysis can often not be determined beforehand because it will be reduced by inclusion of confounding variables in multivariable analyses, the degree of precision with which key variables can be measured, and the exclusion of some individuals.\nFew epidemiological studies explain or report deliberations about sample size. We encourage investigators to report pertinent formal sample size calculations if they were done. In other situations they should indicate the considerations that determined the study size (e.g., a fixed available sample, as in the first example above). If the observational study was stopped early when statistical significance was achieved, readers should be told. Do not bother readers with post hoc justifications for study size or retrospective power calculations. From the point of view of the reader, confidence intervals indicate the statistical precision that was ultimately obtained. It should be realized that confidence intervals reflect statistical uncertainty only, and not all uncertainty that may be present in a study (see item 20).\n\n\n\n\n\nQuantitative variables\n\n\n11. Quantitative variables\n\n\n\n\n\n\n\nExplain how quantitative variables were handled in the analyses. If applicable, describe which groupings were chosen, and why. If applicable, describe how effects of treatment were dealt with.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nInvestigators make choices regarding how to collect and analyse quantitative data about exposures, effect modifiers and confounders. For example, they may group a continuous exposure variable to create a new categorical variable. Grouping choices may have important consequences for later analyses. We advise that authors explain why and how they grouped quantitative data, including the number of categories, the cut-points, and category mean or median values. Whenever data are reported in tabular form, the counts of cases, controls, persons at risk, person-time at risk, etc. should be given for each category. Tables should not consist solely of effect-measure estimates or results of model fitting.\nInvestigators might model an exposure as continuous in order to retain all the information. In making this choice, one needs to consider the nature of the relationship of the exposure to the outcome. As it may be wrong to assume a linear relation automatically, possible departures from linearity should be investigated. Authors could mention alternative models they explored during analyses (e.g., using log transformation, quadratic terms or spline functions). Several methods exist for fitting a non-linear relation between the exposure and outcome. Also, it may be informative to present both continuous and grouped analyses for a quantitative exposure of prime interest.\nIn a recent survey, two thirds of epidemiological publications studied quantitative exposure variables. In 42 of 50 articles (84%) exposures were grouped into several ordered categories, but often without any stated rationale for the choices made. Fifteen articles used linear associations to model continuous exposure but only two reported checking for linearity. In another survey, of the psychological literature, dichotomization was justified in only 22 of 110 articles (20%)\n\n\n\n\n\nStatistical methods\n\n\n12a. Statistical methods\n\n\n\n\n\n\n\nDescribe all statistical methods, including those used to control for confounding. State software version used and options (or settings) chosen.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nIn general, there is no one correct statistical analysis but, rather, several possibilities that may address the same question, but make different assumptions. Regardless, investigators should pre-determine analyses at least for the primary study objectives in a study protocol. Often additional analyses are needed, either instead of, or as well as, those originally envisaged, and these may sometimes be motivated by the data. When a study is reported, authors should tell readers whether particular analyses were suggested by data inspection. Even though the distinction between pre-specified and exploratory analyses may sometimes be blurred, authors should clarify reasons for particular analyses.\nIf groups being compared are not similar with regard to some characteristics, adjustment should be made for possible confounding variables by stratification or by multivariable regression (see Box 5) [94]. Often, the study design determines which type of regression analysis is chosen. For instance, Cox proportional hazard regression is commonly used in cohort studies [95]. whereas logistic regression is often the method of choice in case-control studies [96,97]. Analysts should fully describe specific procedures for variable selection and not only present results from the final model [98,99]. If model comparisons are made to narrow down a list of potential confounders for inclusion in a final model, this process should be described. It is helpful to tell readers if one or two covariates are responsible for a great deal of the apparent confounding in a data analysis. Other statistical analyses such as imputation procedures, data transformation, and calculations of attributable risks should also be described. Non-standard or novel approaches should be referenced and the statistical software used reported. As a guiding principle, we advise statistical methods be described “with enough detail to enable a knowledgeable reader with access to the original data to verify the reported results” [100].\nIn an empirical study, only 93 of 169 articles (55%) reporting adjustment for confounding clearly stated how continuous and multi-category variables were entered into the statistical model [101]. Another study found that among 67 articles in which statistical analyses were adjusted for confounders, it was mostly unclear how confounders were chosen\n\n\n\n\n\n12b. Statistical methods\n\n\n\n\n\n\n\nDescribe any methods used to examine subgroups and interactions\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nAs discussed in detail under item 17, many debate the use and value of analyses restricted to subgroups of the study population [4,104]. Subgroup analyses are nevertheless often done [4]. Readers need to know which subgroup analyses were planned in advance, and which arose while analysing the data. Also, it is important to explain what methods were used to examine whether effects or associations differed across groups (see item 17).\nInteraction relates to the situation when one factor modifies the effect of another (therefore also called ‘effect modification’). The joint action of two factors can be characterized in two ways: on an additive scale, in terms of risk differences; or on a multiplicative scale, in terms of relative risk (see Box 8). Many authors and readers may have their own preference about the way interactions should be analysed. Still, they may be interested to know to what extent the joint effect of exposures differs from the separate effects. There is consensus that the additive scale, which uses absolute risks, is more appropriate for public health and clinical decision making [105]. Whatever view is taken, this should be clearly presented to the reader, as is done in the example above [103]. A lay-out presenting separate effects of both exposures as well as their joint effect, each relative to no exposure, might be most informative. It is presented in the example for interaction under item 17, and the calculations on the different scales are explained in Box 8\n\n\n\n\n\n12c. Statistical methods\n\n\n\n\n\n\n\nExplain how missing data were addressed\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nMissing data are common in observational research. Questionnaires posted to study participants are not always filled in completely, participants may not attend all follow-up visits and routine data sources and clinical databases are often incomplete. Despite its ubiquity and importance, few papers report in detail on the problem of missing data [5,107]. Investigators may use any of several approaches to address missing data. We describe some strengths and limitations of various approaches in Box 6. We advise that authors report the number of missing values for each variable of interest (exposures, outcomes, confounders) and for each step in the analysis. Authors should give reasons for missing values if possible, and indicate how many individuals were excluded because of missing data when describing the flow of participants through the study (see also item 13). For analyses that account for missing data, authors should describe the nature of the analysis (e.g., multiple imputation) and the assumptions that were made (e.g., missing at random, see Box 6).\n\n\n\n\n\n12d. Statistical methods\n\n\n\n\n\n\n\nIf applicable, explain how loss to follow-up was addressed\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nCohort studies are analysed using life table methods or other approaches that are based on the person-time of follow-up and time to developing the disease of interest. Among individuals who remain free of the disease at the end of their observation period, the amount of follow-up time is assumed to be unrelated to the probability of developing the outcome. This will be the case if follow-up ends on a fixed date or at a particular age. Loss to follow-up occurs when participants withdraw from a study before that date. This may hamper the validity of a study if loss to follow-up occurs selectively in exposed individuals, or in persons at high risk of developing the disease (‘informative censoring’). In the example above, patients lost to follow-up in treatment programmes with no active follow-up had fewer CD4 helper cells than those remaining under observation and were therefore at higher risk of dying [116].\nIt is important to distinguish persons who reach the end of the study from those lost to follow-up. Unfortunately, statistical software usually does not distinguish between the two situations: in both cases follow-up time is automatically truncated (‘censored’) at the end of the observation period. Investigators therefore need to decide, ideally at the stage of planning the study, how they will deal with loss to follow-up. When few patients are lost, investigators may either exclude individuals with incomplete follow-up, or treat them as if they withdrew alive at either the date of loss to follow-up or the end of the study. We advise authors to report how many patients were lost to follow-up and what censoring strategies they used\n\n\n\n\n\n12e. Statistical methods\n\n\n\n\n\n\n\nDescribe any sensitivity analyses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nSensitivity analyses are useful to investigate whether or not the main results are consistent with those obtained with alternative analysis strategies or assumptions [121]. Issues that may be examined include the criteria for inclusion in analyses, the definitions of exposures or outcomes [122], which confounding variables merit adjustment, the handling of missing data [120,123], possible selection bias or bias from inaccurate or inconsistent measurement of exposure, disease and other variables, and specific analysis choices, such as the treatment of quantitative variables (see item 11). Sophisticated methods are increasingly used to simultaneously model the influence of several biases or assumptions [124–126].\nIn 1959 Cornfield et al. famously showed that a relative risk of 9 for cigarette smoking and lung cancer was extremely unlikely to be due to any conceivable confounder, since the confounder would need to be at least nine times as prevalent in smokers as in non-smokers [127]. This analysis did not rule out the possibility that such a factor was present, but it did identify the prevalence such a factor would need to have. The same approach was recently used to identify plausible confounding factors that could explain the association between childhood leukaemia and living near electric power lines [128]. More generally, sensitivity analyses can be used to identify the degree of confounding, selection bias, or information bias required to distort an association. One important, perhaps under recognised, use of sensitivity analysis is when a study shows little or no association between an exposure and an outcome and it is plausible that confounding or other biases toward the null are present\n\n\n\n\n\n12f. Statistical methods\n\n\n\n\n\n\n\nState whether Hardy-Weinberg equilibrium was considered and, if so, how.\n\n\n12g. Statistical methods\n\n\n\n\n\n\n\nDescribe any methods used for inferring genotypes or haplotypes\n\n\n12h. Statistical methods\n\n\n\n\n\n\n\nDescribe any methods used to assess or address population stratification.\n\n\n12i. Statistical methods\n\n\n\n\n\n\n\nDescribe any methods used to address multiple comparisons or to control risk of false positive findings.\n\n\n12j. Statistical methods\n\n\n\n\n\n\n\nDescribe any methods used to address and correct for relatedness among subjects\n\n\nParticipants\n\n\n13a. Participants\n\n\n\n\n\n\n\nReport numbers of individuals at each stage of study—eg numbers potentially eligible, examined for eligibility, confirmed eligible, included in the study, completing follow-up, and analysed. Give information separately for for exposed and unexposed groups if applicable. Report numbers of individuals in whom genotyping was attempted and numbers of individuals in whom genotyping was successful.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nDetailed information on the process of recruiting study participants is important for several reasons. Those included in a study often differ in relevant ways from the target population to which results are applied. This may result in estimates of prevalence or incidence that do not reflect the experience of the target population. For example, people who agreed to participate in a postal survey of sexual behaviour attended church less often, had less conservative sexual attitudes and earlier age at first sexual intercourse, and were more likely to smoke cigarettes and drink alcohol than people who refused [130]. These differences suggest that postal surveys may overestimate sexual liberalism and activity in the population. Such response bias (see Box 3) can distort exposure-disease associations if associations differ between those eligible for the study and those included in the study. As another example, the association between young maternal age and leukaemia in offspring, which has been observed in some case-control studies [131,132], was explained by differential participation of young women in case and control groups. Young women with healthy children were less likely to participate than those with unhealthy children [133]. Although low participation does not necessarily compromise the validity of a study, transparent information on participation and reasons for non-participation is essential. Also, as there are no universally agreed definitions for participation, response or follow-up rates, readers need to understand how authors calculated such proportions [134].\nIdeally, investigators should give an account of the numbers of individuals considered at each stage of recruiting study participants, from the choice of a target population to the inclusion of participants’ data in the analysis. Depending on the type of study, this may include the number of individuals considered to be potentially eligible, the number assessed for eligibility, the number found to be eligible, the number included in the study, the number examined, the number followed up and the number included in the analysis. Information on different sampling units may be required, if sampling of study participants is carried out in two or more stages as in the example above (multistage sampling). In case-control studies, we advise that authors describe the flow of participants separately for case and control groups [135]. Controls can sometimes be selected from several sources, including, for example, hospitalised patients and community dwellers. In this case, we recommend a separate account of the numbers of participants for each type of control group. Olson and colleagues proposed useful reporting guidelines for controls recruited through random-digit dialling and other methods [136].\nA recent survey of epidemiological studies published in 10 general epidemiology, public health and medical journals found that some information regarding participation was provided in 47 of 107 case-control studies (59%), 49 of 154 cohort studies (32%), and 51 of 86 cross-sectional studies (59%) [137]. Incomplete or absent reporting of participation and non-participation in epidemiological studies was also documented in two other surveys of the literature [4,5]. Finally, there is evidence that participation in epidemiological studies may have declined in recent decades [137,138], which underscores the need for transparent reporting\n\n\n\n\n\n13b. Participants\n\n\n\n\n\n\n\nGive reasons for non-participation at each stage\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nExplaining the reasons why people no longer participated in a study or why they were excluded from statistical analyses helps readers judge whether the study population was representative of the target population and whether bias was possibly introduced. For example, in a cross-sectional health survey, non-participation due to reasons unlikely to be related to health status (for example, the letter of invitation was not delivered because of an incorrect address) will affect the precision of estimates but will probably not introduce bias. Conversely, if many individuals opt out of the survey because of illness, or perceived good health, results may underestimate or overestimate the prevalence of ill health in the population\n\n\n\n\n\n13c. Participants\n\n\n\n\n\n\n\nConsider use of a flow diagram\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nAn informative and well-structured flow diagram can readily and transparently convey information that might otherwise require a lengthy description [142], as in the example above. The diagram may usefully include the main results, such as the number of events for the primary outcome. While we recommend the use of a flow diagram, particularly for complex observational studies, we do not propose a specific format for the diagram\n\n\n\n\n\nDescriptive data\n\n\n14a. Descriptive data\n\n\n\n\n\n\n\nGive characteristics of study participants (eg demographic, clinical, social) and information on exposures and potential confounders. Give information separately for exposed and unexposed groups if applicable. Consider giving information by genotype\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nReaders need descriptions of study participants and their exposures to judge the generalisability of the findings. Information about potential confounders, including whether and how they were measured, influences judgments about study validity. We advise authors to summarize continuous variables for each study group by giving the mean and standard deviation, or when the data have an asymmetrical distribution, as is often the case, the median and percentile range (e.g., 25th and 75th percentiles). Variables that make up a small number of ordered categories (such as stages of disease I to IV) should not be presented as continuous variables; it is preferable to give numbers and proportions for each category (see also Box 4). In studies that compare groups, the descriptive characteristics and numbers should be given by group, as in the example above.\nInferential measures such as standard errors and confidence intervals should not be used to describe the variability of characteristics, and significance tests should be avoided in descriptive tables. Also, P values are not an appropriate criterion for selecting which confounders to adjust for in analysis; even small differences in a confounder that has a strong effect on the outcome can be important.\nIn cohort studies, it may be useful to document how an exposure relates to other characteristics and potential confounders. Authors could present this information in a table with columns for participants in two or more exposure categories, which permits to judge the differences in confounders between these categories.\nIn case-control studies potential confounders cannot be judged by comparing cases and controls. Control persons represent the source population and will usually be different from the cases in many respects. For example, in a study of oral contraceptives and myocardial infarction, a sample of young women with infarction more often had risk factors for that disease, such as high serum cholesterol, smoking and a positive family history, than the control group [146]. This does not influence the assessment of the effect of oral contraceptives, as long as the prescription of oral contraceptives was not guided by the presence of these risk factors—e.g., because the risk factors were only established after the event (see also Box 5). In case-control studies the equivalent of comparing exposed and non-exposed for the presence of potential confounders (as is done in cohorts) can be achieved by exploring the source population of the cases: if the control group is large enough and represents the source population, exposed and unexposed controls can be compared for potential confounders [121,147].\n\n\n\n\n\n14b. Descriptive data\n\n\n\n\n\n\n\nIndicate number of participants with missing data for each variable of interest\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nAs missing data may bias or affect generalisability of results, authors should tell readers amounts of missing data for exposures, potential confounders, and other important characteristics of patients (see also item 12c and Box 6). In a cohort study, authors should report the extent of loss to follow-up (with reasons), since incomplete follow-up may bias findings (see also items 12d and 13). We advise authors to use their tables and figures to enumerate amounts of missing data.\n\n\n\n\n\n14c. Descriptive data\n\n\n\n\n\n\n\nCohort study – Summarize follow-up time, e.g. average and total amount.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nReaders need to know the duration and extent of follow-up for the available outcome data. Authors can present a summary of the average follow-up with either the mean or median follow-up time or both. The mean allows a reader to calculate the total number of person-years by multiplying it with the number of study participants. Authors also may present minimum and maximum times or percentiles of the distribution to show readers the spread of follow-up times. They may report total person-years of follow-up or some indication of the proportion of potential data that was captured [148]. All such information may be presented separately for participants in two or more exposure categories. Almost half of 132 articles in cancer journals (mostly cohort studies) did not give any summary of length of follow-up\n\n\n\n\n\nOutcome data\n\n\n15. Outcome data\n\n\n\n\n\n\n\nCohort study Report numbers of outcome events or summary measures over time.Give information separately for exposed and unexposed groups if applicable. Report outcomes (phenotypes) for each genotype category over time\nCase-control study – Report numbers in each exposure category, or summary measures of exposure.Give information separately for cases and controls . Report numbers in each genotype category. Cross-sectional study – Report numbers of outcome events or summary measures. Give information separately for exposed and unexposed groups if applicable. Report outcomes (phenotypes) for each genotype category\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nBefore addressing the possible association between exposures (risk factors) and outcomes, authors should report relevant descriptive data. It may be possible and meaningful to present measures of association in the same table that presents the descriptive data (see item 14a). In a cohort study with events as outcomes, report the numbers of events for each outcome of interest. Consider reporting the event rate per person-year of follow-up. If the risk of an event changes over follow-up time, present the numbers and rates of events in appropriate intervals of follow-up or as a Kaplan-Meier life table or plot. It might be preferable to show plots as cumulative incidence that go up from 0% rather than down from 100%, especially if the event rate is lower than, say, 30% [153]. Consider presenting such information separately for participants in different exposure categories of interest. If a cohort study is investigating other time-related outcomes (e.g., quantitative disease markers such as blood pressure), present appropriate summary measures (e.g., means and standard deviations) over time, perhaps in a table or figure.\nFor cross-sectional studies, we recommend presenting the same type of information on prevalent outcome events or summary measures. For case-control studies, the focus will be on reporting exposures separately for cases and controls as frequencies or quantitative summaries [154]. For all designs, it may be helpful also to tabulate continuous outcomes or exposures in categories, even if the data are not analysed as such\n\n\n\n\n\nMain results\n\n\n16a. Main results\n\n\n\n\n\n\n\nGive unadjusted estimates and, if applicable, confounder-adjusted estimates and their precision (eg, 95% confidence interval). Make clear which confounders were adjusted for and why they were included\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nIn many situations, authors may present the results of unadjusted or minimally adjusted analyses and those from fully adjusted analyses. We advise giving the unadjusted analyses together with the main data, for example the number of cases and controls that were exposed or not. This allows the reader to understand the data behind the measures of association (see also item 15). For adjusted analyses, report the number of persons in the analysis, as this number may differ because of missing values in covariates (see also item 12c). Estimates should be given with confidence intervals.\nReaders can compare unadjusted measures of association with those adjusted for potential confounders and judge by how much, and in what direction, they changed. Readers may think that ‘adjusted’ results equal the causal part of the measure of association, but adjusted results are not necessarily free of random sampling error, selection bias, information bias, or residual confounding (see Box 5). Thus, great care should be exercised when interpreting adjusted results, as the validity of results often depends crucially on complete knowledge of important confounders, their precise measurement, and appropriate specification in the statistical model (see also item 20) [157,158].\nAuthors should explain all potential confounders considered, and the criteria for excluding or including variables in statistical models. Decisions about excluding or including variables should be guided by knowledge, or explicit assumptions, on causal relations. Inappropriate decisions may introduce bias, for example by including variables that are in the causal pathway between exposure and disease (unless the aim is to asses how much of the effect is carried by the intermediary variable). If the decision to include a variable in the model was based on the change in the estimate, it is important to report what change was considered sufficiently important to justify its inclusion. If a ‘backward deletion’ or ‘forward inclusion’ strategy was used to select confounders, explain that process and give the significance level for rejecting the null hypothesis of no confounding. Of note, we and others do not advise selecting confounders based solely on statistical significance testing [147,159,160].\nRecent studies of the quality of reporting of epidemiological studies found that confidence intervals were reported in most articles [4]. However, few authors explained their choice of confounding variables [4,5].\n\n\n\n\n\n16b. Main results\n\n\n\n\n\n\n\nReport category boundaries when continuous variables were categorized\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nCategorizing continuous data has several important implications for analysis (see Box 4) and also affects the presentation of results. In tables, outcomes should be given for each exposure category, for example as counts of persons at risk, person-time at risk, if relevant separately for each group (e.g., cases and controls). Details of the categories used may aid comparison of studies and meta-analysis. If data were grouped using conventional cut-points, such as body mass index thresholds [162], group boundaries (i.e., range of values) can be derived easily, except for the highest and lowest categories. If quantile-derived categories are used, the category boundaries cannot be inferred from the data. As a minimum, authors should report the category boundaries; it is helpful also to report the range of the data and the mean or median values within categories.\n\n\n\n\n\n16c. Main results\n\n\n\n\n\n\n\nIf relevant, consider translating estimates of relative risk into absolute risk for a meaningful time period\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nThe results from studies examining the association between an exposure and a disease are commonly reported in relative terms, as ratios of risks, rates or odds (see Box 8). Relative measures capture the strength of the association between an exposure and disease. If the relative risk is a long way from 1 it is less likely that the association is due to confounding [164,165]. Relative effects or associations tend to be more consistent across studies and populations than absolute measures, but what often tends to be the case may be irrelevant in a particular instance. For example, similar relative risks were obtained for the classic cardiovascular risk factors for men living in Northern Ireland, France, the USA and Germany, despite the fact that the underlying risk of coronary heart disease varies substantially between these countries [166,167]. In contrast, in a study of hypertension as a risk factor for cardiovascular disease mortality, the data were more compatible with a constant rate difference than with a constant rate ratio [168].\nWidely used statistical models, including logistic [169] and proportional hazards (Cox) regression [170] are based on ratio measures. In these models, only departures from constancy of ratio effect measures are easily discerned. Nevertheless, measures which assess departures from additivity of risk differences, such as the Relative Excess Risk from Interaction (RERI, see item 12b and Box 8), can be estimated in models based on ratio measures.\nIn many circumstances, the absolute risk associated with an exposure is of greater interest than the relative risk. For example, if the focus is on adverse effects of a drug, one will want to know the number of additional cases per unit time of use (e.g., days, weeks, or years). The example gives the additional number of breast cancer cases per 1000 women who used hormone-replacement therapy for 10 years [163]. Measures such as the attributable risk or population attributable fraction may be useful to gauge how much disease can be prevented if the exposure is eliminated. They should preferably be presented together with a measure of statistical uncertainty (e.g., confidence intervals as in the example). Authors should be aware of the strong assumptions made in this context, including a causal relationship between a risk factor and disease (also see Box 7) [171]. Because of the semantic ambiguity and complexities involved, authors should report in detail what methods were used to calculate attributable risks, ideally giving the formulae used [172].\nA recent survey of abstracts of 222 articles published in leading medical journals found that in 62% of abstracts of randomised trials including a ratio measure absolute risks were given, but only in 21% of abstracts of cohort studies [173]. A free text search of Medline 1966 to 1997 showed that 619 items mentioned attributable risks in the title or abstract, compared to 18,955 using relative risk or odds ratio, for a ratio of 1 to 31 [174].\n\n\n\n\n\n16d. Main results\n\n\n\n\n\n\n\nReport results of any adjustments for multiple comparisons\n\n\nOther analyses\n\n\n17a. Other analyses\n\n\n\n\n\n\n\nReport other analyses done—e.g., analyses of subgroups and interactions, and sensitivity analyses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nIn addition to the main analysis other analyses are often done in observational studies. They may address specific subgroups, the potential interaction between risk factors, the calculation of attributable risks, or use alternative definitions of study variables in sensitivity analyses.\nThere is debate about the dangers associated with subgroup analyses, and multiplicity of analyses in general [4,104]. In our opinion, there is too great a tendency to look for evidence of subgroup-specific associations, or effect-measure modification, when overall results appear to suggest little or no effect. On the other hand, there is value in exploring whether an overall association appears consistent across several, preferably pre-specified subgroups especially when a study is large enough to have sufficient data in each subgroup. A second area of debate is about interesting subgroups that arose during the data analysis. They might be important findings, but might also arise by chance. Some argue that it is neither possible nor necessary to inform the reader about all subgroup analyses done as future analyses of other data will tell to what extent the early exciting findings stand the test of time [9]. We advise authors to report which analyses were planned, and which were not (see also items 4, 12b and 20). This will allow readers to judge the implications of multiplicity, taking into account the study’s position on the continuum from discovery to verification or refutation.\nA third area of debate is how joint effects and interactions between risk factors should be evaluated: on additive or multiplicative scales, or should the scale be determined by the statistical model that fits best (see also item 12b and Box 8)? A sensible approach is to report the separate effect of each exposure as well as the joint effect—if possible in a table, as in the first example above [183], or in the study by Martinelli et al. [185]. Such a table gives the reader sufficient information to evaluate additive as well as multiplicative interaction (how these calculations are done is shown in Box 8). Confidence intervals for separate and joint effects may help the reader to judge the strength of the data. In addition, confidence intervals around measures of interaction, such as the Relative Excess Risk from Interaction (RERI) relate to tests of interaction or homogeneity tests. One recurrent problem is that authors use comparisons of P-values across subgroups, which lead to erroneous claims about an effect modifier. For instance, a statistically significant association in one category (e.g., men), but not in the other (e.g., women) does not in itself provide evidence of effect modification. Similarly, the confidence intervals for each point estimate are sometimes inappropriately used to infer that there is no interaction when intervals overlap. A more valid inference is achieved by directly evaluating whether the magnitude of an association differs across subgroups.\nSensitivity analyses are helpful to investigate the influence of choices made in the statistical analysis, or to investigate the robustness of the findings to missing data or possible biases (see also item 12b). Judgement is needed regarding the level of reporting of such analyses. If many sensitivity analyses were performed, it may be impractical to present detailed findings for them all. It may sometimes be sufficient to report that sensitivity analyses were carried out and that they were consistent with the main results presented. Detailed presentation is more appropriate if the issue investigated is of major concern, or if effect estimates vary considerably [59,186].\nPocock and colleagues found that 43 out of 73 articles reporting observational studies contained subgroup analyses. The majority claimed differences across groups but only eight articles reported a formal evaluation of interaction (see item 12b) [4].\n\n\n\n\n\n17b. Other analyses\n\n\n\n\n\n\n\nReport other analyses done—e.g., analyses of subgroups and interactions, and sensitivity analyses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nIf numerous genetic exposures (genetic variants) were examined, summarize results from all analyses undertaken.\n\n\n\n\n\n17c. Other analyses\n\n\n\n\n\n\n\nReport other analyses done—e.g., analyses of subgroups and interactions, and sensitivity analyses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nIf detailed results are available elsewhere, state how they can be accessed.\n\n\n\n\n\nKey results\n\n\n18. Key results\n\n\n\n\n\n\n\nSummarise key results with reference to study objectives\n\n\nLimitations\n\n\n19. Limitations\n\n\n\n\n\n\n\nDiscuss limitations of the study, taking into account sources of potential bias or imprecision. Discuss both direction and magnitude of any potential bias.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nThe identification and discussion of the limitations of a study are an essential part of scientific reporting. It is important not only to identify the sources of bias and confounding that could have affected results, but also to discuss the relative importance of different biases, including the likely direction and magnitude of any potential bias (see also item 9 and Box 3).\nAuthors should also discuss any imprecision of the results. Imprecision may arise in connection with several aspects of a study, including the study size (item 10) and the measurement of exposures, confounders and outcomes (item 8). The inability to precisely measure true values of an exposure tends to result in bias towards unity: the less precisely a risk factor is measured, the greater the bias. This effect has been described as ‘attenuation’ [201,202], or more recently as ‘regression dilution bias’ [203]. However, when correlated risk factors are measured with different degrees of imprecision, the adjusted relative risk associated with them can be biased towards or away from unity [204–206].\nWhen discussing limitations, authors may compare the study being presented with other studies in the literature in terms of validity, generalisability and precision. In this approach, each study can be viewed as contribution to the literature, not as a stand-alone basis for inference and action [207]. Surprisingly, the discussion of important limitations of a study is sometimes omitted from published reports. A survey of authors who had published original research articles in The Lancet found that important weaknesses of the study were reported by the investigators in the survey questionnaires, but not in the published article\n\n\n\n\n\nInterpretation\n\n\n20. Interpretation\n\n\n\n\n\n\n\nGive a cautious overall interpretation considering objectives, limitations, multiplicity of analyses, results from similar studies, and other relevant evidence.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nThe heart of the discussion section is the interpretation of a study’s results. Over-interpretation is common and human: even when we try hard to give an objective assessment, reviewers often rightly point out that we went too far in some respects. When interpreting results, authors should consider the nature of the study on the discovery to verification continuum and potential sources of bias, including loss to follow-up and non-participation (see also items 9, 12 and 19). Due consideration should be given to confounding (item 16a), the results of relevant sensitivity analyses, and to the issue of multiplicity and subgroup analyses (item 17). Authors should also consider residual confounding due to unmeasured variables or imprecise measurement of confounders. For example, socioeconomic status (SES) is associated with many health outcomes and often differs between groups being compared. Variables used to measure SES (income, education, or occupation) are surrogates for other undefined and unmeasured exposures, and the true confounder will by definition be measured with error [208]. Authors should address the real range of uncertainty in estimates, which is larger than the statistical uncertainty reflected in confidence intervals. The latter do not take into account other uncertainties that arise from a study’s design, implementation, and methods of measurement [209].\nTo guide thinking and conclusions about causality, some may find criteria proposed by Bradford Hill in 1965 helpful [164]. How strong is the association with the exposure? Did it precede the onset of disease? Is the association consistently observed in different studies and settings? Is there supporting evidence from experimental studies, including laboratory and animal studies? How specific is the exposure’s putative effect, and is there a dose-response relationship? Is the association biologically plausible? These criteria should not, however, be applied mechanically. For example, some have argued that relative risks below 2 or 3 should be ignored [210,211]. This is a reversal of the point by Cornfield et al. about the strength of large relative risks (see item 12b) [127]. Although a causal effect is more likely with a relative risk of 9, it does not follow that one below 3 is necessarily spurious. For instance, the small increase in the risk of childhood leukaemia after intrauterine irradiation is credible because it concerns an adverse effect of a medical procedure for which no alternative explanations are obvious [212]. Moreover, the carcinogenic effects of radiation are well established. The doubling in the risk of ovarian cancer associated with eating 2 to 4 eggs per week is not immediately credible, since dietary habits are associated with a large number of lifestyle factors as well as SES [213]. In contrast, the credibility of much debated epidemiologic findings of a difference in thrombosis risk between different types of oral contraceptives was greatly enhanced by the differences in coagulation found in a randomised cross-over trial [214]. A discussion of the existing external evidence, from different types of studies, should always be included, but may be particularly important for studies reporting small increases in risk. Further, authors should put their results in context with similar studies and explain how the new study affects the existing body of evidence, ideally by referring to a systematic review.\n\n\n\n\n\nGeneralisability\n\n\n21. Generalisability\n\n\n\n\n\n\n\nDiscuss the generalisability (external validity) of the study results\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nGeneralisability, also called external validity or applicability, is the extent to which the results of a study can be applied to other circumstances [216]. There is no external validity per se; the term is meaningful only with regard to clearly specified conditions [217]. Can results be applied to an individual, groups or populations that differ from those enrolled in the study with regard to age, sex, ethnicity, severity of disease, and co-morbid conditions? Are the nature and level of exposures comparable, and the definitions of outcomes relevant to another setting or population? Are data that were collected in longitudinal studies many years ago still relevant today? Are results from health services research in one country applicable to health systems in other countries?\nThe question of whether the results of a study have external validity is often a matter of judgment that depends on the study setting, the characteristics of the participants, the exposures examined, and the outcomes assessed. Thus, it is crucial that authors provide readers with adequate information about the setting and locations, eligibility criteria, the exposures and how they were measured, the definition of outcomes, and the period of recruitment and follow-up. The degree of non-participation and the proportion of unexposed participants in whom the outcome develops are also relevant. Knowledge of the absolute risk and prevalence of the exposure, which will often vary across populations, are helpful when applying results to other settings and populations (see Box 7)\n\n\n\n\n\nFunding\n\n\n22. Funding\n\n\n\n\n\n\n\nGive the source of funding and the role of the funders for the present study and, if applicable, for the original study on which the present article is based\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nSome journals require authors to disclose the presence or absence of financial and other conflicts of interest [100,218]. Several investigations show strong associations between the source of funding and the conclusions of research articles [219–222]. The conclusions in randomised trials recommended the experimental drug as the drug of choice much more often (odds ratio 5.3) if the trial was funded by for-profit organisations, even after adjustment for the effect size [223]. Other studies document the influence of the tobacco and telecommunication industries on the research they funded [224–227]. There are also examples of undue influence when the sponsor is governmental or a non-profit organisation.\nAuthors or funders may have conflicts of interest that influence any of the following: the design of the study [228]; choice of exposures [228,229], outcomes [230], statistical methods [231], and selective publication of outcomes [230] and studies [232]. Consequently, the role of the funders should be described in detail: in what part of the study they took direct responsibility (e.g., design, data collection, analysis, drafting of manuscript, decision to publish) [100]. Other sources of undue influence include employers (e.g., university administrators for academic researchers and government supervisors, especially political appointees, for government researchers), advisory committees, litigants, and special interest groups"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-1a_title-1",
    "href": "guidelines/strega/index.html#sec-1a_title-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nReaders should be able to easily identify the design that was used from the title or abstract. An explicit, commonly used term for the study design also helps ensure correct indexing of articles in electronic databases"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-1b_abstract-1",
    "href": "guidelines/strega/index.html#sec-1b_abstract-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nThe abstract provides key information that enables readers to understand a study and decide whether to read the article. Typical components include a statement of the research question, a short description of methods and results, and a conclusion. Abstracts should summarize key details of studies and should only present information that is provided in the article. We advise presenting key results in a numerical form that includes numbers of participants, estimates of associations and appropriate measures of variability and uncertainty (e.g., odds ratios with confidence intervals). We regard it insufficient to state only that an exposure is or is not significantly associated with an outcome.\nA series of headings pertaining to the background, design, conduct, and analysis of a study may help readers acquire the essential information rapidly. Many journals require such structured abstracts, which tend to be of higher quality and more readily informative than unstructured summaries."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-2-1",
    "href": "guidelines/strega/index.html#sec-2-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nThe scientific background of the study provides important context for readers. It sets the stage for the study and describes its focus. It gives an overview of what is known on a topic and what gaps in current knowledge are addressed by the study. Background material should note recent pertinent studies and any systematic reviews of pertinent studies."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-3-1",
    "href": "guidelines/strega/index.html#sec-3-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nObjectives are the detailed aims of the study. Well crafted objectives specify populations, exposures and outcomes, and parameters that will be estimated. They may be formulated as specific hypotheses or as questions that the study was designed to address. In some situations objectives may be less specific, for example, in early discovery phases. Regardless, the report should clearly reflect the investigators’ intentions. For example, if important subgroups or additional analyses were not the original aim of the study but arose during data analysis, they should be described accordingly (see also items 4, 17 and 20)."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-4-1",
    "href": "guidelines/strega/index.html#sec-4-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nWe advise presenting key elements of study design early in the methods section (or at the end of the introduction) so that readers can understand the basics of the study. For example, authors should indicate that the study was a cohort study, which followed people over a particular time period, and describe the group of persons that comprised the cohort and their exposure status. Similarly, if the investigation used a case-control design, the cases and controls and their source population should be described. If the study was a cross-sectional survey, the population and the point in time at which the cross-section was taken should be mentioned. When a study is a variant of the three main study types, there is an additional need for clarity. For instance, for a case-crossover study, one of the variants of the case-control design, a succinct description of the principles was given in the example above [28].\nWe recommend that authors refrain from simply calling a study ‘prospective’ or ‘retrospective’ because these terms are ill defined [29]. One usage sees cohort and prospective as synonymous and reserves the word retrospective for case-control studies [30]. A second usage distinguishes prospective and retrospective cohort studies according to the timing of data collection relative to when the idea for the study was developed [31]. A third usage distinguishes prospective and retrospective case-control studies depending on whether the data about the exposure of interest existed when cases were selected [32]. Some advise against using these terms [33], or adopting the alternatives ‘concurrent’ and ‘historical’ for describing cohort studies [34]. In STROBE, we do not use the words prospective and retrospective, nor alternatives such as concurrent and historical. We recommend that, whenever authors use these words, they define what they mean. Most importantly, we recommend that authors describe exactly how and when data collection took place.\nThe first part of the methods section might also be the place to mention whether the report is one of several from a study. If a new report is in line with the original aims of the study, this is usually indicated by referring to an earlier publication and by briefly restating the salient features of the study. However, the aims of a study may also evolve over time. Researchers often use data for purposes for which they were not originally intended, including, for example, official vital statistics that were collected primarily for administrative purposes, items in questionnaires that originally were only included for completeness, or blood samples that were collected for another purpose. For example, the Physicians’ Health Study, a randomized controlled trial of aspirin and carotene, was later used to demonstrate that a point mutation in the factor V gene was associated with an increased risk of venous thrombosis, but not of myocardial infarction or stroke [35]. The secondary use of existing data is a creative part of observational research and does not necessarily make results less credible or less important. However, briefly restating the original aims might help readers understand the context of the research and possible limitations in the data."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-5-1",
    "href": "guidelines/strega/index.html#sec-5-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nReaders need information on setting and locations to assess the context and generalisability of a study’s results. Exposures such as environmental factors and therapies can change over time. Also, study methods may evolve over time. Knowing when a study took place and over what period participants were recruited and followed up places the study in historical context and is important for the interpretation of results.\nInformation about setting includes recruitment sites or sources (e.g., electoral roll, outpatient clinic, cancer registry, or tertiary care centre). Information about location may refer to the countries, towns, hospitals or practices where the investigation took place. We advise stating dates rather than only describing the length of time periods. There may be different sets of dates for exposure, disease occurrence, recruitment, beginning and end of follow-up, and data collection. Of note, nearly 80% of 132 reports in oncology journals that used survival analysis included the starting and ending dates for accrual of patients, but only 24% also reported the date on which follow-up ended [37]."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-6a_-1",
    "href": "guidelines/strega/index.html#sec-6a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nDetailed descriptions of the study participants help readers understand the applicability of the results. Investigators usually restrict a study population by defining clinical, demographic and other characteristics of eligible participants. Typical eligibility criteria relate to age, gender, diagnosis and comorbid conditions. Despite their importance, eligibility criteria often are not reported adequately. In a survey of observational stroke research, 17 of 49 reports (35%) did not specify eligibility criteria [5].\nEligibility criteria may be presented as inclusion and exclusion criteria, although this distinction is not always necessary or useful. Regardless, we advise authors to report all eligibility criteria and also to describe the group from which the study population was selected (e.g., the general population of a region or country), and the method of recruitment (e.g., referral or self-selection through advertisements).\nKnowing details about follow-up procedures, including whether procedures minimized non-response and loss to follow-up and whether the procedures were similar for all participants, informs judgments about the validity of results. For example, in a study that used IgM antibodies to detect acute infections, readers needed to know the interval between blood tests for IgM antibodies so that they could judge whether some infections likely were missed because the interval between blood tests was too long [41]. In other studies where follow-up procedures differed between exposed and unexposed groups, readers might recognize substantial bias due to unequal ascertainment of events or differences in non-response or loss to follow-up [42]. Accordingly, we advise that researchers describe the methods used for following participants and whether those methods were the same for all participants, and that they describe the completeness of ascertainment of variables (see also item 14).\nIn case-control studies, the choice of cases and controls is crucial to interpreting the results, and the method of their selection has major implications for study validity. In general, controls should reflect the population from which the cases arose. Various methods are used to sample controls, all with advantages and disadvantages: for cases that arise from a general population, population roster sampling, random digit dialling, neighbourhood or friend controls are used. Neighbourhood or friend controls may present intrinsic matching on exposure [17]. Controls with other diseases may have advantages over population-based controls, in particular for hospital-based cases, because they better reflect the catchment population of a hospital, have greater comparability of recall and ease of recruitment. However, they can present problems if the exposure of interest affects the risk of developing or being hospitalized for the control condition(s) [43,44]. To remedy this problem often a mixture of the best defensible control diseases is used [45]."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-6b_-1",
    "href": "guidelines/strega/index.html#sec-6b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nMatching is much more common in case-control studies, but occasionally, investigators use matching in cohort studies to make groups comparable at the start of follow-up. Matching in cohort studies makes groups directly comparable for potential confounders and presents fewer intricacies than with case-control studies. For example, it is not necessary to take the matching into account for the estimation of the relative risk [48]. Because matching in cohort studies may increase statistical precision investigators might allow for the matching in their analyses and thus obtain narrower confidence intervals.\nIn case-control studies matching is done to increase a study’s efficiency by ensuring similarity in the distribution of variables between cases and controls, in particular the distribution of potential confounding variables [48,49]. Because matching can be done in various ways, with one or more controls per case, the rationale for the choice of matching variables and the details of the method used should be described. Commonly used forms of matching are frequency matching (also called group matching) and individual matching. In frequency matching, investigators choose controls so that the distribution of matching variables becomes identical or similar to that of cases. Individual matching involves matching one or several controls to each case. Although intuitively appealing and sometimes useful, matching in case-control studies has a number of disadvantages, is not always appropriate, and needs to be taken into account in the analysis"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-7a_-1",
    "href": "guidelines/strega/index.html#sec-7a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nAuthors should define all variables considered for and included in the analysis, including outcomes, exposures, predictors, potential confounders and potential effect modifiers. Disease outcomes require adequately detailed description of the diagnostic criteria. This applies to criteria for cases in a case-control study, disease events during follow-up in a cohort study and prevalent disease in a cross-sectional study. Clear definitions and steps taken to adhere to them are particularly important for any disease condition of primary interest in the study.\nFor some studies, ‘determinant’ or ‘predictor’ may be appropriate terms for exposure variables and outcomes may be called ‘endpoints’. In multivariable models, authors sometimes use ‘dependent variable’ for an outcome and ‘independent variable’ or ‘explanatory variable’ for exposure and confounding variables. The latter is not precise as it does not distinguish exposures from confounders.\nIf many variables have been measured and included in exploratory analyses in an early discovery phase, consider providing a list with details on each variable in an appendix, additional table or separate publication. Of note, the International Journal of Epidemiology recently launched a new section with ‘cohort profiles’, that includes detailed information on what was measured at different points in time in particular studies [56,57]. Finally, we advise that authors declare all ‘candidate variables’ considered for statistical analysis, rather than selectively reporting only those included in the final models (see also item 16a) [58,59]"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-8a_-1",
    "href": "guidelines/strega/index.html#sec-8a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nThe way in which exposures, confounders and outcomes were measured affects the reliability and validity of a study. Measurement error and misclassification of exposures or outcomes can make it more difficult to detect cause-effect relationships, or may produce spurious relationships. Error in measurement of potential confounders can increase the risk of residual confounding [62,63]. It is helpful, therefore, if authors report the findings of any studies of the validity or reliability of assessments or measurements, including details of the reference standard that was used. Rather than simply citing validation studies (as in the first example), we advise that authors give the estimated validity or reliability, which can then be used for measurement error adjustment or sensitivity analyses (see items 12e and 17).\nIn addition, it is important to know if groups being compared differed with respect to the way in which the data were collected. This may be important for laboratory examinations (as in the second example) and other situations. For instance, if an interviewer first questions all the cases and then the controls, or vice versa, bias is possible because of the learning curve; solutions such as randomising the order of interviewing may avoid this problem. Information bias may also arise if the compared groups are not given the same diagnostic tests or if one group receives more tests of the same kind than another (see also item 9)."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-9a_-1",
    "href": "guidelines/strega/index.html#sec-9a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nBiased studies produce results that differ systematically from the truth (see also Box 3). It is important for a reader to know what measures were taken during the conduct of a study to reduce the potential of bias. Ideally, investigators carefully consider potential sources of bias when they plan their study. At the stage of reporting, we recommend that authors always assess the likelihood of relevant biases. Specifically, the direction and magnitude of bias should be discussed and, if possible, estimated. For instance, in case-control studies information bias can occur, but may be reduced by selecting an appropriate control group, as in the first example [64]. Differences in the medical surveillance of participants were a problem in the second example [65]. Consequently, the authors provide more detail about the additional data they collected to tackle this problem. When investigators have set up quality control programs for data collection to counter a possible “drift” in measurements of variables in longitudinal studies, or to keep variability at a minimum when multiple observers are used, these should be described.\nUnfortunately, authors often do not address important biases when reporting their results. Among 43 case-control and cohort studies published from 1990 to 1994 that investigated the risk of second cancers in patients with a history of cancer, medical surveillance bias was mentioned in only 5 articles [66]. A survey of reports of mental health research published during 1998 in three psychiatric journals found that only 13% of 392 articles mentioned response bias [67]. A survey of cohort studies in stroke research found that 14 of 49 (28%) articles published from 1999 to 2003 addressed potential selection bias in the recruitment of study participants and 35 (71%) mentioned the possibility that any type of bias may have affected results"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-9b_-1",
    "href": "guidelines/strega/index.html#sec-9b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nFor quantitative outcome variables, specify if any investigation of potential bias resulting from pharmacotherapy was undertaken. If relevant, describe the nature and magnitude of the potential bias, and explain what approach was used to deal with this."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-10-1",
    "href": "guidelines/strega/index.html#sec-10-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nA study should be large enough to obtain a point estimate with a sufficiently narrow confidence interval to meaningfully answer a research question. Large samples are needed to distinguish a small association from no association. Small studies often provide valuable information, but wide confidence intervals may indicate that they contribute less to current knowledge in comparison with studies providing estimates with narrower confidence intervals. Also, small studies that show ‘interesting’ or ‘statistically significant’ associations are published more frequently than small studies that do not have ‘significant’ findings. While these studies may provide an early signal in the context of discovery, readers should be informed of their potential weaknesses.\nThe importance of sample size determination in observational studies depends on the context. If an analysis is performed on data that were already available for other purposes, the main question is whether the analysis of the data will produce results with sufficient statistical precision to contribute substantially to the literature, and sample size considerations will be informal. Formal, a priori calculation of sample size may be useful when planning a new study. Such calculations are associated with more uncertainty than implied by the single number that is generally produced. For example, estimates of the rate of the event of interest or other assumptions central to calculations are commonly imprecise, if not guesswork. The precision obtained in the final analysis can often not be determined beforehand because it will be reduced by inclusion of confounding variables in multivariable analyses, the degree of precision with which key variables can be measured, and the exclusion of some individuals.\nFew epidemiological studies explain or report deliberations about sample size. We encourage investigators to report pertinent formal sample size calculations if they were done. In other situations they should indicate the considerations that determined the study size (e.g., a fixed available sample, as in the first example above). If the observational study was stopped early when statistical significance was achieved, readers should be told. Do not bother readers with post hoc justifications for study size or retrospective power calculations. From the point of view of the reader, confidence intervals indicate the statistical precision that was ultimately obtained. It should be realized that confidence intervals reflect statistical uncertainty only, and not all uncertainty that may be present in a study (see item 20)."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-11-1",
    "href": "guidelines/strega/index.html#sec-11-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nInvestigators make choices regarding how to collect and analyse quantitative data about exposures, effect modifiers and confounders. For example, they may group a continuous exposure variable to create a new categorical variable. Grouping choices may have important consequences for later analyses. We advise that authors explain why and how they grouped quantitative data, including the number of categories, the cut-points, and category mean or median values. Whenever data are reported in tabular form, the counts of cases, controls, persons at risk, person-time at risk, etc. should be given for each category. Tables should not consist solely of effect-measure estimates or results of model fitting.\nInvestigators might model an exposure as continuous in order to retain all the information. In making this choice, one needs to consider the nature of the relationship of the exposure to the outcome. As it may be wrong to assume a linear relation automatically, possible departures from linearity should be investigated. Authors could mention alternative models they explored during analyses (e.g., using log transformation, quadratic terms or spline functions). Several methods exist for fitting a non-linear relation between the exposure and outcome. Also, it may be informative to present both continuous and grouped analyses for a quantitative exposure of prime interest.\nIn a recent survey, two thirds of epidemiological publications studied quantitative exposure variables. In 42 of 50 articles (84%) exposures were grouped into several ordered categories, but often without any stated rationale for the choices made. Fifteen articles used linear associations to model continuous exposure but only two reported checking for linearity. In another survey, of the psychological literature, dichotomization was justified in only 22 of 110 articles (20%)"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-12a_-1",
    "href": "guidelines/strega/index.html#sec-12a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nIn general, there is no one correct statistical analysis but, rather, several possibilities that may address the same question, but make different assumptions. Regardless, investigators should pre-determine analyses at least for the primary study objectives in a study protocol. Often additional analyses are needed, either instead of, or as well as, those originally envisaged, and these may sometimes be motivated by the data. When a study is reported, authors should tell readers whether particular analyses were suggested by data inspection. Even though the distinction between pre-specified and exploratory analyses may sometimes be blurred, authors should clarify reasons for particular analyses.\nIf groups being compared are not similar with regard to some characteristics, adjustment should be made for possible confounding variables by stratification or by multivariable regression (see Box 5) [94]. Often, the study design determines which type of regression analysis is chosen. For instance, Cox proportional hazard regression is commonly used in cohort studies [95]. whereas logistic regression is often the method of choice in case-control studies [96,97]. Analysts should fully describe specific procedures for variable selection and not only present results from the final model [98,99]. If model comparisons are made to narrow down a list of potential confounders for inclusion in a final model, this process should be described. It is helpful to tell readers if one or two covariates are responsible for a great deal of the apparent confounding in a data analysis. Other statistical analyses such as imputation procedures, data transformation, and calculations of attributable risks should also be described. Non-standard or novel approaches should be referenced and the statistical software used reported. As a guiding principle, we advise statistical methods be described “with enough detail to enable a knowledgeable reader with access to the original data to verify the reported results” [100].\nIn an empirical study, only 93 of 169 articles (55%) reporting adjustment for confounding clearly stated how continuous and multi-category variables were entered into the statistical model [101]. Another study found that among 67 articles in which statistical analyses were adjusted for confounders, it was mostly unclear how confounders were chosen"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-12b_-1",
    "href": "guidelines/strega/index.html#sec-12b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nAs discussed in detail under item 17, many debate the use and value of analyses restricted to subgroups of the study population [4,104]. Subgroup analyses are nevertheless often done [4]. Readers need to know which subgroup analyses were planned in advance, and which arose while analysing the data. Also, it is important to explain what methods were used to examine whether effects or associations differed across groups (see item 17).\nInteraction relates to the situation when one factor modifies the effect of another (therefore also called ‘effect modification’). The joint action of two factors can be characterized in two ways: on an additive scale, in terms of risk differences; or on a multiplicative scale, in terms of relative risk (see Box 8). Many authors and readers may have their own preference about the way interactions should be analysed. Still, they may be interested to know to what extent the joint effect of exposures differs from the separate effects. There is consensus that the additive scale, which uses absolute risks, is more appropriate for public health and clinical decision making [105]. Whatever view is taken, this should be clearly presented to the reader, as is done in the example above [103]. A lay-out presenting separate effects of both exposures as well as their joint effect, each relative to no exposure, might be most informative. It is presented in the example for interaction under item 17, and the calculations on the different scales are explained in Box 8"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-12c_-1",
    "href": "guidelines/strega/index.html#sec-12c_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nMissing data are common in observational research. Questionnaires posted to study participants are not always filled in completely, participants may not attend all follow-up visits and routine data sources and clinical databases are often incomplete. Despite its ubiquity and importance, few papers report in detail on the problem of missing data [5,107]. Investigators may use any of several approaches to address missing data. We describe some strengths and limitations of various approaches in Box 6. We advise that authors report the number of missing values for each variable of interest (exposures, outcomes, confounders) and for each step in the analysis. Authors should give reasons for missing values if possible, and indicate how many individuals were excluded because of missing data when describing the flow of participants through the study (see also item 13). For analyses that account for missing data, authors should describe the nature of the analysis (e.g., multiple imputation) and the assumptions that were made (e.g., missing at random, see Box 6)."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-12d_-1",
    "href": "guidelines/strega/index.html#sec-12d_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nCohort studies are analysed using life table methods or other approaches that are based on the person-time of follow-up and time to developing the disease of interest. Among individuals who remain free of the disease at the end of their observation period, the amount of follow-up time is assumed to be unrelated to the probability of developing the outcome. This will be the case if follow-up ends on a fixed date or at a particular age. Loss to follow-up occurs when participants withdraw from a study before that date. This may hamper the validity of a study if loss to follow-up occurs selectively in exposed individuals, or in persons at high risk of developing the disease (‘informative censoring’). In the example above, patients lost to follow-up in treatment programmes with no active follow-up had fewer CD4 helper cells than those remaining under observation and were therefore at higher risk of dying [116].\nIt is important to distinguish persons who reach the end of the study from those lost to follow-up. Unfortunately, statistical software usually does not distinguish between the two situations: in both cases follow-up time is automatically truncated (‘censored’) at the end of the observation period. Investigators therefore need to decide, ideally at the stage of planning the study, how they will deal with loss to follow-up. When few patients are lost, investigators may either exclude individuals with incomplete follow-up, or treat them as if they withdrew alive at either the date of loss to follow-up or the end of the study. We advise authors to report how many patients were lost to follow-up and what censoring strategies they used"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-12e_-1",
    "href": "guidelines/strega/index.html#sec-12e_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nSensitivity analyses are useful to investigate whether or not the main results are consistent with those obtained with alternative analysis strategies or assumptions [121]. Issues that may be examined include the criteria for inclusion in analyses, the definitions of exposures or outcomes [122], which confounding variables merit adjustment, the handling of missing data [120,123], possible selection bias or bias from inaccurate or inconsistent measurement of exposure, disease and other variables, and specific analysis choices, such as the treatment of quantitative variables (see item 11). Sophisticated methods are increasingly used to simultaneously model the influence of several biases or assumptions [124–126].\nIn 1959 Cornfield et al. famously showed that a relative risk of 9 for cigarette smoking and lung cancer was extremely unlikely to be due to any conceivable confounder, since the confounder would need to be at least nine times as prevalent in smokers as in non-smokers [127]. This analysis did not rule out the possibility that such a factor was present, but it did identify the prevalence such a factor would need to have. The same approach was recently used to identify plausible confounding factors that could explain the association between childhood leukaemia and living near electric power lines [128]. More generally, sensitivity analyses can be used to identify the degree of confounding, selection bias, or information bias required to distort an association. One important, perhaps under recognised, use of sensitivity analysis is when a study shows little or no association between an exposure and an outcome and it is plausible that confounding or other biases toward the null are present"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-13a_-1",
    "href": "guidelines/strega/index.html#sec-13a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nDetailed information on the process of recruiting study participants is important for several reasons. Those included in a study often differ in relevant ways from the target population to which results are applied. This may result in estimates of prevalence or incidence that do not reflect the experience of the target population. For example, people who agreed to participate in a postal survey of sexual behaviour attended church less often, had less conservative sexual attitudes and earlier age at first sexual intercourse, and were more likely to smoke cigarettes and drink alcohol than people who refused [130]. These differences suggest that postal surveys may overestimate sexual liberalism and activity in the population. Such response bias (see Box 3) can distort exposure-disease associations if associations differ between those eligible for the study and those included in the study. As another example, the association between young maternal age and leukaemia in offspring, which has been observed in some case-control studies [131,132], was explained by differential participation of young women in case and control groups. Young women with healthy children were less likely to participate than those with unhealthy children [133]. Although low participation does not necessarily compromise the validity of a study, transparent information on participation and reasons for non-participation is essential. Also, as there are no universally agreed definitions for participation, response or follow-up rates, readers need to understand how authors calculated such proportions [134].\nIdeally, investigators should give an account of the numbers of individuals considered at each stage of recruiting study participants, from the choice of a target population to the inclusion of participants’ data in the analysis. Depending on the type of study, this may include the number of individuals considered to be potentially eligible, the number assessed for eligibility, the number found to be eligible, the number included in the study, the number examined, the number followed up and the number included in the analysis. Information on different sampling units may be required, if sampling of study participants is carried out in two or more stages as in the example above (multistage sampling). In case-control studies, we advise that authors describe the flow of participants separately for case and control groups [135]. Controls can sometimes be selected from several sources, including, for example, hospitalised patients and community dwellers. In this case, we recommend a separate account of the numbers of participants for each type of control group. Olson and colleagues proposed useful reporting guidelines for controls recruited through random-digit dialling and other methods [136].\nA recent survey of epidemiological studies published in 10 general epidemiology, public health and medical journals found that some information regarding participation was provided in 47 of 107 case-control studies (59%), 49 of 154 cohort studies (32%), and 51 of 86 cross-sectional studies (59%) [137]. Incomplete or absent reporting of participation and non-participation in epidemiological studies was also documented in two other surveys of the literature [4,5]. Finally, there is evidence that participation in epidemiological studies may have declined in recent decades [137,138], which underscores the need for transparent reporting"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-13b_-1",
    "href": "guidelines/strega/index.html#sec-13b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nExplaining the reasons why people no longer participated in a study or why they were excluded from statistical analyses helps readers judge whether the study population was representative of the target population and whether bias was possibly introduced. For example, in a cross-sectional health survey, non-participation due to reasons unlikely to be related to health status (for example, the letter of invitation was not delivered because of an incorrect address) will affect the precision of estimates but will probably not introduce bias. Conversely, if many individuals opt out of the survey because of illness, or perceived good health, results may underestimate or overestimate the prevalence of ill health in the population"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-13c_-1",
    "href": "guidelines/strega/index.html#sec-13c_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nAn informative and well-structured flow diagram can readily and transparently convey information that might otherwise require a lengthy description [142], as in the example above. The diagram may usefully include the main results, such as the number of events for the primary outcome. While we recommend the use of a flow diagram, particularly for complex observational studies, we do not propose a specific format for the diagram"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-14a_-1",
    "href": "guidelines/strega/index.html#sec-14a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nReaders need descriptions of study participants and their exposures to judge the generalisability of the findings. Information about potential confounders, including whether and how they were measured, influences judgments about study validity. We advise authors to summarize continuous variables for each study group by giving the mean and standard deviation, or when the data have an asymmetrical distribution, as is often the case, the median and percentile range (e.g., 25th and 75th percentiles). Variables that make up a small number of ordered categories (such as stages of disease I to IV) should not be presented as continuous variables; it is preferable to give numbers and proportions for each category (see also Box 4). In studies that compare groups, the descriptive characteristics and numbers should be given by group, as in the example above.\nInferential measures such as standard errors and confidence intervals should not be used to describe the variability of characteristics, and significance tests should be avoided in descriptive tables. Also, P values are not an appropriate criterion for selecting which confounders to adjust for in analysis; even small differences in a confounder that has a strong effect on the outcome can be important.\nIn cohort studies, it may be useful to document how an exposure relates to other characteristics and potential confounders. Authors could present this information in a table with columns for participants in two or more exposure categories, which permits to judge the differences in confounders between these categories.\nIn case-control studies potential confounders cannot be judged by comparing cases and controls. Control persons represent the source population and will usually be different from the cases in many respects. For example, in a study of oral contraceptives and myocardial infarction, a sample of young women with infarction more often had risk factors for that disease, such as high serum cholesterol, smoking and a positive family history, than the control group [146]. This does not influence the assessment of the effect of oral contraceptives, as long as the prescription of oral contraceptives was not guided by the presence of these risk factors—e.g., because the risk factors were only established after the event (see also Box 5). In case-control studies the equivalent of comparing exposed and non-exposed for the presence of potential confounders (as is done in cohorts) can be achieved by exploring the source population of the cases: if the control group is large enough and represents the source population, exposed and unexposed controls can be compared for potential confounders [121,147]."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-14b_-1",
    "href": "guidelines/strega/index.html#sec-14b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nAs missing data may bias or affect generalisability of results, authors should tell readers amounts of missing data for exposures, potential confounders, and other important characteristics of patients (see also item 12c and Box 6). In a cohort study, authors should report the extent of loss to follow-up (with reasons), since incomplete follow-up may bias findings (see also items 12d and 13). We advise authors to use their tables and figures to enumerate amounts of missing data."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-14c_-1",
    "href": "guidelines/strega/index.html#sec-14c_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nReaders need to know the duration and extent of follow-up for the available outcome data. Authors can present a summary of the average follow-up with either the mean or median follow-up time or both. The mean allows a reader to calculate the total number of person-years by multiplying it with the number of study participants. Authors also may present minimum and maximum times or percentiles of the distribution to show readers the spread of follow-up times. They may report total person-years of follow-up or some indication of the proportion of potential data that was captured [148]. All such information may be presented separately for participants in two or more exposure categories. Almost half of 132 articles in cancer journals (mostly cohort studies) did not give any summary of length of follow-up"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-15-1",
    "href": "guidelines/strega/index.html#sec-15-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nBefore addressing the possible association between exposures (risk factors) and outcomes, authors should report relevant descriptive data. It may be possible and meaningful to present measures of association in the same table that presents the descriptive data (see item 14a). In a cohort study with events as outcomes, report the numbers of events for each outcome of interest. Consider reporting the event rate per person-year of follow-up. If the risk of an event changes over follow-up time, present the numbers and rates of events in appropriate intervals of follow-up or as a Kaplan-Meier life table or plot. It might be preferable to show plots as cumulative incidence that go up from 0% rather than down from 100%, especially if the event rate is lower than, say, 30% [153]. Consider presenting such information separately for participants in different exposure categories of interest. If a cohort study is investigating other time-related outcomes (e.g., quantitative disease markers such as blood pressure), present appropriate summary measures (e.g., means and standard deviations) over time, perhaps in a table or figure.\nFor cross-sectional studies, we recommend presenting the same type of information on prevalent outcome events or summary measures. For case-control studies, the focus will be on reporting exposures separately for cases and controls as frequencies or quantitative summaries [154]. For all designs, it may be helpful also to tabulate continuous outcomes or exposures in categories, even if the data are not analysed as such"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-16a_-1",
    "href": "guidelines/strega/index.html#sec-16a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nIn many situations, authors may present the results of unadjusted or minimally adjusted analyses and those from fully adjusted analyses. We advise giving the unadjusted analyses together with the main data, for example the number of cases and controls that were exposed or not. This allows the reader to understand the data behind the measures of association (see also item 15). For adjusted analyses, report the number of persons in the analysis, as this number may differ because of missing values in covariates (see also item 12c). Estimates should be given with confidence intervals.\nReaders can compare unadjusted measures of association with those adjusted for potential confounders and judge by how much, and in what direction, they changed. Readers may think that ‘adjusted’ results equal the causal part of the measure of association, but adjusted results are not necessarily free of random sampling error, selection bias, information bias, or residual confounding (see Box 5). Thus, great care should be exercised when interpreting adjusted results, as the validity of results often depends crucially on complete knowledge of important confounders, their precise measurement, and appropriate specification in the statistical model (see also item 20) [157,158].\nAuthors should explain all potential confounders considered, and the criteria for excluding or including variables in statistical models. Decisions about excluding or including variables should be guided by knowledge, or explicit assumptions, on causal relations. Inappropriate decisions may introduce bias, for example by including variables that are in the causal pathway between exposure and disease (unless the aim is to asses how much of the effect is carried by the intermediary variable). If the decision to include a variable in the model was based on the change in the estimate, it is important to report what change was considered sufficiently important to justify its inclusion. If a ‘backward deletion’ or ‘forward inclusion’ strategy was used to select confounders, explain that process and give the significance level for rejecting the null hypothesis of no confounding. Of note, we and others do not advise selecting confounders based solely on statistical significance testing [147,159,160].\nRecent studies of the quality of reporting of epidemiological studies found that confidence intervals were reported in most articles [4]. However, few authors explained their choice of confounding variables [4,5]."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-16b_-1",
    "href": "guidelines/strega/index.html#sec-16b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nCategorizing continuous data has several important implications for analysis (see Box 4) and also affects the presentation of results. In tables, outcomes should be given for each exposure category, for example as counts of persons at risk, person-time at risk, if relevant separately for each group (e.g., cases and controls). Details of the categories used may aid comparison of studies and meta-analysis. If data were grouped using conventional cut-points, such as body mass index thresholds [162], group boundaries (i.e., range of values) can be derived easily, except for the highest and lowest categories. If quantile-derived categories are used, the category boundaries cannot be inferred from the data. As a minimum, authors should report the category boundaries; it is helpful also to report the range of the data and the mean or median values within categories."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-16c_-1",
    "href": "guidelines/strega/index.html#sec-16c_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nThe results from studies examining the association between an exposure and a disease are commonly reported in relative terms, as ratios of risks, rates or odds (see Box 8). Relative measures capture the strength of the association between an exposure and disease. If the relative risk is a long way from 1 it is less likely that the association is due to confounding [164,165]. Relative effects or associations tend to be more consistent across studies and populations than absolute measures, but what often tends to be the case may be irrelevant in a particular instance. For example, similar relative risks were obtained for the classic cardiovascular risk factors for men living in Northern Ireland, France, the USA and Germany, despite the fact that the underlying risk of coronary heart disease varies substantially between these countries [166,167]. In contrast, in a study of hypertension as a risk factor for cardiovascular disease mortality, the data were more compatible with a constant rate difference than with a constant rate ratio [168].\nWidely used statistical models, including logistic [169] and proportional hazards (Cox) regression [170] are based on ratio measures. In these models, only departures from constancy of ratio effect measures are easily discerned. Nevertheless, measures which assess departures from additivity of risk differences, such as the Relative Excess Risk from Interaction (RERI, see item 12b and Box 8), can be estimated in models based on ratio measures.\nIn many circumstances, the absolute risk associated with an exposure is of greater interest than the relative risk. For example, if the focus is on adverse effects of a drug, one will want to know the number of additional cases per unit time of use (e.g., days, weeks, or years). The example gives the additional number of breast cancer cases per 1000 women who used hormone-replacement therapy for 10 years [163]. Measures such as the attributable risk or population attributable fraction may be useful to gauge how much disease can be prevented if the exposure is eliminated. They should preferably be presented together with a measure of statistical uncertainty (e.g., confidence intervals as in the example). Authors should be aware of the strong assumptions made in this context, including a causal relationship between a risk factor and disease (also see Box 7) [171]. Because of the semantic ambiguity and complexities involved, authors should report in detail what methods were used to calculate attributable risks, ideally giving the formulae used [172].\nA recent survey of abstracts of 222 articles published in leading medical journals found that in 62% of abstracts of randomised trials including a ratio measure absolute risks were given, but only in 21% of abstracts of cohort studies [173]. A free text search of Medline 1966 to 1997 showed that 619 items mentioned attributable risks in the title or abstract, compared to 18,955 using relative risk or odds ratio, for a ratio of 1 to 31 [174]."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-17a_-1",
    "href": "guidelines/strega/index.html#sec-17a_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nIn addition to the main analysis other analyses are often done in observational studies. They may address specific subgroups, the potential interaction between risk factors, the calculation of attributable risks, or use alternative definitions of study variables in sensitivity analyses.\nThere is debate about the dangers associated with subgroup analyses, and multiplicity of analyses in general [4,104]. In our opinion, there is too great a tendency to look for evidence of subgroup-specific associations, or effect-measure modification, when overall results appear to suggest little or no effect. On the other hand, there is value in exploring whether an overall association appears consistent across several, preferably pre-specified subgroups especially when a study is large enough to have sufficient data in each subgroup. A second area of debate is about interesting subgroups that arose during the data analysis. They might be important findings, but might also arise by chance. Some argue that it is neither possible nor necessary to inform the reader about all subgroup analyses done as future analyses of other data will tell to what extent the early exciting findings stand the test of time [9]. We advise authors to report which analyses were planned, and which were not (see also items 4, 12b and 20). This will allow readers to judge the implications of multiplicity, taking into account the study’s position on the continuum from discovery to verification or refutation.\nA third area of debate is how joint effects and interactions between risk factors should be evaluated: on additive or multiplicative scales, or should the scale be determined by the statistical model that fits best (see also item 12b and Box 8)? A sensible approach is to report the separate effect of each exposure as well as the joint effect—if possible in a table, as in the first example above [183], or in the study by Martinelli et al. [185]. Such a table gives the reader sufficient information to evaluate additive as well as multiplicative interaction (how these calculations are done is shown in Box 8). Confidence intervals for separate and joint effects may help the reader to judge the strength of the data. In addition, confidence intervals around measures of interaction, such as the Relative Excess Risk from Interaction (RERI) relate to tests of interaction or homogeneity tests. One recurrent problem is that authors use comparisons of P-values across subgroups, which lead to erroneous claims about an effect modifier. For instance, a statistically significant association in one category (e.g., men), but not in the other (e.g., women) does not in itself provide evidence of effect modification. Similarly, the confidence intervals for each point estimate are sometimes inappropriately used to infer that there is no interaction when intervals overlap. A more valid inference is achieved by directly evaluating whether the magnitude of an association differs across subgroups.\nSensitivity analyses are helpful to investigate the influence of choices made in the statistical analysis, or to investigate the robustness of the findings to missing data or possible biases (see also item 12b). Judgement is needed regarding the level of reporting of such analyses. If many sensitivity analyses were performed, it may be impractical to present detailed findings for them all. It may sometimes be sufficient to report that sensitivity analyses were carried out and that they were consistent with the main results presented. Detailed presentation is more appropriate if the issue investigated is of major concern, or if effect estimates vary considerably [59,186].\nPocock and colleagues found that 43 out of 73 articles reporting observational studies contained subgroup analyses. The majority claimed differences across groups but only eight articles reported a formal evaluation of interaction (see item 12b) [4]."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-17b_-1",
    "href": "guidelines/strega/index.html#sec-17b_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nIf numerous genetic exposures (genetic variants) were examined, summarize results from all analyses undertaken."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-17c_-1",
    "href": "guidelines/strega/index.html#sec-17c_-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nIf detailed results are available elsewhere, state how they can be accessed."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-19-1",
    "href": "guidelines/strega/index.html#sec-19-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nThe identification and discussion of the limitations of a study are an essential part of scientific reporting. It is important not only to identify the sources of bias and confounding that could have affected results, but also to discuss the relative importance of different biases, including the likely direction and magnitude of any potential bias (see also item 9 and Box 3).\nAuthors should also discuss any imprecision of the results. Imprecision may arise in connection with several aspects of a study, including the study size (item 10) and the measurement of exposures, confounders and outcomes (item 8). The inability to precisely measure true values of an exposure tends to result in bias towards unity: the less precisely a risk factor is measured, the greater the bias. This effect has been described as ‘attenuation’ [201,202], or more recently as ‘regression dilution bias’ [203]. However, when correlated risk factors are measured with different degrees of imprecision, the adjusted relative risk associated with them can be biased towards or away from unity [204–206].\nWhen discussing limitations, authors may compare the study being presented with other studies in the literature in terms of validity, generalisability and precision. In this approach, each study can be viewed as contribution to the literature, not as a stand-alone basis for inference and action [207]. Surprisingly, the discussion of important limitations of a study is sometimes omitted from published reports. A survey of authors who had published original research articles in The Lancet found that important weaknesses of the study were reported by the investigators in the survey questionnaires, but not in the published article"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-20-1",
    "href": "guidelines/strega/index.html#sec-20-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nThe heart of the discussion section is the interpretation of a study’s results. Over-interpretation is common and human: even when we try hard to give an objective assessment, reviewers often rightly point out that we went too far in some respects. When interpreting results, authors should consider the nature of the study on the discovery to verification continuum and potential sources of bias, including loss to follow-up and non-participation (see also items 9, 12 and 19). Due consideration should be given to confounding (item 16a), the results of relevant sensitivity analyses, and to the issue of multiplicity and subgroup analyses (item 17). Authors should also consider residual confounding due to unmeasured variables or imprecise measurement of confounders. For example, socioeconomic status (SES) is associated with many health outcomes and often differs between groups being compared. Variables used to measure SES (income, education, or occupation) are surrogates for other undefined and unmeasured exposures, and the true confounder will by definition be measured with error [208]. Authors should address the real range of uncertainty in estimates, which is larger than the statistical uncertainty reflected in confidence intervals. The latter do not take into account other uncertainties that arise from a study’s design, implementation, and methods of measurement [209].\nTo guide thinking and conclusions about causality, some may find criteria proposed by Bradford Hill in 1965 helpful [164]. How strong is the association with the exposure? Did it precede the onset of disease? Is the association consistently observed in different studies and settings? Is there supporting evidence from experimental studies, including laboratory and animal studies? How specific is the exposure’s putative effect, and is there a dose-response relationship? Is the association biologically plausible? These criteria should not, however, be applied mechanically. For example, some have argued that relative risks below 2 or 3 should be ignored [210,211]. This is a reversal of the point by Cornfield et al. about the strength of large relative risks (see item 12b) [127]. Although a causal effect is more likely with a relative risk of 9, it does not follow that one below 3 is necessarily spurious. For instance, the small increase in the risk of childhood leukaemia after intrauterine irradiation is credible because it concerns an adverse effect of a medical procedure for which no alternative explanations are obvious [212]. Moreover, the carcinogenic effects of radiation are well established. The doubling in the risk of ovarian cancer associated with eating 2 to 4 eggs per week is not immediately credible, since dietary habits are associated with a large number of lifestyle factors as well as SES [213]. In contrast, the credibility of much debated epidemiologic findings of a difference in thrombosis risk between different types of oral contraceptives was greatly enhanced by the differences in coagulation found in a randomised cross-over trial [214]. A discussion of the existing external evidence, from different types of studies, should always be included, but may be particularly important for studies reporting small increases in risk. Further, authors should put their results in context with similar studies and explain how the new study affects the existing body of evidence, ideally by referring to a systematic review."
  },
  {
    "objectID": "guidelines/strega/index.html#sec-21-1",
    "href": "guidelines/strega/index.html#sec-21-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nGeneralisability, also called external validity or applicability, is the extent to which the results of a study can be applied to other circumstances [216]. There is no external validity per se; the term is meaningful only with regard to clearly specified conditions [217]. Can results be applied to an individual, groups or populations that differ from those enrolled in the study with regard to age, sex, ethnicity, severity of disease, and co-morbid conditions? Are the nature and level of exposures comparable, and the definitions of outcomes relevant to another setting or population? Are data that were collected in longitudinal studies many years ago still relevant today? Are results from health services research in one country applicable to health systems in other countries?\nThe question of whether the results of a study have external validity is often a matter of judgment that depends on the study setting, the characteristics of the participants, the exposures examined, and the outcomes assessed. Thus, it is crucial that authors provide readers with adequate information about the setting and locations, eligibility criteria, the exposures and how they were measured, the definition of outcomes, and the period of recruitment and follow-up. The degree of non-participation and the proportion of unexposed participants in whom the outcome develops are also relevant. Knowledge of the absolute risk and prevalence of the exposure, which will often vary across populations, are helpful when applying results to other settings and populations (see Box 7)"
  },
  {
    "objectID": "guidelines/strega/index.html#sec-22-1",
    "href": "guidelines/strega/index.html#sec-22-1",
    "title": "The STREGA guideline for writing a genetic association study.",
    "section": "Read More",
    "text": "Read More\nSome journals require authors to disclose the presence or absence of financial and other conflicts of interest [100,218]. Several investigations show strong associations between the source of funding and the conclusions of research articles [219–222]. The conclusions in randomised trials recommended the experimental drug as the drug of choice much more often (odds ratio 5.3) if the trial was funded by for-profit organisations, even after adjustment for the effect size [223]. Other studies document the influence of the tobacco and telecommunication industries on the research they funded [224–227]. There are also examples of undue influence when the sponsor is governmental or a non-profit organisation.\nAuthors or funders may have conflicts of interest that influence any of the following: the design of the study [228]; choice of exposures [228,229], outcomes [230], statistical methods [231], and selective publication of outcomes [230] and studies [232]. Consequently, the role of the funders should be described in detail: in what part of the study they took direct responsibility (e.g., design, data collection, analysis, drafting of manuscript, decision to publish) [100]. Other sources of undue influence include employers (e.g., university administrators for academic researchers and government supervisors, especially political appointees, for government researchers), advisory committees, litigants, and special interest groups"
  },
  {
    "objectID": "guidelines/strobe/index.html#about-this-guideline",
    "href": "guidelines/strobe/index.html#about-this-guideline",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "About this guideline",
    "text": "About this guideline\n\nThis advice is relevant to studies where the investigators observe exposures (e.g. smoking status) and outcomes (e.g. cancer) in study participants but do not influence what happens. Observational studies include cohort, case-control, and cross-sectional studies."
  },
  {
    "objectID": "guidelines/strobe/index.html#download-resources",
    "href": "guidelines/strobe/index.html#download-resources",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Download Resources",
    "text": "Download Resources\nReporting guidelines are best used early:\n\nUse a template to write quickly and avoid the blank page\nUse a checklist to double-check and reassure others that your work is described transparently\n\n\n\n\nFor drafting\n\nTemplate\n\n\n\nFor checking\n\nChecklist\n\n\n\nFor planning\n\nTo-do list"
  },
  {
    "objectID": "guidelines/strobe/index.html#guidance",
    "href": "guidelines/strobe/index.html#guidance",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Guidance",
    "text": "Guidance\nApprox. 3 min read\n\nTitle and abstract\n\n\n1a. Title\n\n\n\n\n\n\n\nIndicate the study’s design with a commonly used term in the title or the abstract\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nReaders should be able to easily identify the design that was used from the title or abstract. An explicit, commonly used term for the study design also helps ensure correct indexing of articles in electronic databases.\n\n\nExamples\n\nLeukaemia incidence among workers in the shoe and boot manufacturing industry: a case-control study\n\nBack to top\n\n\n\n\n\n\n1b. Abstract\n\n\n\n\n\n\n\nProvide in the abstract an informative and balanced summary of what was done and what was found\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nThe abstract provides key information that enables readers to understand a study and decide whether to read the article. Typical components include a statement of the research question, a short description of methods and results, and a conclusion [22]. Abstracts should summarize key details of studies and should only present information that is provided in the article. We advise presenting key results in a numerical form that includes numbers of participants, estimates of associations and appropriate measures of variability and uncertainty (e.g., odds ratios with confidence intervals). We regard it insufficient to state only that an exposure is or is not significantly associated with an outcome.\n\n\nExamples\n\nBackground: The expected survival of HIV-infected patients is of major public health interest.\n\n\nObjective: To estimate survival time and age-specific mortality rates of an HIV-infected population compared with that of the general population.\n\n\nDesign: Population-based cohort study.\n\n\nSetting: All HIV-infected persons receiving care in Denmark from 1995 to 2005.\n\n\nPatients: Each member of the nationwide Danish HIV Cohort Study was matched with as many as 99 persons from the general population according to sex, date of birth, and municipality of residence.\n\n\nMeasurements: The authors computed Kaplan-Meier life tables with age as the time scale to estimate survival from age 25 years. Patients with HIV infection and corresponding persons from the general population were observed from the date of the patient’s HIV diagnosis until death, emigration, or 1 May 2005.\n\n\nResults: 3990 HIV-infected patients and 379,872 persons from the general population were included in the study, yielding 22,744 (median, 5.8 y/person) and 2,689,287 (median, 8.4 years/person) person-years of observation. Three percent of participants were lost to follow-up. From age 25 years, the median survival was 19.9 years (95% CI, 18.5 to 21.3) among patients with HIV infection and 51.1 years (CI, 50.9 to 51.5) among the general population. For HIV-infected patients, survival increased to 32.5 years (CI, 29.4 to 34.7) during the 2000 to 2005 period. In the subgroup that excluded persons with known hepatitis C coinfection (16%), median survival was 38.9 years (CI, 35.4 to 40.1) during this same period. The relative mortality rates for patients with HIV infection compared with those for the general population decreased with increasing age, whereas the excess mortality rate increased with increasing age.\n\n\nLimitations: The observed mortality rates are assumed to apply beyond the current maximum observation time of 10 years.\n\n\nConclusions: The estimated median survival is more than 35 years for a young person diagnosed with HIV infection in the late highly active antiretroviral therapy era. However, an ongoing effort is still needed to further reduce mortality rates for these persons compared with the general population\n\nBack to top\n\n\n\n\n\n\nIntroduction\n\n\n2. Background / rationale\n\n\n\n\n\n\n\nExplain the scientific background and rationale for the investigation being reported\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nThe scientific background of the study provides important context for readers. It sets the stage for the study and describes its focus. It gives an overview of what is known on a topic and what gaps in current knowledge are addressed by the study. Background material should note recent pertinent studies and any systematic reviews of pertinent studies.\n\n\nExamples\n\nConcerns about the rising prevalence of obesity in children and adolescents have focused on the well documented associations between childhood obesity and increased cardiovascular risk1 and mortality in adulthood.2 Childhood obesity has considerable social and psychological consequences within childhood and adolescence,3 yet little is known about social, socioeconomic, and psychological consequences in adult life.\n\nA recent systematic review found no longitudinal studies on the outcomes of childhood obesity other than physical health outcomes3 and only two longitudinal studies of the socioeconomic effects of obesity in adolescence. Gortmaker et al found that US women who had been obese in late adolescence in 1981 were less likely to be married and had lower incomes seven years later than women who had not been overweight, while men who had been overweight were less likely to be married.4 Sargent et al found that UK women, but not men, who had been obese at 16 years in 1974 earned 7.4% less than their non-obese peers at age 23.5\nThe study of adult outcomes of childhood obesity is difficult because obesity often continues into adult life and therefore poorer socioeconomic and educational outcomes may actually reflect confounding by adult obesity. Yet identifying outcomes related to obesity confined childhood is important in determining whether people who are obese in childhood and who later lose weight remain at risk for adult adversity and inequalities.\nWe used longitudinal data from the 1970 British birth cohort to examine the adult socioeconomic, educational, social, and psychological outcomes of childhood obesity. We hypothesised that obesity limited to childhood has fewer adverse adult outcomes than obesity that persists into adult life\nBack to top\n\n\n\n\n\n\n3. Objectives\n\n\n\n\n\n\n\nState specific objectives, including any prespecified hypotheses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nObjectives are the detailed aims of the study. Well crafted objectives specify populations, exposures and outcomes, and parameters that will be estimated. They may be formulated as specific hypotheses or as questions that the study was designed to address. In some situations objectives may be less specific, for example, in early discovery phases. Regardless, the report should clearly reflect the investigators’ intentions. For example, if important subgroups or additional analyses were not the original aim of the study but arose during data analysis, they should be described accordingly (see also items 4, 17 and 20).\n\n\nExamples\n\nOur primary objectives were to 1) determine the prevalence of domestic violence among female patients presenting to four community-based, primary care, adult medicine practices that serve patients of diverse socioeconomic background and 2) identify demographic and clinical differences between currently abused patients and patients not currently being abused\n\nBack to top\n\n\n\n\n\n\nMethods\n\n\n4. Study design\n\n\n\n\n\n\n\nPresent key elements of study design early in the paper.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nWe advise presenting key elements of study design early in the methods section (or at the end of the introduction) so that readers can understand the basics of the study. For example, authors should indicate that the study was a cohort study, which followed people over a particular time period, and describe the group of persons that comprised the cohort and their exposure status. Similarly, if the investigation used a case-control design, the cases and controls and their source population should be described. If the study was a cross-sectional survey, the population and the point in time at which the cross-section was taken should be mentioned. When a study is a variant of the three main study types, there is an additional need for clarity. For instance, for a case-crossover study, one of the variants of the case-control design, a succinct description of the principles was given in the example above [28].\nWe recommend that authors refrain from simply calling a study ‘prospective’ or ‘retrospective’ because these terms are ill defined [29]. One usage sees cohort and prospective as synonymous and reserves the word retrospective for case-control studies [30]. A second usage distinguishes prospective and retrospective cohort studies according to the timing of data collection relative to when the idea for the study was developed [31]. A third usage distinguishes prospective and retrospective case-control studies depending on whether the data about the exposure of interest existed when cases were selected [32]. Some advise against using these terms [33], or adopting the alternatives ‘concurrent’ and ‘historical’ for describing cohort studies [34]. In STROBE, we do not use the words prospective and retrospective, nor alternatives such as concurrent and historical. We recommend that, whenever authors use these words, they define what they mean. Most importantly, we recommend that authors describe exactly how and when data collection took place.\nThe first part of the methods section might also be the place to mention whether the report is one of several from a study. If a new report is in line with the original aims of the study, this is usually indicated by referring to an earlier publication and by briefly restating the salient features of the study. However, the aims of a study may also evolve over time. Researchers often use data for purposes for which they were not originally intended, including, for example, official vital statistics that were collected primarily for administrative purposes, items in questionnaires that originally were only included for completeness, or blood samples that were collected for another purpose. For example, the Physicians’ Health Study, a randomized controlled trial of aspirin and carotene, was later used to demonstrate that a point mutation in the factor V gene was associated with an increased risk of venous thrombosis, but not of myocardial infarction or stroke [35]. The secondary use of existing data is a creative part of observational research and does not necessarily make results less credible or less important. However, briefly restating the original aims might help readers understand the context of the research and possible limitations in the data.\n\n\nExamples\n\nWe used a case-crossover design, a variation of a case-control design that is appropriate when a brief exposure (driver’s phone use) causes a transient rise in the risk of a rare outcome (a crash). We compared a driver’s use of a mobile phone at the estimated time of a crash with the same driver’s use during another suitable time period. Because drivers are their own controls, the design controls for characteristics of the driver that may affect the risk of a crash but do not change over a short period of time. As it is important that risks during control periods and crash trips are similar, we compared phone activity during the hazard interval (time immediately before the crash) with phone activity during control intervals (equivalent times during which participants were driving but did not crash) in the previous week\n\nBack to top\n\n\n\n\n\n\n5. Setting\n\n\n\n\n\n\n\nDescribe the setting, locations, and relevant dates, including periods of recruitment, exposure, follow-up, and data collection.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nReaders need information on setting and locations to assess the context and generalisability of a study’s results. Exposures such as environmental factors and therapies can change over time. Also, study methods may evolve over time. Knowing when a study took place and over what period participants were recruited and followed up places the study in historical context and is important for the interpretation of results.\nInformation about setting includes recruitment sites or sources (e.g., electoral roll, outpatient clinic, cancer registry, or tertiary care centre). Information about location may refer to the countries, towns, hospitals or practices where the investigation took place. We advise stating dates rather than only describing the length of time periods. There may be different sets of dates for exposure, disease occurrence, recruitment, beginning and end of follow-up, and data collection. Of note, nearly 80% of 132 reports in oncology journals that used survival analysis included the starting and ending dates for accrual of patients, but only 24% also reported the date on which follow-up ended [37].\n\n\nExamples\n\nThe Pasitos Cohort Study recruited pregnant women from Women, Infant and Child (WIC) clinics in Socorro and San Elizario, El Paso County, Texas and maternal-child clinics of the Mexican Social Security Institute (IMSS) in Ciudad Juarez, Mexico from April 1998 to October 2000. At baseline, prior to the birth of the enrolled cohort children, staff interviewed mothers regarding the household environment. In this ongoing cohort study, we target follow-up exams at 6-month intervals beginning at age 6 months\n\nBack to top\n\n\n\n\n\n\n6a. Eligibility criteria\n\n\n\n\n\n\n\nCohort study: Give the eligibility criteria, and the sources and methods of selection of participants. Describe methods of follow-up.\nCase-control study: Give the eligibility criteria, and the sources and methods of case ascertainment and control selection. Give the rationale for the choice of cases and controls.\nCross-sectional study: Give the eligibility criteria, and the sources and methods of selection of participants.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nDetailed descriptions of the study participants help readers understand the applicability of the results. Investigators usually restrict a study population by defining clinical, demographic and other characteristics of eligible participants. Typical eligibility criteria relate to age, gender, diagnosis and comorbid conditions. Despite their importance, eligibility criteria often are not reported adequately. In a survey of observational stroke research, 17 of 49 reports (35%) did not specify eligibility criteria [5].\nEligibility criteria may be presented as inclusion and exclusion criteria, although this distinction is not always necessary or useful. Regardless, we advise authors to report all eligibility criteria and also to describe the group from which the study population was selected (e.g., the general population of a region or country), and the method of recruitment (e.g., referral or self-selection through advertisements).\nKnowing details about follow-up procedures, including whether procedures minimized non-response and loss to follow-up and whether the procedures were similar for all participants, informs judgments about the validity of results. For example, in a study that used IgM antibodies to detect acute infections, readers needed to know the interval between blood tests for IgM antibodies so that they could judge whether some infections likely were missed because the interval between blood tests was too long [41]. In other studies where follow-up procedures differed between exposed and unexposed groups, readers might recognize substantial bias due to unequal ascertainment of events or differences in non-response or loss to follow-up [42]. Accordingly, we advise that researchers describe the methods used for following participants and whether those methods were the same for all participants, and that they describe the completeness of ascertainment of variables (see also item 14).\nIn case-control studies, the choice of cases and controls is crucial to interpreting the results, and the method of their selection has major implications for study validity. In general, controls should reflect the population from which the cases arose. Various methods are used to sample controls, all with advantages and disadvantages: for cases that arise from a general population, population roster sampling, random digit dialling, neighbourhood or friend controls are used. Neighbourhood or friend controls may present intrinsic matching on exposure [17]. Controls with other diseases may have advantages over population-based controls, in particular for hospital-based cases, because they better reflect the catchment population of a hospital, have greater comparability of recall and ease of recruitment. However, they can present problems if the exposure of interest affects the risk of developing or being hospitalized for the control condition(s) [43,44]. To remedy this problem often a mixture of the best defensible control diseases is used [45].\n\n\nExamples\n\nCohort study: Participants in the Iowa Women’s Health Study were a random sample of all women ages 55 to 69 years derived from the state of Iowa automobile driver’s license list in 1985, which represented approximately 94% of Iowa women in that age group. (…) Follow-up questionnaires were mailed in October 1987 and August 1989 to assess vital status and address changes. (…) Incident cancers, except for nonmelanoma skin cancers, were ascertained by the State Health Registry of Iowa (…). The Iowa Women’s Health Study cohort was matched to the registry with combinations of first, last, and maiden names, zip code, birthdate, and social security number.\n\n\nCase-control study: Cutaneous melanoma cases diagnosed in 1999 and 2000 were ascertained through the Iowa Cancer Registry (…). Controls, also identified through the Iowa Cancer Registry, were colorectal cancer patients diagnosed during the same time. Colorectal cancer controls were selected because they are common and have a relatively long survival, and because arsenic exposure has not been conclusively linked to the incidence of colorectal cancer.\n\n\n“Cross-sectional study:** We retrospectively identified patients with a principal diagnosis of myocardial infarction (code 410) according to the International Classification of Diseases, 9th Revision, Clinical Modification, from codes designating discharge diagnoses, excluding the codes with a fifth digit of 2, which designates a subsequent episode of care (…) A random sample of the entire Medicare cohort with myocardial infarction from February 1994 to July 1995 was selected (…) To be eligible, patients had to present to the hospital after at least 30 minutes but less than 12 hours of chest pain and had to have ST-segment elevation of at least 1 mm on two contiguous leads on the initial electrocardiogram.\n\n\n\n\nBack to top\n\n\n\n\n\n\n6b. Matching criteria\n\n\n\n\n\n\n\nCohort study: For matched studies, give matching criteria and number of exposed and unexposed.\nCase-control study: For matched studies, give matching criteria and the number of controls per case.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nMatching is much more common in case-control studies, but occasionally, investigators use matching in cohort studies to make groups comparable at the start of follow-up. Matching in cohort studies makes groups directly comparable for potential confounders and presents fewer intricacies than with case-control studies. For example, it is not necessary to take the matching into account for the estimation of the relative risk [48]. Because matching in cohort studies may increase statistical precision investigators might allow for the matching in their analyses and thus obtain narrower confidence intervals.\nIn case-control studies matching is done to increase a study’s efficiency by ensuring similarity in the distribution of variables between cases and controls, in particular the distribution of potential confounding variables [48,49]. Because matching can be done in various ways, with one or more controls per case, the rationale for the choice of matching variables and the details of the method used should be described. Commonly used forms of matching are frequency matching (also called group matching) and individual matching. In frequency matching, investigators choose controls so that the distribution of matching variables becomes identical or similar to that of cases. Individual matching involves matching one or several controls to each case. Although intuitively appealing and sometimes useful, matching in case-control studies has a number of disadvantages, is not always appropriate, and needs to be taken into account in the analysis (see Box 2).\nEven apparently simple matching procedures may be poorly reported. For example, authors may state that controls were matched to cases ‘within five years’, or using ‘five year age bands’. Does this mean that, if a case was 54 years old, the respective control needed to be in the five-year age band 50 to 54, or aged 49 to 59, which is within five years of age 54? If a wide (e.g., 10-year) age band is chosen, there is a danger of residual confounding by age (see also Box 4), for example because controls may then be younger than cases on average.\n\n\nExamples\n\nCohort study: For each patient who initially received a statin, we used propensity-based matching to identify one control who did not receive a statin according to the following protocol. First, propensity scores were calculated for each patient in the entire cohort on the basis of an extensive list of factors potentially related to the use of statins or the risk of sepsis. Second, each statin user was matched to a smaller pool of non-statin-users by sex, age (plus or minus 1 year), and index date (plus or minus 3 months). Third, we selected the control with the closest propensity score (within 0.2 SD) to each statin user in a 1:1 fashion and discarded the remaining controls.\n\n\nCase-control study: We aimed to select five controls for every case from among individuals in the study population who had no diagnosis of autism or other pervasive developmental disorders (PDD) recorded in their general practice record and who were alive and registered with a participating practice on the date of the PDD diagnosis in the case. Controls were individually matched to cases by year of birth (up to 1 year older or younger), sex, and general practice. For each of 300 cases, five controls could be identified who met all the matching criteria. For the remaining 994, one or more controls was excluded…\n\nBack to top\n\n\n\n\n\n\n7. Variables\n\n\n\n\n\n\n\nClearly define all outcomes, exposures, predictors, potential confounders, and effect modifiers. Give diagnostic criteria, if applicable\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nAuthors should define all variables considered for and included in the analysis, including outcomes, exposures, predictors, potential confounders and potential effect modifiers. Disease outcomes require adequately detailed description of the diagnostic criteria. This applies to criteria for cases in a case-control study, disease events during follow-up in a cohort study and prevalent disease in a cross-sectional study. Clear definitions and steps taken to adhere to them are particularly important for any disease condition of primary interest in the study.\nFor some studies, ‘determinant’ or ‘predictor’ may be appropriate terms for exposure variables and outcomes may be called ‘endpoints’. In multivariable models, authors sometimes use ‘dependent variable’ for an outcome and ‘independent variable’ or ‘explanatory variable’ for exposure and confounding variables. The latter is not precise as it does not distinguish exposures from confounders.\nIf many variables have been measured and included in exploratory analyses in an early discovery phase, consider providing a list with details on each variable in an appendix, additional table or separate publication. Of note, the International Journal of Epidemiology recently launched a new section with ‘cohort profiles’, that includes detailed information on what was measured at different points in time in particular studies [56,57]. Finally, we advise that authors declare all ‘candidate variables’ considered for statistical analysis, rather than selectively reporting only those included in the final models (see also item 16a) [58,59].\n\n\nExamples\n\nOnly major congenital malformations were included in the analyses. Minor anomalies were excluded according to the exclusion list of European Registration of Congenital Anomalies (EUROCAT). If a child had more than one major congenital malformation of one organ system, those malformations were treated as one outcome in the analyses by organ system (…) In the statistical analyses, factors considered potential confounders were maternal age at delivery and number of previous parities. Factors considered potential effect modifiers were maternal age at reimbursement for antiepileptic medication and maternal age at delivery\n\nBack to top\n\n\n\n\n\n\n8. Data sources / measurement\n\n\n\n\n\n\n\nFor each variable of interest give sources of data and details of methods of assessment (measurement). Describe comparability of assessment methods if there is more than one group\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nThe way in which exposures, confounders and outcomes were measured affects the reliability and validity of a study. Measurement error and misclassification of exposures or outcomes can make it more difficult to detect cause-effect relationships, or may produce spurious relationships. Error in measurement of potential confounders can increase the risk of residual confounding [62,63]. It is helpful, therefore, if authors report the findings of any studies of the validity or reliability of assessments or measurements, including details of the reference standard that was used. Rather than simply citing validation studies (as in the first example), we advise that authors give the estimated validity or reliability, which can then be used for measurement error adjustment or sensitivity analyses (see items 12e and 17).\nIn addition, it is important to know if groups being compared differed with respect to the way in which the data were collected. This may be important for laboratory examinations (as in the second example) and other situations. For instance, if an interviewer first questions all the cases and then the controls, or vice versa, bias is possible because of the learning curve; solutions such as randomising the order of interviewing may avoid this problem. Information bias may also arise if the compared groups are not given the same diagnostic tests or if one group receives more tests of the same kind than another (see also item 9).\n\n\nExamples\n\nTotal caffeine intake was calculated primarily using US Department of Agriculture food composition sources. In these calculations, it was assumed that the content of caffeine was 137 mg per cup of coffee, 47 mg per cup of tea, 46 mg per can or bottle of cola beverage, and 7 mg per serving of chocolate candy. This method of measuring (caffeine) intake was shown to be valid in both the NHS I cohort and a similar cohort study of male health professionals (…) Self-reported diagnosis of hypertension was found to be reliable in the NHS I cohort\n\n\nSamples pertaining to matched cases and controls were always analyzed together in the same batch and laboratory personnel were unable to distinguish among cases and controls\n\nBack to top\n\n\n\n\n\n\n9. Bias\n\n\n\n\n\n\n\nDescribe any efforts to address potential sources of bias\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nBiased studies produce results that differ systematically from the truth (see also Box 3). It is important for a reader to know what measures were taken during the conduct of a study to reduce the potential of bias. Ideally, investigators carefully consider potential sources of bias when they plan their study. At the stage of reporting, we recommend that authors always assess the likelihood of relevant biases. Specifically, the direction and magnitude of bias should be discussed and, if possible, estimated. For instance, in case-control studies information bias can occur, but may be reduced by selecting an appropriate control group, as in the first example [64]. Differences in the medical surveillance of participants were a problem in the second example [65]. Consequently, the authors provide more detail about the additional data they collected to tackle this problem. When investigators have set up quality control programs for data collection to counter a possible “drift” in measurements of variables in longitudinal studies, or to keep variability at a minimum when multiple observers are used, these should be described.\nUnfortunately, authors often do not address important biases when reporting their results. Among 43 case-control and cohort studies published from 1990 to 1994 that investigated the risk of second cancers in patients with a history of cancer, medical surveillance bias was mentioned in only 5 articles [66]. A survey of reports of mental health research published during 1998 in three psychiatric journals found that only 13% of 392 articles mentioned response bias [67]. A survey of cohort studies in stroke research found that 14 of 49 (28%) articles published from 1999 to 2003 addressed potential selection bias in the recruitment of study participants and 35 (71%) mentioned the possibility that any type of bias may have affected results [5].\n\n\nExamples\n\nIn most case-control studies of suicide, the control group comprises living individuals but we decided to have a control group of people who had died of other causes (…). With a control group of deceased individuals, the sources of information used to assess risk factors are informants who have recently experienced the death of a family member or close associate - and are therefore more comparable to the sources of information in the suicide group than if living controls were used\n\n\nDetection bias could influence the association between Type 2 diabetes mellitus (T2DM) and primary open-angle glaucoma (POAG) if women with T2DM were under closer ophthalmic surveillance than women without this condition. We compared the mean number of eye examinations reported by women with and without diabetes. We also recalculated the relative risk for POAG with additional control for covariates associated with more careful ocular surveillance (a self-report of cataract, macular degeneration, number of eye examinations, and number of physical examinations)\n\nBack to top\n\n\n\n\n\n\n10. Study size\n\n\n\n\n\n\n\nExplain how the study size was arrived at\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nA study should be large enough to obtain a point estimate with a sufficiently narrow confidence interval to meaningfully answer a research question. Large samples are needed to distinguish a small association from no association. Small studies often provide valuable information, but wide confidence intervals may indicate that they contribute less to current knowledge in comparison with studies providing estimates with narrower confidence intervals. Also, small studies that show ‘interesting’ or ‘statistically significant’ associations are published more frequently than small studies that do not have ‘significant’ findings. While these studies may provide an early signal in the context of discovery, readers should be informed of their potential weaknesses.\nThe importance of sample size determination in observational studies depends on the context. If an analysis is performed on data that were already available for other purposes, the main question is whether the analysis of the data will produce results with sufficient statistical precision to contribute substantially to the literature, and sample size considerations will be informal. Formal, a priori calculation of sample size may be useful when planning a new study [75,76]. Such calculations are associated with more uncertainty than implied by the single number that is generally produced. For example, estimates of the rate of the event of interest or other assumptions central to calculations are commonly imprecise, if not guesswork [77]. The precision obtained in the final analysis can often not be determined beforehand because it will be reduced by inclusion of confounding variables in multivariable analyses [78], the degree of precision with which key variables can be measured [79], and the exclusion of some individuals.\nFew epidemiological studies explain or report deliberations about sample size [4,5]. We encourage investigators to report pertinent formal sample size calculations if they were done. In other situations they should indicate the considerations that determined the study size (e.g., a fixed available sample, as in the first example above). If the observational study was stopped early when statistical significance was achieved, readers should be told. Do not bother readers with post hoc justifications for study size or retrospective power calculations [77]. From the point of view of the reader, confidence intervals indicate the statistical precision that was ultimately obtained. It should be realized that confidence intervals reflect statistical uncertainty only, and not all uncertainty that may be present in a study (see item 20).\n\n\nExamples\n\nThe number of cases in the area during the study period determined the sample size\n\n\nA survey of postnatal depression in the region had documented a prevalence of 19.8%. Assuming depression in mothers with normal weight children to be 20% and an odds ratio of 3 for depression in mothers with a malnourished child we needed 72 case-control sets (one case to one control) with an 80% power and 5% significance\n\nBack to top\n\n\n\n\n\n\n11. Quantitative variables\n\n\n\n\n\n\n\nExplain how quantitative variables were handled in the analyses. If applicable, describe which groupings were chosen, and why\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nInvestigators make choices regarding how to collect and analyse quantitative data about exposures, effect modifiers and confounders. For example, they may group a continuous exposure variable to create a new categorical variable (see Box 4). Grouping choices may have important consequences for later analyses [81,82]. We advise that authors explain why and how they grouped quantitative data, including the number of categories, the cut-points, and category mean or median values. Whenever data are reported in tabular form, the counts of cases, controls, persons at risk, person-time at risk, etc. should be given for each category. Tables should not consist solely of effect-measure estimates or results of model fitting.\nInvestigators might model an exposure as continuous in order to retain all the information. In making this choice, one needs to consider the nature of the relationship of the exposure to the outcome. As it may be wrong to assume a linear relation automatically, possible departures from linearity should be investigated. Authors could mention alternative models they explored during analyses (e.g., using log transformation, quadratic terms or spline functions). Several methods exist for fitting a non-linear relation between the exposure and outcome [82–84]. Also, it may be informative to present both continuous and grouped analyses for a quantitative exposure of prime interest.\nIn a recent survey, two thirds of epidemiological publications studied quantitative exposure variables [4]. In 42 of 50 articles (84%) exposures were grouped into several ordered categories, but often without any stated rationale for the choices made. Fifteen articles used linear associations to model continuous exposure but only two reported checking for linearity. In another survey, of the psychological literature, dichotomization was justified in only 22 of 110 articles (20%) [85].\n\n\nExamples\n\nPatients with a Glasgow Coma Scale less than 8 are considered to be seriously injured. A GCS of 9 or more indicates less serious brain injury. We examined the association of GCS in these two categories with the occurrence of death within 12 months from injury\n\nBack to top\n\n\n\n\n\n\n12a. Statistical methods\n\n\n\n\n\n\n\nDescribe all statistical methods, including those used to control for confounding.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nIn general, there is no one correct statistical analysis but, rather, several possibilities that may address the same question, but make different assumptions. Regardless, investigators should pre-determine analyses at least for the primary study objectives in a study protocol. Often additional analyses are needed, either instead of, or as well as, those originally envisaged, and these may sometimes be motivated by the data. When a study is reported, authors should tell readers whether particular analyses were suggested by data inspection. Even though the distinction between pre-specified and exploratory analyses may sometimes be blurred, authors should clarify reasons for particular analyses.\nIf groups being compared are not similar with regard to some characteristics, adjustment should be made for possible confounding variables by stratification or by multivariable regression (see Box 5) [94]. Often, the study design determines which type of regression analysis is chosen. For instance, Cox proportional hazard regression is commonly used in cohort studies [95]. whereas logistic regression is often the method of choice in case-control studies [96,97]. Analysts should fully describe specific procedures for variable selection and not only present results from the final model [98,99]. If model comparisons are made to narrow down a list of potential confounders for inclusion in a final model, this process should be described. It is helpful to tell readers if one or two covariates are responsible for a great deal of the apparent confounding in a data analysis. Other statistical analyses such as imputation procedures, data transformation, and calculations of attributable risks should also be described. Non-standard or novel approaches should be referenced and the statistical software used reported. As a guiding principle, we advise statistical methods be described “with enough detail to enable a knowledgeable reader with access to the original data to verify the reported results” [100].\nIn an empirical study, only 93 of 169 articles (55%) reporting adjustment for confounding clearly stated how continuous and multi-category variables were entered into the statistical model [101]. Another study found that among 67 articles in which statistical analyses were adjusted for confounders, it was mostly unclear how confounders were chosen [4].\n\n\nExamples\n\nThe adjusted relative risk was calculated using the Mantel-Haenszel technique, when evaluating if confounding by age or gender was present in the groups compared. The 95% confidence interval (CI) was computed around the adjusted relative risk, using the variance according to Greenland and Robins and Robins et al\n\nBack to top\n\n\n\n\n\n\n12b. Statistical methods\n\n\n\n\n\n\n\nDescribe any methods used to examine subgroups and interactions\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nAs discussed in detail under item 17, many debate the use and value of analyses restricted to subgroups of the study population [4,104]. Subgroup analyses are nevertheless often done [4]. Readers need to know which subgroup analyses were planned in advance, and which arose while analysing the data. Also, it is important to explain what methods were used to examine whether effects or associations differed across groups (see item 17).\nInteraction relates to the situation when one factor modifies the effect of another (therefore also called ‘effect modification’). The joint action of two factors can be characterized in two ways: on an additive scale, in terms of risk differences; or on a multiplicative scale, in terms of relative risk (see Box 8). Many authors and readers may have their own preference about the way interactions should be analysed. Still, they may be interested to know to what extent the joint effect of exposures differs from the separate effects. There is consensus that the additive scale, which uses absolute risks, is more appropriate for public health and clinical decision making [105]. Whatever view is taken, this should be clearly presented to the reader, as is done in the example above [103]. A lay-out presenting separate effects of both exposures as well as their joint effect, each relative to no exposure, might be most informative. It is presented in the example for interaction under item 17, and the calculations on the different scales are explained in Box 8.\n\n\nExamples\n\nSex differences in susceptibility to the 3 lifestyle-related risk factors studied were explored by testing for biological interaction according to Rothman: a new composite variable with 4 categories (a − b − , a − b+, a+b − , and a+b+) was redefined for sex and a dichotomous exposure of interest where a− and b− denote absence of exposure. RR was calculated for each category after adjustment for age. An interaction effect is defined as departure from additivity of absolute effects, and excess RR caused by interaction (RERI) was calculated:\n\n[equation image]\nwhere RR(a+b+) denotes RR among those exposed to both factors where RR(a − b −) is used as reference category (RR = 1.0). Ninety-five percent CIs were calculated as proposed by Hosmer and Lemeshow. RERI of 0 means no interaction\nBack to top\n\n\n\n\n\n\n12c. Statistical methods\n\n\n\n\n\n\n\nExplain how missing data were addressed.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nMissing data are common in observational research. Questionnaires posted to study participants are not always filled in completely, participants may not attend all follow-up visits and routine data sources and clinical databases are often incomplete. Despite its ubiquity and importance, few papers report in detail on the problem of missing data [5,107]. Investigators may use any of several approaches to address missing data. We describe some strengths and limitations of various approaches in Box 6. We advise that authors report the number of missing values for each variable of interest (exposures, outcomes, confounders) and for each step in the analysis. Authors should give reasons for missing values if possible, and indicate how many individuals were excluded because of missing data when describing the flow of participants through the study (see also item 13). For analyses that account for missing data, authors should describe the nature of the analysis (e.g., multiple imputation) and the assumptions that were made (e.g., missing at random, see Box 6).\n\n\nExamples\n\nOur missing data analysis procedures used missing at random (MAR) assumptions. We used the MICE (multivariate imputation by chained equations) method of multiple multivariate imputation in STATA. We independently analysed 10 copies of the data, each with missing values suitably imputed, in the multivariate logistic regression analyses. We averaged estimates of the variables to give a single mean estimate and adjusted standard errors according to Rubin’s rules\n\nBack to top\n\n\n\n\n\n\n17. 12di. Statistical methods\n\n\n\n\n\n\n\nIf applicable, describe how loss to follow-up was addressed\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nCohort studies are analysed using life table methods or other approaches that are based on the person-time of follow-up and time to developing the disease of interest. Among individuals who remain free of the disease at the end of their observation period, the amount of follow-up time is assumed to be unrelated to the probability of developing the outcome. This will be the case if follow-up ends on a fixed date or at a particular age. Loss to follow-up occurs when participants withdraw from a study before that date. This may hamper the validity of a study if loss to follow-up occurs selectively in exposed individuals, or in persons at high risk of developing the disease (‘informative censoring’). In the example above, patients lost to follow-up in treatment programmes with no active follow-up had fewer CD4 helper cells than those remaining under observation and were therefore at higher risk of dying [116].\nIt is important to distinguish persons who reach the end of the study from those lost to follow-up. Unfortunately, statistical software usually does not distinguish between the two situations: in both cases follow-up time is automatically truncated (‘censored’) at the end of the observation period. Investigators therefore need to decide, ideally at the stage of planning the study, how they will deal with loss to follow-up. When few patients are lost, investigators may either exclude individuals with incomplete follow-up, or treat them as if they withdrew alive at either the date of loss to follow-up or the end of the study. We advise authors to report how many patients were lost to follow-up and what censoring strategies they used.\n\n\nExamples\n\nIn treatment programmes with active follow-up, those lost to follow-up and those followed-up at 1 year had similar baseline CD4 cell counts (median 115 cells per μL and 123 cells per μL), whereas patients lost to follow-up in programmes with no active follow-up procedures had considerably lower CD4 cell counts than those followed-up (median 64 cells per μL and 123 cells per μL). (…) Treatment programmes with passive follow-up were excluded from subsequent analyses\n\nBack to top\n\n\n\n\n\n\n18. 12dii. Statistical methods\n\n\n\n\n\n\n\nCase-control study: If applicable, explain how matching of cases and controls was addressed.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nIn individually matched case-control studies a crude analysis of the odds ratio, ignoring the matching, usually leads to an estimation that is biased towards unity (see Box 2). A matched analysis is therefore often necessary. This can intuitively be understood as a stratified analysis: each case is seen as one stratum with his or her set of matched controls. The analysis rests on considering whether the case is more often exposed than the controls, despite having made them alike regarding the matching variables. Investigators can do such a stratified analysis using the Mantel-Haenszel method on a ‘matched’ 2 by 2 table. In its simplest form the odds ratio becomes the ratio of pairs that are discordant for the exposure variable. If matching was done for variables like age and sex that are universal attributes, the analysis needs not retain the individual, person-to-person matching: a simple analysis in categories of age and sex is sufficient [50]. For other matching variables, such as neighbourhood, sibship, or friendship, however, each matched set should be considered its own stratum.\nIn individually matched studies, the most widely used method of analysis is conditional logistic regression, in which each case and their controls are considered together. The conditional method is necessary when the number of controls varies among cases, and when, in addition to the matching variables, other variables need to be adjusted for. To allow readers to judge whether the matched design was appropriately taken into account in the analysis, we recommend that authors describe in detail what statistical methods were used to analyse the data. If taking the matching into account does have little effect on the estimates, authors may choose to present an unmatched analysis.\n\n\nExamples\n\nWe used McNemar’s test, paired t test, and conditional logistic regression analysis to compare dementia patients with their matched controls for cardiovascular risk factors, the occurrence of spontaneous cerebral emboli, carotid disease, and venous to arterial circulation shunt\n\nBack to top\n\n\n\n\n\n\n19. 12diii. Statistical methods\n\n\n\n\n\n\n\nCross-sectional study: If applicable, describe analytical methods taking account of sampling strategy.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nMost cross-sectional studies use a pre-specified sampling strategy to select participants from a source population. Sampling may be more complex than taking a simple random sample, however. It may include several stages and clustering of participants (e.g., in districts or villages). Proportionate stratification may ensure that subgroups with a specific characteristic are correctly represented. Disproportionate stratification may be useful to over-sample a subgroup of particular interest.\nAn estimate of association derived from a complex sample may be more or less precise than that derived from a simple random sample. Measures of precision such as standard error or confidence interval should be corrected using the design effect, a ratio measure that describes how much precision is gained or lost if a more complex sampling strategy is used instead of simple random sampling [119]. Most complex sampling techniques lead to a decrease of precision, resulting in a design effect greater than 1.\nWe advise that authors clearly state the method used to adjust for complex sampling strategies so that readers may understand how the chosen sampling method influenced the precision of the obtained estimates. For instance, with clustered sampling, the implicit trade-off between easier data collection and loss of precision is transparent if the design effect is reported. In the example, the calculated design effects of 1.9 for men indicates that the actual sample size would need to be 1.9 times greater than with simple random sampling for the resulting estimates to have equal precision.\n\n\nExamples\n\nThe standard errors (SE) were calculated using the Taylor expansion method to estimate the sampling errors of estimators based on the complex sample design. (…) The overall design effect for diastolic blood pressure was found to be 1.9 for men and 1.8 for women and, for systolic blood pressure, it was 1.9 for men and 2.0 for women\n\nBack to top\n\n\n\n\n\n\n12e. Statistical methods\n\n\n\n\n\n\n\nDescribe any sensitivity analyses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nSensitivity analyses are useful to investigate whether or not the main results are consistent with those obtained with alternative analysis strategies or assumptions [121]. Issues that may be examined include the criteria for inclusion in analyses, the definitions of exposures or outcomes [122], which confounding variables merit adjustment, the handling of missing data [120,123], possible selection bias or bias from inaccurate or inconsistent measurement of exposure, disease and other variables, and specific analysis choices, such as the treatment of quantitative variables (see item 11). Sophisticated methods are increasingly used to simultaneously model the influence of several biases or assumptions [124–126].\nIn 1959 Cornfield et al. famously showed that a relative risk of 9 for cigarette smoking and lung cancer was extremely unlikely to be due to any conceivable confounder, since the confounder would need to be at least nine times as prevalent in smokers as in non-smokers [127]. This analysis did not rule out the possibility that such a factor was present, but it did identify the prevalence such a factor would need to have. The same approach was recently used to identify plausible confounding factors that could explain the association between childhood leukaemia and living near electric power lines [128]. More generally, sensitivity analyses can be used to identify the degree of confounding, selection bias, or information bias required to distort an association. One important, perhaps under recognised, use of sensitivity analysis is when a study shows little or no association between an exposure and an outcome and it is plausible that confounding or other biases toward the null are present.\n\n\nExamples\n\nBecause we had a relatively higher proportion of ‘missing’ dead patients with insufficient data (38/148=25.7%) as compared to live patients (15/437=3.4%) (…), it is possible that this might have biased the results. We have, therefore, carried out a sensitivity analysis. We have assumed that the proportion of women using oral contraceptives in the study group applies to the whole (19.1% for dead, and 11.4% for live patients), and then applied two extreme scenarios: either all the exposed missing patients used second generation pills or they all used third-generation pills\n\nBack to top\n\n\n\n\n\n\nResults\n\n\n13a. Participants\n\n\n\n\n\n\n\nReport the numbers of individuals at each stage of the study—e.g., numbers potentially eligible, examined for eligibility, confirmed eligible, included in the study, completing follow-up, and analysed; Consider use of a flow diagram.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nDetailed information on the process of recruiting study participants is important for several reasons. Those included in a study often differ in relevant ways from the target population to which results are applied. This may result in estimates of prevalence or incidence that do not reflect the experience of the target population. For example, people who agreed to participate in a postal survey of sexual behaviour attended church less often, had less conservative sexual attitudes and earlier age at first sexual intercourse, and were more likely to smoke cigarettes and drink alcohol than people who refused [130]. These differences suggest that postal surveys may overestimate sexual liberalism and activity in the population. Such response bias (see Box 3) can distort exposure-disease associations if associations differ between those eligible for the study and those included in the study. As another example, the association between young maternal age and leukaemia in offspring, which has been observed in some case-control studies [131,132], was explained by differential participation of young women in case and control groups. Young women with healthy children were less likely to participate than those with unhealthy children [133]. Although low participation does not necessarily compromise the validity of a study, transparent information on participation and reasons for non-participation is essential. Also, as there are no universally agreed definitions for participation, response or follow-up rates, readers need to understand how authors calculated such proportions [134].\nIdeally, investigators should give an account of the numbers of individuals considered at each stage of recruiting study participants, from the choice of a target population to the inclusion of participants’ data in the analysis. Depending on the type of study, this may include the number of individuals considered to be potentially eligible, the number assessed for eligibility, the number found to be eligible, the number included in the study, the number examined, the number followed up and the number included in the analysis. Information on different sampling units may be required, if sampling of study participants is carried out in two or more stages as in the example above (multistage sampling). In case-control studies, we advise that authors describe the flow of participants separately for case and control groups [135]. Controls can sometimes be selected from several sources, including, for example, hospitalised patients and community dwellers. In this case, we recommend a separate account of the numbers of participants for each type of control group. Olson and colleagues proposed useful reporting guidelines for controls recruited through random-digit dialling and other methods [136].\nA recent survey of epidemiological studies published in 10 general epidemiology, public health and medical journals found that some information regarding participation was provided in 47 of 107 case-control studies (59%), 49 of 154 cohort studies (32%), and 51 of 86 cross-sectional studies (59%) [137]. Incomplete or absent reporting of participation and non-participation in epidemiological studies was also documented in two other surveys of the literature [4,5]. Finally, there is evidence that participation in epidemiological studies may have declined in recent decades [137,138], which underscores the need for transparent reporting [139].\n\n\nExamples\n\nOf the 105 freestanding bars and taverns sampled, 13 establishments were no longer in business and 9 were located in restaurants, leaving 83 eligible businesses. In 22 cases, the owner could not be reached by telephone despite 6 or more attempts. The owners of 36 bars declined study participation. (…) The 25 participating bars and taverns employed 124 bartenders, with 67 bartenders working at least 1 weekly daytime shift. Fifty-four of the daytime bartenders (81%) completed baseline interviews and spirometry; 53 of these subjects (98%) completed follow-up\n\n\nFlow diagram from Hay et al (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/figure/pmed-0040297-g001/)\n\nBack to top\n\n\n\n\n\n\n13b. Participants\n\n\n\n\n\n\n\nGive reasons for non-participation at each stage\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nExplaining the reasons why people no longer participated in a study or why they were excluded from statistical analyses helps readers judge whether the study population was representative of the target population and whether bias was possibly introduced. For example, in a cross-sectional health survey, non-participation due to reasons unlikely to be related to health status (for example, the letter of invitation was not delivered because of an incorrect address) will affect the precision of estimates but will probably not introduce bias. Conversely, if many individuals opt out of the survey because of illness, or perceived good health, results may underestimate or overestimate the prevalence of ill health in the population.\n\n\nExamples\n\nThe main reasons for non-participation were the participant was too ill or had died before interview (cases 30%, controls &lt; 1%), nonresponse (cases 2%, controls 21%), refusal (cases 10%, controls 29%), and other reasons (refusal by consultant or general practitioner, non-English speaking, mental impairment) (cases 7%, controls 5%)\n\nBack to top\n\n\n\n\n\n\n13c. Participants\n\n\n\n\n\n\n\nConsider use of a flow diagram.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nAn informative and well-structured flow diagram can readily and transparently convey information that might otherwise require a lengthy description [142], as in the example above. The diagram may usefully include the main results, such as the number of events for the primary outcome. While we recommend the use of a flow diagram, particularly for complex observational studies, we do not propose a specific format for the diagram.\n\n\n\n\n\n14a.\n\n\n\n\n\n\n\nGive characteristics of study participants (e.g., demographic, clinical, social) and information on exposures and potential confounders. Present the information in a table\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nReaders need descriptions of study participants and their exposures to judge the generalisability of the findings. Information about potential confounders, including whether and how they were measured, influences judgments about study validity. We advise authors to summarize continuous variables for each study group by giving the mean and standard deviation, or when the data have an asymmetrical distribution, as is often the case, the median and percentile range (e.g., 25th and 75th percentiles). Variables that make up a small number of ordered categories (such as stages of disease I to IV) should not be presented as continuous variables; it is preferable to give numbers and proportions for each category (see also Box 4). In studies that compare groups, the descriptive characteristics and numbers should be given by group, as in the example above.\nInferential measures such as standard errors and confidence intervals should not be used to describe the variability of characteristics, and significance tests should be avoided in descriptive tables. Also, P values are not an appropriate criterion for selecting which confounders to adjust for in analysis; even small differences in a confounder that has a strong effect on the outcome can be important [144,145].\nIn cohort studies, it may be useful to document how an exposure relates to other characteristics and potential confounders. Authors could present this information in a table with columns for participants in two or more exposure categories, which permits to judge the differences in confounders between these categories.\nIn case-control studies potential confounders cannot be judged by comparing cases and controls. Control persons represent the source population and will usually be different from the cases in many respects. For example, in a study of oral contraceptives and myocardial infarction, a sample of young women with infarction more often had risk factors for that disease, such as high serum cholesterol, smoking and a positive family history, than the control group [146]. This does not influence the assessment of the effect of oral contraceptives, as long as the prescription of oral contraceptives was not guided by the presence of these risk factors—e.g., because the risk factors were only established after the event (see also Box 5). In case-control studies the equivalent of comparing exposed and non-exposed for the presence of potential confounders (as is done in cohorts) can be achieved by exploring the source population of the cases: if the control group is large enough and represents the source population, exposed and unexposed controls can be compared for potential confounders [121,147].\n\n\nExamples\n\nTable: Characteristics of the Study Base at Enrolment, Castellana G (Italy) (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t002/(\n\nBack to top\n\n\n\n\n\n\n14b.\n\n\n\n\n\n\n\nIndicate the number of participants with missing data for each variable of interest.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nAs missing data may bias or affect generalisability of results, authors should tell readers amounts of missing data for exposures, potential confounders, and other important characteristics of patients (see also item 12c and Box 6). In a cohort study, authors should report the extent of loss to follow-up (with reasons), since incomplete follow-up may bias findings (see also items 12d and 13) [148]. We advise authors to use their tables and figures to enumerate amounts of missing data.\n\n\nExamples\n\nSymptom End Points Used in Survival Analysis (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t003/)\n\nBack to top\n\n\n\n\n\n\n14c.\n\n\n\n\n\n\n\nCohort study: Summarise follow-up time—e.g., average and total amount\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nReaders need to know the duration and extent of follow-up for the available outcome data. Authors can present a summary of the average follow-up with either the mean or median follow-up time or both. The mean allows a reader to calculate the total number of person-years by multiplying it with the number of study participants. Authors also may present minimum and maximum times or percentiles of the distribution to show readers the spread of follow-up times. They may report total person-years of follow-up or some indication of the proportion of potential data that was captured [148]. All such information may be presented separately for participants in two or more exposure categories. Almost half of 132 articles in cancer journals (mostly cohort studies) did not give any summary of length of follow-up [37].\n\n\nExamples\n\nDuring the 4366 person-years of follow-up (median 5.4, maximum 8.3 years), 265 subjects were diagnosed as having dementia, including 202 with Alzheimer’s disease\n\nBack to top\n\n\n\n\n\n\n15. Outcome data\n\n\n\n\n\n\n\nCohort study: Report numbers of outcome events or summary measures over time.\nCase-control study: Report numbers in each exposure category, or summary measures of exposure.\nCross-sectional study: Report numbers of outcome events or summary measures.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nBefore addressing the possible association between exposures (risk factors) and outcomes, authors should report relevant descriptive data. It may be possible and meaningful to present measures of association in the same table that presents the descriptive data (see item 14a). In a cohort study with events as outcomes, report the numbers of events for each outcome of interest. Consider reporting the event rate per person-year of follow-up. If the risk of an event changes over follow-up time, present the numbers and rates of events in appropriate intervals of follow-up or as a Kaplan-Meier life table or plot. It might be preferable to show plots as cumulative incidence that go up from 0% rather than down from 100%, especially if the event rate is lower than, say, 30% [153]. Consider presenting such information separately for participants in different exposure categories of interest. If a cohort study is investigating other time-related outcomes (e.g., quantitative disease markers such as blood pressure), present appropriate summary measures (e.g., means and standard deviations) over time, perhaps in a table or figure.\nFor cross-sectional studies, we recommend presenting the same type of information on prevalent outcome events or summary measures. For case-control studies, the focus will be on reporting exposures separately for cases and controls as frequencies or quantitative summaries [154]. For all designs, it may be helpful also to tabulate continuous outcomes or exposures in categories, even if the data are not analysed as such.\n\n\nExamples\n\nCohort study: Table: Rates of HIV-1 Seroconversion by Selected Sociodemographic Variables: 1990–1993 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t004/)\n\n\nCase-control study: Table: Exposure among Liver Cirrhosis Cases and Controls (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t006/)\n\n\nCross-sectional study: Table: Prevalence of Current Asthma and Diagnosed Hay Fever by Average Alternaria alternata Antigen Level in the Household (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t007/)\n\nBack to top\n\n\n\n\n\n\n16a. Main results\n\n\n\n\n\n\n\nGive unadjusted estimates and, if applicable, confounder-adjusted estimates and their precision (e.g., 95% confidence intervals). Make clear which confounders were adjusted for and why they were included\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nIn many situations, authors may present the results of unadjusted or minimally adjusted analyses and those from fully adjusted analyses. We advise giving the unadjusted analyses together with the main data, for example the number of cases and controls that were exposed or not. This allows the reader to understand the data behind the measures of association (see also item 15). For adjusted analyses, report the number of persons in the analysis, as this number may differ because of missing values in covariates (see also item 12c). Estimates should be given with confidence intervals.\nReaders can compare unadjusted measures of association with those adjusted for potential confounders and judge by how much, and in what direction, they changed. Readers may think that ‘adjusted’ results equal the causal part of the measure of association, but adjusted results are not necessarily free of random sampling error, selection bias, information bias, or residual confounding (see Box 5). Thus, great care should be exercised when interpreting adjusted results, as the validity of results often depends crucially on complete knowledge of important confounders, their precise measurement, and appropriate specification in the statistical model (see also item 20) [157,158].\nAuthors should explain all potential confounders considered, and the criteria for excluding or including variables in statistical models. Decisions about excluding or including variables should be guided by knowledge, or explicit assumptions, on causal relations. Inappropriate decisions may introduce bias, for example by including variables that are in the causal pathway between exposure and disease (unless the aim is to asses how much of the effect is carried by the intermediary variable). If the decision to include a variable in the model was based on the change in the estimate, it is important to report what change was considered sufficiently important to justify its inclusion. If a ‘backward deletion’ or ‘forward inclusion’ strategy was used to select confounders, explain that process and give the significance level for rejecting the null hypothesis of no confounding. Of note, we and others do not advise selecting confounders based solely on statistical significance testing [147,159,160].\nRecent studies of the quality of reporting of epidemiological studies found that confidence intervals were reported in most articles [4]. However, few authors explained their choice of confounding variables [4,5].\n\n\nExamples\n\nWe initially considered the following variables as potential confounders by Mantel-Haenszel stratified analysis: (…) The variables we included in the final logistic regression models were those (…) that produced a 10% change in the odds ratio after the Mantel-Haenszel adjustment\n\n\nTable: Relative Rates of Rehospitalisation by Treatment in Patients in Community Care after First Hospitalisation due to Schizophrenia and Schizoaffective Disorder (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t008/)\n\nBack to top\n\n\n\n\n\n\n16b. Main results\n\n\n\n\n\n\n\nReport category boundaries when continuous variables were categorised\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nCategorizing continuous data has several important implications for analysis (see Box 4) and also affects the presentation of results. In tables, outcomes should be given for each exposure category, for example as counts of persons at risk, person-time at risk, if relevant separately for each group (e.g., cases and controls). Details of the categories used may aid comparison of studies and meta-analysis. If data were grouped using conventional cut-points, such as body mass index thresholds [162], group boundaries (i.e., range of values) can be derived easily, except for the highest and lowest categories. If quantile-derived categories are used, the category boundaries cannot be inferred from the data. As a minimum, authors should report the category boundaries; it is helpful also to report the range of the data and the mean or median values within categories.\n\n\nExamples\n\nTable: Polychlorinated Biphenyls in Cord Serum (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t005/)\n\nBack to top\n\n\n\n\n\n\n16c. Main results\n\n\n\n\n\n\n\nIf relevant, consider translating estimates of relative risk into absolute risk for a meaningful time period\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nThe results from studies examining the association between an exposure and a disease are commonly reported in relative terms, as ratios of risks, rates or odds (see Box 8). Relative measures capture the strength of the association between an exposure and disease. If the relative risk is a long way from 1 it is less likely that the association is due to confounding [164,165]. Relative effects or associations tend to be more consistent across studies and populations than absolute measures, but what often tends to be the case may be irrelevant in a particular instance. For example, similar relative risks were obtained for the classic cardiovascular risk factors for men living in Northern Ireland, France, the USA and Germany, despite the fact that the underlying risk of coronary heart disease varies substantially between these countries [166,167]. In contrast, in a study of hypertension as a risk factor for cardiovascular disease mortality, the data were more compatible with a constant rate difference than with a constant rate ratio [168].\nWidely used statistical models, including logistic [169] and proportional hazards (Cox) regression [170] are based on ratio measures. In these models, only departures from constancy of ratio effect measures are easily discerned. Nevertheless, measures which assess departures from additivity of risk differences, such as the Relative Excess Risk from Interaction (RERI, see item 12b and Box 8), can be estimated in models based on ratio measures.\nIn many circumstances, the absolute risk associated with an exposure is of greater interest than the relative risk. For example, if the focus is on adverse effects of a drug, one will want to know the number of additional cases per unit time of use (e.g., days, weeks, or years). The example gives the additional number of breast cancer cases per 1000 women who used hormone-replacement therapy for 10 years [163]. Measures such as the attributable risk or population attributable fraction may be useful to gauge how much disease can be prevented if the exposure is eliminated. They should preferably be presented together with a measure of statistical uncertainty (e.g., confidence intervals as in the example). Authors should be aware of the strong assumptions made in this context, including a causal relationship between a risk factor and disease (also see Box 7) [171]. Because of the semantic ambiguity and complexities involved, authors should report in detail what methods were used to calculate attributable risks, ideally giving the formulae used [172].\nA recent survey of abstracts of 222 articles published in leading medical journals found that in 62% of abstracts of randomised trials including a ratio measure absolute risks were given, but only in 21% of abstracts of cohort studies [173]. A free text search of Medline 1966 to 1997 showed that 619 items mentioned attributable risks in the title or abstract, compared to 18,955 using relative risk or odds ratio, for a ratio of 1 to 31 [174].\n\n\nExamples\n\n10 years’ use of HRT [hormone replacement therapy] is estimated to result in five (95% CI 3–7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15–23) additional cancers per 1000 users of oestrogen-progestagen combinations\n\nBack to top\n\n\n\n\n\n\n17. Other analyses\n\n\n\n\n\n\n\nReport other analyses done—e.g., analyses of subgroups and interactions, and sensitivity analyses\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nIn addition to the main analysis other analyses are often done in observational studies. They may address specific subgroups, the potential interaction between risk factors, the calculation of attributable risks, or use alternative definitions of study variables in sensitivity analyses.\nThere is debate about the dangers associated with subgroup analyses, and multiplicity of analyses in general [4,104]. In our opinion, there is too great a tendency to look for evidence of subgroup-specific associations, or effect-measure modification, when overall results appear to suggest little or no effect. On the other hand, there is value in exploring whether an overall association appears consistent across several, preferably pre-specified subgroups especially when a study is large enough to have sufficient data in each subgroup. A second area of debate is about interesting subgroups that arose during the data analysis. They might be important findings, but might also arise by chance. Some argue that it is neither possible nor necessary to inform the reader about all subgroup analyses done as future analyses of other data will tell to what extent the early exciting findings stand the test of time [9]. We advise authors to report which analyses were planned, and which were not (see also items 4, 12b and 20). This will allow readers to judge the implications of multiplicity, taking into account the study’s position on the continuum from discovery to verification or refutation.\nA third area of debate is how joint effects and interactions between risk factors should be evaluated: on additive or multiplicative scales, or should the scale be determined by the statistical model that fits best (see also item 12b and Box 8)? A sensible approach is to report the separate effect of each exposure as well as the joint effect—if possible in a table, as in the first example above [183], or in the study by Martinelli et al. [185]. Such a table gives the reader sufficient information to evaluate additive as well as multiplicative interaction (how these calculations are done is shown in Box 8). Confidence intervals for separate and joint effects may help the reader to judge the strength of the data. In addition, confidence intervals around measures of interaction, such as the Relative Excess Risk from Interaction (RERI) relate to tests of interaction or homogeneity tests. One recurrent problem is that authors use comparisons of P-values across subgroups, which lead to erroneous claims about an effect modifier. For instance, a statistically significant association in one category (e.g., men), but not in the other (e.g., women) does not in itself provide evidence of effect modification. Similarly, the confidence intervals for each point estimate are sometimes inappropriately used to infer that there is no interaction when intervals overlap. A more valid inference is achieved by directly evaluating whether the magnitude of an association differs across subgroups.\nSensitivity analyses are helpful to investigate the influence of choices made in the statistical analysis, or to investigate the robustness of the findings to missing data or possible biases (see also item 12b). Judgement is needed regarding the level of reporting of such analyses. If many sensitivity analyses were performed, it may be impractical to present detailed findings for them all. It may sometimes be sufficient to report that sensitivity analyses were carried out and that they were consistent with the main results presented. Detailed presentation is more appropriate if the issue investigated is of major concern, or if effect estimates vary considerably [59,186].\nPocock and colleagues found that 43 out of 73 articles reporting observational studies contained subgroup analyses. The majority claimed differences across groups but only eight articles reported a formal evaluation of interaction (see item 12b) [4].\n\n\nExamples\n\nAnalysis of Oral Contraceptive Use, Presence of Factor V Leiden Allele, and Risk for Venous Thromboembolism (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t009/)\n\n\nSensitivity of the Rate Ratio for Cardiovascular Outcome to an Unmeasured Confounder (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t010/)\n\nBack to top\n\n\n\n\n\n\nDiscussion\n\n\n18. Key results\n\n\n\n\n\n\n\nSummarise key results with reference to study objectives\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nIt is good practice to begin the discussion with a short summary of the main findings of the study. The short summary reminds readers of the main findings and may help them assess whether the subsequent interpretation and implications offered by the authors are supported by the findings.\n\n\nExamples\n\nWe hypothesized that ethnic minority status would be associated with higher levels of cardiovascular disease (CVD) risk factors, but that the associations would be explained substantially by socioeconomic status (SES). Our hypothesis was not confirmed. After adjustment for age and SES, highly significant differences in body mass index, blood pressure, diabetes, and physical inactivity remained between white women and both black and Mexican American women. In addition, we found large differences in CVD risk factors by SES, a finding that illustrates the high-risk status of both ethnic minority women as well as white women with low SES\n\nBack to top\n\n\n\n\n\n\n19. Limitations\n\n\n\n\n\n\n\nDiscuss limitations of the study, taking into account sources of potential bias or imprecision. Discuss both direction and magnitude of any potential bias.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nThe identification and discussion of the limitations of a study are an essential part of scientific reporting. It is important not only to identify the sources of bias and confounding that could have affected results, but also to discuss the relative importance of different biases, including the likely direction and magnitude of any potential bias (see also item 9 and Box 3).\nAuthors should also discuss any imprecision of the results. Imprecision may arise in connection with several aspects of a study, including the study size (item 10) and the measurement of exposures, confounders and outcomes (item 8). The inability to precisely measure true values of an exposure tends to result in bias towards unity: the less precisely a risk factor is measured, the greater the bias. This effect has been described as ‘attenuation’ [201,202], or more recently as ‘regression dilution bias’ [203]. However, when correlated risk factors are measured with different degrees of imprecision, the adjusted relative risk associated with them can be biased towards or away from unity [204–206].\nWhen discussing limitations, authors may compare the study being presented with other studies in the literature in terms of validity, generalisability and precision. In this approach, each study can be viewed as contribution to the literature, not as a stand-alone basis for inference and action [207]. Surprisingly, the discussion of important limitations of a study is sometimes omitted from published reports. A survey of authors who had published original research articles in The Lancet found that important weaknesses of the study were reported by the investigators in the survey questionnaires, but not in the published article [192].\n\n\nExamples\n\nSince the prevalence of counseling increases with increasing levels of obesity, our estimates may overestimate the true prevalence. Telephone surveys also may overestimate the true prevalence of counseling. Although persons without telephones have similar levels of overweight as persons with telephones, persons without telephones tend to be less educated, a factor associated with lower levels of counseling in our study. Also, of concern is the potential bias caused by those who refused to participate as well as those who refused to respond to questions about weight. Furthermore, because data were collected cross-sectionally, we cannot infer that counseling preceded a patient’s attempt to lose weight\n\nBack to top\n\n\n\n\n\n\n20. Interpretation\n\n\n\n\n\n\n\nGive a cautious overall interpretation considering objectives, limitations, multiplicity of analyses, results from similar studies, and other relevant evidence.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nThe heart of the discussion section is the interpretation of a study’s results. Over-interpretation is common and human: even when we try hard to give an objective assessment, reviewers often rightly point out that we went too far in some respects. When interpreting results, authors should consider the nature of the study on the discovery to verification continuum and potential sources of bias, including loss to follow-up and non-participation (see also items 9, 12 and 19). Due consideration should be given to confounding (item 16a), the results of relevant sensitivity analyses, and to the issue of multiplicity and subgroup analyses (item 17). Authors should also consider residual confounding due to unmeasured variables or imprecise measurement of confounders. For example, socioeconomic status (SES) is associated with many health outcomes and often differs between groups being compared. Variables used to measure SES (income, education, or occupation) are surrogates for other undefined and unmeasured exposures, and the true confounder will by definition be measured with error [208]. Authors should address the real range of uncertainty in estimates, which is larger than the statistical uncertainty reflected in confidence intervals. The latter do not take into account other uncertainties that arise from a study’s design, implementation, and methods of measurement [209].\nTo guide thinking and conclusions about causality, some may find criteria proposed by Bradford Hill in 1965 helpful [164]. How strong is the association with the exposure? Did it precede the onset of disease? Is the association consistently observed in different studies and settings? Is there supporting evidence from experimental studies, including laboratory and animal studies? How specific is the exposure’s putative effect, and is there a dose-response relationship? Is the association biologically plausible? These criteria should not, however, be applied mechanically. For example, some have argued that relative risks below 2 or 3 should be ignored [210,211]. This is a reversal of the point by Cornfield et al. about the strength of large relative risks (see item 12b) [127]. Although a causal effect is more likely with a relative risk of 9, it does not follow that one below 3 is necessarily spurious. For instance, the small increase in the risk of childhood leukaemia after intrauterine irradiation is credible because it concerns an adverse effect of a medical procedure for which no alternative explanations are obvious [212]. Moreover, the carcinogenic effects of radiation are well established. The doubling in the risk of ovarian cancer associated with eating 2 to 4 eggs per week is not immediately credible, since dietary habits are associated with a large number of lifestyle factors as well as SES [213]. In contrast, the credibility of much debated epidemiologic findings of a difference in thrombosis risk between different types of oral contraceptives was greatly enhanced by the differences in coagulation found in a randomised cross-over trial [214]. A discussion of the existing external evidence, from different types of studies, should always be included, but may be particularly important for studies reporting small increases in risk. Further, authors should put their results in context with similar studies and explain how the new study affects the existing body of evidence, ideally by referring to a systematic review.\n\n\nExamples\n\nAny explanation for an association between death from myocardial infarction and use of second generation oral contraceptives must be conjectural. There is no published evidence to suggest a direct biologic mechanism, and there are no other epidemiologic studies with relevant results. (…) The increase in absolute risk is very small and probably applies predominantly to smokers. Due to the lack of corroborative evidence, and because the analysis is based on relatively small numbers, more evidence on the subject is needed. We would not recommend any change in prescribing practice on the strength of these results\n\nBack to top\n\n\n\n\n\n\n21. Generisability\n\n\n\n\n\n\n\nDiscuss the generalisability (external validity) of the study results.\n\n\n\n\n\n\nRead more\n\n\n\n\n\nJump to:\n\nRead More\nExamples\n\n\nRead More\nGeneralisability, also called external validity or applicability, is the extent to which the results of a study can be applied to other circumstances [216]. There is no external validity per se; the term is meaningful only with regard to clearly specified conditions [217]. Can results be applied to an individual, groups or populations that differ from those enrolled in the study with regard to age, sex, ethnicity, severity of disease, and co-morbid conditions? Are the nature and level of exposures comparable, and the definitions of outcomes relevant to another setting or population? Are data that were collected in longitudinal studies many years ago still relevant today? Are results from health services research in one country applicable to health systems in other countries?\nThe question of whether the results of a study have external validity is often a matter of judgment that depends on the study setting, the characteristics of the participants, the exposures examined, and the outcomes assessed. Thus, it is crucial that authors provide readers with adequate information about the setting and locations, eligibility criteria, the exposures and how they were measured, the definition of outcomes, and the period of recruitment and follow-up. The degree of non-participation and the proportion of unexposed participants in whom the outcome develops are also relevant. Knowledge of the absolute risk and prevalence of the exposure, which will often vary across populations, are helpful when applying results to other settings and populations (see Box 7).\n\n\nExamples\n\nHow applicable are our estimates to other HIV-1-infected patients? This is an important question because the accuracy of prognostic models tends to be lower when applied to data other than those used to develop them. We addressed this issue by penalising model complexity, and by choosing models that generalised best to cohorts omitted from the estimation procedure. Our database included patients from many countries from Europe and North America, who were treated in different settings. The range of patients was broad: men and women, from teenagers to elderly people were included, and the major exposure categories were well represented. The severity of immunodeficiency at baseline ranged from not measureable to very severe, and viral load from undetectable to extremely high\n\nBack to top\n\n\n\n\n\n\nOther information\n\n\n22. Funding\n\n\n\n\n\n\n\nGive the source of funding and the role of the funders for the present study and, if applicable, for the original study on which the present article is based\n\n\n\n\n\n\nRead more\n\n\n\n\n\nRead More\nSome journals require authors to disclose the presence or absence of financial and other conflicts of interest [100,218]. Several investigations show strong associations between the source of funding and the conclusions of research articles [219–222]. The conclusions in randomised trials recommended the experimental drug as the drug of choice much more often (odds ratio 5.3) if the trial was funded by for-profit organisations, even after adjustment for the effect size [223]. Other studies document the influence of the tobacco and telecommunication industries on the research they funded [224–227]. There are also examples of undue influence when the sponsor is governmental or a non-profit organisation.\nAuthors or funders may have conflicts of interest that influence any of the following: the design of the study [228]; choice of exposures [228,229], outcomes [230], statistical methods [231], and selective publication of outcomes [230] and studies [232]. Consequently, the role of the funders should be described in detail: in what part of the study they took direct responsibility (e.g., design, data collection, analysis, drafting of manuscript, decision to publish) [100]. Other sources of undue influence include employers (e.g., university administrators for academic researchers and government supervisors, especially political appointees, for government researchers), advisory committees, litigants, and special interest groups."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-1a_title-1",
    "href": "guidelines/strobe/index.html#sec-1a_title-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nReaders should be able to easily identify the design that was used from the title or abstract. An explicit, commonly used term for the study design also helps ensure correct indexing of articles in electronic databases."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-1a_title-2",
    "href": "guidelines/strobe/index.html#sec-1a_title-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nLeukaemia incidence among workers in the shoe and boot manufacturing industry: a case-control study\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-1b_abstract-1",
    "href": "guidelines/strobe/index.html#sec-1b_abstract-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nThe abstract provides key information that enables readers to understand a study and decide whether to read the article. Typical components include a statement of the research question, a short description of methods and results, and a conclusion [22]. Abstracts should summarize key details of studies and should only present information that is provided in the article. We advise presenting key results in a numerical form that includes numbers of participants, estimates of associations and appropriate measures of variability and uncertainty (e.g., odds ratios with confidence intervals). We regard it insufficient to state only that an exposure is or is not significantly associated with an outcome."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-1b_abstract-2",
    "href": "guidelines/strobe/index.html#sec-1b_abstract-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nBackground: The expected survival of HIV-infected patients is of major public health interest.\n\n\nObjective: To estimate survival time and age-specific mortality rates of an HIV-infected population compared with that of the general population.\n\n\nDesign: Population-based cohort study.\n\n\nSetting: All HIV-infected persons receiving care in Denmark from 1995 to 2005.\n\n\nPatients: Each member of the nationwide Danish HIV Cohort Study was matched with as many as 99 persons from the general population according to sex, date of birth, and municipality of residence.\n\n\nMeasurements: The authors computed Kaplan-Meier life tables with age as the time scale to estimate survival from age 25 years. Patients with HIV infection and corresponding persons from the general population were observed from the date of the patient’s HIV diagnosis until death, emigration, or 1 May 2005.\n\n\nResults: 3990 HIV-infected patients and 379,872 persons from the general population were included in the study, yielding 22,744 (median, 5.8 y/person) and 2,689,287 (median, 8.4 years/person) person-years of observation. Three percent of participants were lost to follow-up. From age 25 years, the median survival was 19.9 years (95% CI, 18.5 to 21.3) among patients with HIV infection and 51.1 years (CI, 50.9 to 51.5) among the general population. For HIV-infected patients, survival increased to 32.5 years (CI, 29.4 to 34.7) during the 2000 to 2005 period. In the subgroup that excluded persons with known hepatitis C coinfection (16%), median survival was 38.9 years (CI, 35.4 to 40.1) during this same period. The relative mortality rates for patients with HIV infection compared with those for the general population decreased with increasing age, whereas the excess mortality rate increased with increasing age.\n\n\nLimitations: The observed mortality rates are assumed to apply beyond the current maximum observation time of 10 years.\n\n\nConclusions: The estimated median survival is more than 35 years for a young person diagnosed with HIV infection in the late highly active antiretroviral therapy era. However, an ongoing effort is still needed to further reduce mortality rates for these persons compared with the general population\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-2_background__rationale-1",
    "href": "guidelines/strobe/index.html#sec-2_background__rationale-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nThe scientific background of the study provides important context for readers. It sets the stage for the study and describes its focus. It gives an overview of what is known on a topic and what gaps in current knowledge are addressed by the study. Background material should note recent pertinent studies and any systematic reviews of pertinent studies."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-2_background__rationale-2",
    "href": "guidelines/strobe/index.html#sec-2_background__rationale-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nConcerns about the rising prevalence of obesity in children and adolescents have focused on the well documented associations between childhood obesity and increased cardiovascular risk1 and mortality in adulthood.2 Childhood obesity has considerable social and psychological consequences within childhood and adolescence,3 yet little is known about social, socioeconomic, and psychological consequences in adult life.\n\nA recent systematic review found no longitudinal studies on the outcomes of childhood obesity other than physical health outcomes3 and only two longitudinal studies of the socioeconomic effects of obesity in adolescence. Gortmaker et al found that US women who had been obese in late adolescence in 1981 were less likely to be married and had lower incomes seven years later than women who had not been overweight, while men who had been overweight were less likely to be married.4 Sargent et al found that UK women, but not men, who had been obese at 16 years in 1974 earned 7.4% less than their non-obese peers at age 23.5\nThe study of adult outcomes of childhood obesity is difficult because obesity often continues into adult life and therefore poorer socioeconomic and educational outcomes may actually reflect confounding by adult obesity. Yet identifying outcomes related to obesity confined childhood is important in determining whether people who are obese in childhood and who later lose weight remain at risk for adult adversity and inequalities.\nWe used longitudinal data from the 1970 British birth cohort to examine the adult socioeconomic, educational, social, and psychological outcomes of childhood obesity. We hypothesised that obesity limited to childhood has fewer adverse adult outcomes than obesity that persists into adult life\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-3_objectives-1",
    "href": "guidelines/strobe/index.html#sec-3_objectives-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nObjectives are the detailed aims of the study. Well crafted objectives specify populations, exposures and outcomes, and parameters that will be estimated. They may be formulated as specific hypotheses or as questions that the study was designed to address. In some situations objectives may be less specific, for example, in early discovery phases. Regardless, the report should clearly reflect the investigators’ intentions. For example, if important subgroups or additional analyses were not the original aim of the study but arose during data analysis, they should be described accordingly (see also items 4, 17 and 20)."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-3_objectives-2",
    "href": "guidelines/strobe/index.html#sec-3_objectives-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nOur primary objectives were to 1) determine the prevalence of domestic violence among female patients presenting to four community-based, primary care, adult medicine practices that serve patients of diverse socioeconomic background and 2) identify demographic and clinical differences between currently abused patients and patients not currently being abused\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-4_study_design-1",
    "href": "guidelines/strobe/index.html#sec-4_study_design-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nWe advise presenting key elements of study design early in the methods section (or at the end of the introduction) so that readers can understand the basics of the study. For example, authors should indicate that the study was a cohort study, which followed people over a particular time period, and describe the group of persons that comprised the cohort and their exposure status. Similarly, if the investigation used a case-control design, the cases and controls and their source population should be described. If the study was a cross-sectional survey, the population and the point in time at which the cross-section was taken should be mentioned. When a study is a variant of the three main study types, there is an additional need for clarity. For instance, for a case-crossover study, one of the variants of the case-control design, a succinct description of the principles was given in the example above [28].\nWe recommend that authors refrain from simply calling a study ‘prospective’ or ‘retrospective’ because these terms are ill defined [29]. One usage sees cohort and prospective as synonymous and reserves the word retrospective for case-control studies [30]. A second usage distinguishes prospective and retrospective cohort studies according to the timing of data collection relative to when the idea for the study was developed [31]. A third usage distinguishes prospective and retrospective case-control studies depending on whether the data about the exposure of interest existed when cases were selected [32]. Some advise against using these terms [33], or adopting the alternatives ‘concurrent’ and ‘historical’ for describing cohort studies [34]. In STROBE, we do not use the words prospective and retrospective, nor alternatives such as concurrent and historical. We recommend that, whenever authors use these words, they define what they mean. Most importantly, we recommend that authors describe exactly how and when data collection took place.\nThe first part of the methods section might also be the place to mention whether the report is one of several from a study. If a new report is in line with the original aims of the study, this is usually indicated by referring to an earlier publication and by briefly restating the salient features of the study. However, the aims of a study may also evolve over time. Researchers often use data for purposes for which they were not originally intended, including, for example, official vital statistics that were collected primarily for administrative purposes, items in questionnaires that originally were only included for completeness, or blood samples that were collected for another purpose. For example, the Physicians’ Health Study, a randomized controlled trial of aspirin and carotene, was later used to demonstrate that a point mutation in the factor V gene was associated with an increased risk of venous thrombosis, but not of myocardial infarction or stroke [35]. The secondary use of existing data is a creative part of observational research and does not necessarily make results less credible or less important. However, briefly restating the original aims might help readers understand the context of the research and possible limitations in the data."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-4_study_design-2",
    "href": "guidelines/strobe/index.html#sec-4_study_design-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nWe used a case-crossover design, a variation of a case-control design that is appropriate when a brief exposure (driver’s phone use) causes a transient rise in the risk of a rare outcome (a crash). We compared a driver’s use of a mobile phone at the estimated time of a crash with the same driver’s use during another suitable time period. Because drivers are their own controls, the design controls for characteristics of the driver that may affect the risk of a crash but do not change over a short period of time. As it is important that risks during control periods and crash trips are similar, we compared phone activity during the hazard interval (time immediately before the crash) with phone activity during control intervals (equivalent times during which participants were driving but did not crash) in the previous week\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-5_setting-1",
    "href": "guidelines/strobe/index.html#sec-5_setting-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nReaders need information on setting and locations to assess the context and generalisability of a study’s results. Exposures such as environmental factors and therapies can change over time. Also, study methods may evolve over time. Knowing when a study took place and over what period participants were recruited and followed up places the study in historical context and is important for the interpretation of results.\nInformation about setting includes recruitment sites or sources (e.g., electoral roll, outpatient clinic, cancer registry, or tertiary care centre). Information about location may refer to the countries, towns, hospitals or practices where the investigation took place. We advise stating dates rather than only describing the length of time periods. There may be different sets of dates for exposure, disease occurrence, recruitment, beginning and end of follow-up, and data collection. Of note, nearly 80% of 132 reports in oncology journals that used survival analysis included the starting and ending dates for accrual of patients, but only 24% also reported the date on which follow-up ended [37]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-5_setting-2",
    "href": "guidelines/strobe/index.html#sec-5_setting-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nThe Pasitos Cohort Study recruited pregnant women from Women, Infant and Child (WIC) clinics in Socorro and San Elizario, El Paso County, Texas and maternal-child clinics of the Mexican Social Security Institute (IMSS) in Ciudad Juarez, Mexico from April 1998 to October 2000. At baseline, prior to the birth of the enrolled cohort children, staff interviewed mothers regarding the household environment. In this ongoing cohort study, we target follow-up exams at 6-month intervals beginning at age 6 months\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-6a_eligibility_criteria-1",
    "href": "guidelines/strobe/index.html#sec-6a_eligibility_criteria-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nDetailed descriptions of the study participants help readers understand the applicability of the results. Investigators usually restrict a study population by defining clinical, demographic and other characteristics of eligible participants. Typical eligibility criteria relate to age, gender, diagnosis and comorbid conditions. Despite their importance, eligibility criteria often are not reported adequately. In a survey of observational stroke research, 17 of 49 reports (35%) did not specify eligibility criteria [5].\nEligibility criteria may be presented as inclusion and exclusion criteria, although this distinction is not always necessary or useful. Regardless, we advise authors to report all eligibility criteria and also to describe the group from which the study population was selected (e.g., the general population of a region or country), and the method of recruitment (e.g., referral or self-selection through advertisements).\nKnowing details about follow-up procedures, including whether procedures minimized non-response and loss to follow-up and whether the procedures were similar for all participants, informs judgments about the validity of results. For example, in a study that used IgM antibodies to detect acute infections, readers needed to know the interval between blood tests for IgM antibodies so that they could judge whether some infections likely were missed because the interval between blood tests was too long [41]. In other studies where follow-up procedures differed between exposed and unexposed groups, readers might recognize substantial bias due to unequal ascertainment of events or differences in non-response or loss to follow-up [42]. Accordingly, we advise that researchers describe the methods used for following participants and whether those methods were the same for all participants, and that they describe the completeness of ascertainment of variables (see also item 14).\nIn case-control studies, the choice of cases and controls is crucial to interpreting the results, and the method of their selection has major implications for study validity. In general, controls should reflect the population from which the cases arose. Various methods are used to sample controls, all with advantages and disadvantages: for cases that arise from a general population, population roster sampling, random digit dialling, neighbourhood or friend controls are used. Neighbourhood or friend controls may present intrinsic matching on exposure [17]. Controls with other diseases may have advantages over population-based controls, in particular for hospital-based cases, because they better reflect the catchment population of a hospital, have greater comparability of recall and ease of recruitment. However, they can present problems if the exposure of interest affects the risk of developing or being hospitalized for the control condition(s) [43,44]. To remedy this problem often a mixture of the best defensible control diseases is used [45]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-6a_eligibility_criteria-2",
    "href": "guidelines/strobe/index.html#sec-6a_eligibility_criteria-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nCohort study: Participants in the Iowa Women’s Health Study were a random sample of all women ages 55 to 69 years derived from the state of Iowa automobile driver’s license list in 1985, which represented approximately 94% of Iowa women in that age group. (…) Follow-up questionnaires were mailed in October 1987 and August 1989 to assess vital status and address changes. (…) Incident cancers, except for nonmelanoma skin cancers, were ascertained by the State Health Registry of Iowa (…). The Iowa Women’s Health Study cohort was matched to the registry with combinations of first, last, and maiden names, zip code, birthdate, and social security number.\n\n\nCase-control study: Cutaneous melanoma cases diagnosed in 1999 and 2000 were ascertained through the Iowa Cancer Registry (…). Controls, also identified through the Iowa Cancer Registry, were colorectal cancer patients diagnosed during the same time. Colorectal cancer controls were selected because they are common and have a relatively long survival, and because arsenic exposure has not been conclusively linked to the incidence of colorectal cancer.\n\n\n“Cross-sectional study:** We retrospectively identified patients with a principal diagnosis of myocardial infarction (code 410) according to the International Classification of Diseases, 9th Revision, Clinical Modification, from codes designating discharge diagnoses, excluding the codes with a fifth digit of 2, which designates a subsequent episode of care (…) A random sample of the entire Medicare cohort with myocardial infarction from February 1994 to July 1995 was selected (…) To be eligible, patients had to present to the hospital after at least 30 minutes but less than 12 hours of chest pain and had to have ST-segment elevation of at least 1 mm on two contiguous leads on the initial electrocardiogram.\n\n\n\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-6b_matching_criteria-1",
    "href": "guidelines/strobe/index.html#sec-6b_matching_criteria-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nMatching is much more common in case-control studies, but occasionally, investigators use matching in cohort studies to make groups comparable at the start of follow-up. Matching in cohort studies makes groups directly comparable for potential confounders and presents fewer intricacies than with case-control studies. For example, it is not necessary to take the matching into account for the estimation of the relative risk [48]. Because matching in cohort studies may increase statistical precision investigators might allow for the matching in their analyses and thus obtain narrower confidence intervals.\nIn case-control studies matching is done to increase a study’s efficiency by ensuring similarity in the distribution of variables between cases and controls, in particular the distribution of potential confounding variables [48,49]. Because matching can be done in various ways, with one or more controls per case, the rationale for the choice of matching variables and the details of the method used should be described. Commonly used forms of matching are frequency matching (also called group matching) and individual matching. In frequency matching, investigators choose controls so that the distribution of matching variables becomes identical or similar to that of cases. Individual matching involves matching one or several controls to each case. Although intuitively appealing and sometimes useful, matching in case-control studies has a number of disadvantages, is not always appropriate, and needs to be taken into account in the analysis (see Box 2).\nEven apparently simple matching procedures may be poorly reported. For example, authors may state that controls were matched to cases ‘within five years’, or using ‘five year age bands’. Does this mean that, if a case was 54 years old, the respective control needed to be in the five-year age band 50 to 54, or aged 49 to 59, which is within five years of age 54? If a wide (e.g., 10-year) age band is chosen, there is a danger of residual confounding by age (see also Box 4), for example because controls may then be younger than cases on average."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-6b_matching_criteria-2",
    "href": "guidelines/strobe/index.html#sec-6b_matching_criteria-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nCohort study: For each patient who initially received a statin, we used propensity-based matching to identify one control who did not receive a statin according to the following protocol. First, propensity scores were calculated for each patient in the entire cohort on the basis of an extensive list of factors potentially related to the use of statins or the risk of sepsis. Second, each statin user was matched to a smaller pool of non-statin-users by sex, age (plus or minus 1 year), and index date (plus or minus 3 months). Third, we selected the control with the closest propensity score (within 0.2 SD) to each statin user in a 1:1 fashion and discarded the remaining controls.\n\n\nCase-control study: We aimed to select five controls for every case from among individuals in the study population who had no diagnosis of autism or other pervasive developmental disorders (PDD) recorded in their general practice record and who were alive and registered with a participating practice on the date of the PDD diagnosis in the case. Controls were individually matched to cases by year of birth (up to 1 year older or younger), sex, and general practice. For each of 300 cases, five controls could be identified who met all the matching criteria. For the remaining 994, one or more controls was excluded…\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-7_variables-1",
    "href": "guidelines/strobe/index.html#sec-7_variables-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nAuthors should define all variables considered for and included in the analysis, including outcomes, exposures, predictors, potential confounders and potential effect modifiers. Disease outcomes require adequately detailed description of the diagnostic criteria. This applies to criteria for cases in a case-control study, disease events during follow-up in a cohort study and prevalent disease in a cross-sectional study. Clear definitions and steps taken to adhere to them are particularly important for any disease condition of primary interest in the study.\nFor some studies, ‘determinant’ or ‘predictor’ may be appropriate terms for exposure variables and outcomes may be called ‘endpoints’. In multivariable models, authors sometimes use ‘dependent variable’ for an outcome and ‘independent variable’ or ‘explanatory variable’ for exposure and confounding variables. The latter is not precise as it does not distinguish exposures from confounders.\nIf many variables have been measured and included in exploratory analyses in an early discovery phase, consider providing a list with details on each variable in an appendix, additional table or separate publication. Of note, the International Journal of Epidemiology recently launched a new section with ‘cohort profiles’, that includes detailed information on what was measured at different points in time in particular studies [56,57]. Finally, we advise that authors declare all ‘candidate variables’ considered for statistical analysis, rather than selectively reporting only those included in the final models (see also item 16a) [58,59]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-7_variables-2",
    "href": "guidelines/strobe/index.html#sec-7_variables-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nOnly major congenital malformations were included in the analyses. Minor anomalies were excluded according to the exclusion list of European Registration of Congenital Anomalies (EUROCAT). If a child had more than one major congenital malformation of one organ system, those malformations were treated as one outcome in the analyses by organ system (…) In the statistical analyses, factors considered potential confounders were maternal age at delivery and number of previous parities. Factors considered potential effect modifiers were maternal age at reimbursement for antiepileptic medication and maternal age at delivery\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-8_data_sources__measurement-1",
    "href": "guidelines/strobe/index.html#sec-8_data_sources__measurement-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nThe way in which exposures, confounders and outcomes were measured affects the reliability and validity of a study. Measurement error and misclassification of exposures or outcomes can make it more difficult to detect cause-effect relationships, or may produce spurious relationships. Error in measurement of potential confounders can increase the risk of residual confounding [62,63]. It is helpful, therefore, if authors report the findings of any studies of the validity or reliability of assessments or measurements, including details of the reference standard that was used. Rather than simply citing validation studies (as in the first example), we advise that authors give the estimated validity or reliability, which can then be used for measurement error adjustment or sensitivity analyses (see items 12e and 17).\nIn addition, it is important to know if groups being compared differed with respect to the way in which the data were collected. This may be important for laboratory examinations (as in the second example) and other situations. For instance, if an interviewer first questions all the cases and then the controls, or vice versa, bias is possible because of the learning curve; solutions such as randomising the order of interviewing may avoid this problem. Information bias may also arise if the compared groups are not given the same diagnostic tests or if one group receives more tests of the same kind than another (see also item 9)."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-8_data_sources__measurement-2",
    "href": "guidelines/strobe/index.html#sec-8_data_sources__measurement-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nTotal caffeine intake was calculated primarily using US Department of Agriculture food composition sources. In these calculations, it was assumed that the content of caffeine was 137 mg per cup of coffee, 47 mg per cup of tea, 46 mg per can or bottle of cola beverage, and 7 mg per serving of chocolate candy. This method of measuring (caffeine) intake was shown to be valid in both the NHS I cohort and a similar cohort study of male health professionals (…) Self-reported diagnosis of hypertension was found to be reliable in the NHS I cohort\n\n\nSamples pertaining to matched cases and controls were always analyzed together in the same batch and laboratory personnel were unable to distinguish among cases and controls\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-9_bias-1",
    "href": "guidelines/strobe/index.html#sec-9_bias-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nBiased studies produce results that differ systematically from the truth (see also Box 3). It is important for a reader to know what measures were taken during the conduct of a study to reduce the potential of bias. Ideally, investigators carefully consider potential sources of bias when they plan their study. At the stage of reporting, we recommend that authors always assess the likelihood of relevant biases. Specifically, the direction and magnitude of bias should be discussed and, if possible, estimated. For instance, in case-control studies information bias can occur, but may be reduced by selecting an appropriate control group, as in the first example [64]. Differences in the medical surveillance of participants were a problem in the second example [65]. Consequently, the authors provide more detail about the additional data they collected to tackle this problem. When investigators have set up quality control programs for data collection to counter a possible “drift” in measurements of variables in longitudinal studies, or to keep variability at a minimum when multiple observers are used, these should be described.\nUnfortunately, authors often do not address important biases when reporting their results. Among 43 case-control and cohort studies published from 1990 to 1994 that investigated the risk of second cancers in patients with a history of cancer, medical surveillance bias was mentioned in only 5 articles [66]. A survey of reports of mental health research published during 1998 in three psychiatric journals found that only 13% of 392 articles mentioned response bias [67]. A survey of cohort studies in stroke research found that 14 of 49 (28%) articles published from 1999 to 2003 addressed potential selection bias in the recruitment of study participants and 35 (71%) mentioned the possibility that any type of bias may have affected results [5]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-9_bias-2",
    "href": "guidelines/strobe/index.html#sec-9_bias-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nIn most case-control studies of suicide, the control group comprises living individuals but we decided to have a control group of people who had died of other causes (…). With a control group of deceased individuals, the sources of information used to assess risk factors are informants who have recently experienced the death of a family member or close associate - and are therefore more comparable to the sources of information in the suicide group than if living controls were used\n\n\nDetection bias could influence the association between Type 2 diabetes mellitus (T2DM) and primary open-angle glaucoma (POAG) if women with T2DM were under closer ophthalmic surveillance than women without this condition. We compared the mean number of eye examinations reported by women with and without diabetes. We also recalculated the relative risk for POAG with additional control for covariates associated with more careful ocular surveillance (a self-report of cataract, macular degeneration, number of eye examinations, and number of physical examinations)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-10_study_size-1",
    "href": "guidelines/strobe/index.html#sec-10_study_size-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nA study should be large enough to obtain a point estimate with a sufficiently narrow confidence interval to meaningfully answer a research question. Large samples are needed to distinguish a small association from no association. Small studies often provide valuable information, but wide confidence intervals may indicate that they contribute less to current knowledge in comparison with studies providing estimates with narrower confidence intervals. Also, small studies that show ‘interesting’ or ‘statistically significant’ associations are published more frequently than small studies that do not have ‘significant’ findings. While these studies may provide an early signal in the context of discovery, readers should be informed of their potential weaknesses.\nThe importance of sample size determination in observational studies depends on the context. If an analysis is performed on data that were already available for other purposes, the main question is whether the analysis of the data will produce results with sufficient statistical precision to contribute substantially to the literature, and sample size considerations will be informal. Formal, a priori calculation of sample size may be useful when planning a new study [75,76]. Such calculations are associated with more uncertainty than implied by the single number that is generally produced. For example, estimates of the rate of the event of interest or other assumptions central to calculations are commonly imprecise, if not guesswork [77]. The precision obtained in the final analysis can often not be determined beforehand because it will be reduced by inclusion of confounding variables in multivariable analyses [78], the degree of precision with which key variables can be measured [79], and the exclusion of some individuals.\nFew epidemiological studies explain or report deliberations about sample size [4,5]. We encourage investigators to report pertinent formal sample size calculations if they were done. In other situations they should indicate the considerations that determined the study size (e.g., a fixed available sample, as in the first example above). If the observational study was stopped early when statistical significance was achieved, readers should be told. Do not bother readers with post hoc justifications for study size or retrospective power calculations [77]. From the point of view of the reader, confidence intervals indicate the statistical precision that was ultimately obtained. It should be realized that confidence intervals reflect statistical uncertainty only, and not all uncertainty that may be present in a study (see item 20)."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-10_study_size-2",
    "href": "guidelines/strobe/index.html#sec-10_study_size-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nThe number of cases in the area during the study period determined the sample size\n\n\nA survey of postnatal depression in the region had documented a prevalence of 19.8%. Assuming depression in mothers with normal weight children to be 20% and an odds ratio of 3 for depression in mothers with a malnourished child we needed 72 case-control sets (one case to one control) with an 80% power and 5% significance\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-11_quantitative_variables-1",
    "href": "guidelines/strobe/index.html#sec-11_quantitative_variables-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nInvestigators make choices regarding how to collect and analyse quantitative data about exposures, effect modifiers and confounders. For example, they may group a continuous exposure variable to create a new categorical variable (see Box 4). Grouping choices may have important consequences for later analyses [81,82]. We advise that authors explain why and how they grouped quantitative data, including the number of categories, the cut-points, and category mean or median values. Whenever data are reported in tabular form, the counts of cases, controls, persons at risk, person-time at risk, etc. should be given for each category. Tables should not consist solely of effect-measure estimates or results of model fitting.\nInvestigators might model an exposure as continuous in order to retain all the information. In making this choice, one needs to consider the nature of the relationship of the exposure to the outcome. As it may be wrong to assume a linear relation automatically, possible departures from linearity should be investigated. Authors could mention alternative models they explored during analyses (e.g., using log transformation, quadratic terms or spline functions). Several methods exist for fitting a non-linear relation between the exposure and outcome [82–84]. Also, it may be informative to present both continuous and grouped analyses for a quantitative exposure of prime interest.\nIn a recent survey, two thirds of epidemiological publications studied quantitative exposure variables [4]. In 42 of 50 articles (84%) exposures were grouped into several ordered categories, but often without any stated rationale for the choices made. Fifteen articles used linear associations to model continuous exposure but only two reported checking for linearity. In another survey, of the psychological literature, dichotomization was justified in only 22 of 110 articles (20%) [85]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-11_quantitative_variables-2",
    "href": "guidelines/strobe/index.html#sec-11_quantitative_variables-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nPatients with a Glasgow Coma Scale less than 8 are considered to be seriously injured. A GCS of 9 or more indicates less serious brain injury. We examined the association of GCS in these two categories with the occurrence of death within 12 months from injury\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12a_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12a_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nIn general, there is no one correct statistical analysis but, rather, several possibilities that may address the same question, but make different assumptions. Regardless, investigators should pre-determine analyses at least for the primary study objectives in a study protocol. Often additional analyses are needed, either instead of, or as well as, those originally envisaged, and these may sometimes be motivated by the data. When a study is reported, authors should tell readers whether particular analyses were suggested by data inspection. Even though the distinction between pre-specified and exploratory analyses may sometimes be blurred, authors should clarify reasons for particular analyses.\nIf groups being compared are not similar with regard to some characteristics, adjustment should be made for possible confounding variables by stratification or by multivariable regression (see Box 5) [94]. Often, the study design determines which type of regression analysis is chosen. For instance, Cox proportional hazard regression is commonly used in cohort studies [95]. whereas logistic regression is often the method of choice in case-control studies [96,97]. Analysts should fully describe specific procedures for variable selection and not only present results from the final model [98,99]. If model comparisons are made to narrow down a list of potential confounders for inclusion in a final model, this process should be described. It is helpful to tell readers if one or two covariates are responsible for a great deal of the apparent confounding in a data analysis. Other statistical analyses such as imputation procedures, data transformation, and calculations of attributable risks should also be described. Non-standard or novel approaches should be referenced and the statistical software used reported. As a guiding principle, we advise statistical methods be described “with enough detail to enable a knowledgeable reader with access to the original data to verify the reported results” [100].\nIn an empirical study, only 93 of 169 articles (55%) reporting adjustment for confounding clearly stated how continuous and multi-category variables were entered into the statistical model [101]. Another study found that among 67 articles in which statistical analyses were adjusted for confounders, it was mostly unclear how confounders were chosen [4]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12a_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12a_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nThe adjusted relative risk was calculated using the Mantel-Haenszel technique, when evaluating if confounding by age or gender was present in the groups compared. The 95% confidence interval (CI) was computed around the adjusted relative risk, using the variance according to Greenland and Robins and Robins et al\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12b_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12b_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nAs discussed in detail under item 17, many debate the use and value of analyses restricted to subgroups of the study population [4,104]. Subgroup analyses are nevertheless often done [4]. Readers need to know which subgroup analyses were planned in advance, and which arose while analysing the data. Also, it is important to explain what methods were used to examine whether effects or associations differed across groups (see item 17).\nInteraction relates to the situation when one factor modifies the effect of another (therefore also called ‘effect modification’). The joint action of two factors can be characterized in two ways: on an additive scale, in terms of risk differences; or on a multiplicative scale, in terms of relative risk (see Box 8). Many authors and readers may have their own preference about the way interactions should be analysed. Still, they may be interested to know to what extent the joint effect of exposures differs from the separate effects. There is consensus that the additive scale, which uses absolute risks, is more appropriate for public health and clinical decision making [105]. Whatever view is taken, this should be clearly presented to the reader, as is done in the example above [103]. A lay-out presenting separate effects of both exposures as well as their joint effect, each relative to no exposure, might be most informative. It is presented in the example for interaction under item 17, and the calculations on the different scales are explained in Box 8."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12b_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12b_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nSex differences in susceptibility to the 3 lifestyle-related risk factors studied were explored by testing for biological interaction according to Rothman: a new composite variable with 4 categories (a − b − , a − b+, a+b − , and a+b+) was redefined for sex and a dichotomous exposure of interest where a− and b− denote absence of exposure. RR was calculated for each category after adjustment for age. An interaction effect is defined as departure from additivity of absolute effects, and excess RR caused by interaction (RERI) was calculated:\n\n[equation image]\nwhere RR(a+b+) denotes RR among those exposed to both factors where RR(a − b −) is used as reference category (RR = 1.0). Ninety-five percent CIs were calculated as proposed by Hosmer and Lemeshow. RERI of 0 means no interaction\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12c_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12c_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nMissing data are common in observational research. Questionnaires posted to study participants are not always filled in completely, participants may not attend all follow-up visits and routine data sources and clinical databases are often incomplete. Despite its ubiquity and importance, few papers report in detail on the problem of missing data [5,107]. Investigators may use any of several approaches to address missing data. We describe some strengths and limitations of various approaches in Box 6. We advise that authors report the number of missing values for each variable of interest (exposures, outcomes, confounders) and for each step in the analysis. Authors should give reasons for missing values if possible, and indicate how many individuals were excluded because of missing data when describing the flow of participants through the study (see also item 13). For analyses that account for missing data, authors should describe the nature of the analysis (e.g., multiple imputation) and the assumptions that were made (e.g., missing at random, see Box 6)."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12c_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12c_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nOur missing data analysis procedures used missing at random (MAR) assumptions. We used the MICE (multivariate imputation by chained equations) method of multiple multivariate imputation in STATA. We independently analysed 10 copies of the data, each with missing values suitably imputed, in the multivariate logistic regression analyses. We averaged estimates of the variables to give a single mean estimate and adjusted standard errors according to Rubin’s rules\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12di_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12di_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nCohort studies are analysed using life table methods or other approaches that are based on the person-time of follow-up and time to developing the disease of interest. Among individuals who remain free of the disease at the end of their observation period, the amount of follow-up time is assumed to be unrelated to the probability of developing the outcome. This will be the case if follow-up ends on a fixed date or at a particular age. Loss to follow-up occurs when participants withdraw from a study before that date. This may hamper the validity of a study if loss to follow-up occurs selectively in exposed individuals, or in persons at high risk of developing the disease (‘informative censoring’). In the example above, patients lost to follow-up in treatment programmes with no active follow-up had fewer CD4 helper cells than those remaining under observation and were therefore at higher risk of dying [116].\nIt is important to distinguish persons who reach the end of the study from those lost to follow-up. Unfortunately, statistical software usually does not distinguish between the two situations: in both cases follow-up time is automatically truncated (‘censored’) at the end of the observation period. Investigators therefore need to decide, ideally at the stage of planning the study, how they will deal with loss to follow-up. When few patients are lost, investigators may either exclude individuals with incomplete follow-up, or treat them as if they withdrew alive at either the date of loss to follow-up or the end of the study. We advise authors to report how many patients were lost to follow-up and what censoring strategies they used."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12di_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12di_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nIn treatment programmes with active follow-up, those lost to follow-up and those followed-up at 1 year had similar baseline CD4 cell counts (median 115 cells per μL and 123 cells per μL), whereas patients lost to follow-up in programmes with no active follow-up procedures had considerably lower CD4 cell counts than those followed-up (median 64 cells per μL and 123 cells per μL). (…) Treatment programmes with passive follow-up were excluded from subsequent analyses\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12dii_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12dii_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nIn individually matched case-control studies a crude analysis of the odds ratio, ignoring the matching, usually leads to an estimation that is biased towards unity (see Box 2). A matched analysis is therefore often necessary. This can intuitively be understood as a stratified analysis: each case is seen as one stratum with his or her set of matched controls. The analysis rests on considering whether the case is more often exposed than the controls, despite having made them alike regarding the matching variables. Investigators can do such a stratified analysis using the Mantel-Haenszel method on a ‘matched’ 2 by 2 table. In its simplest form the odds ratio becomes the ratio of pairs that are discordant for the exposure variable. If matching was done for variables like age and sex that are universal attributes, the analysis needs not retain the individual, person-to-person matching: a simple analysis in categories of age and sex is sufficient [50]. For other matching variables, such as neighbourhood, sibship, or friendship, however, each matched set should be considered its own stratum.\nIn individually matched studies, the most widely used method of analysis is conditional logistic regression, in which each case and their controls are considered together. The conditional method is necessary when the number of controls varies among cases, and when, in addition to the matching variables, other variables need to be adjusted for. To allow readers to judge whether the matched design was appropriately taken into account in the analysis, we recommend that authors describe in detail what statistical methods were used to analyse the data. If taking the matching into account does have little effect on the estimates, authors may choose to present an unmatched analysis."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12dii_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12dii_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nWe used McNemar’s test, paired t test, and conditional logistic regression analysis to compare dementia patients with their matched controls for cardiovascular risk factors, the occurrence of spontaneous cerebral emboli, carotid disease, and venous to arterial circulation shunt\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12diii_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12diii_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nMost cross-sectional studies use a pre-specified sampling strategy to select participants from a source population. Sampling may be more complex than taking a simple random sample, however. It may include several stages and clustering of participants (e.g., in districts or villages). Proportionate stratification may ensure that subgroups with a specific characteristic are correctly represented. Disproportionate stratification may be useful to over-sample a subgroup of particular interest.\nAn estimate of association derived from a complex sample may be more or less precise than that derived from a simple random sample. Measures of precision such as standard error or confidence interval should be corrected using the design effect, a ratio measure that describes how much precision is gained or lost if a more complex sampling strategy is used instead of simple random sampling [119]. Most complex sampling techniques lead to a decrease of precision, resulting in a design effect greater than 1.\nWe advise that authors clearly state the method used to adjust for complex sampling strategies so that readers may understand how the chosen sampling method influenced the precision of the obtained estimates. For instance, with clustered sampling, the implicit trade-off between easier data collection and loss of precision is transparent if the design effect is reported. In the example, the calculated design effects of 1.9 for men indicates that the actual sample size would need to be 1.9 times greater than with simple random sampling for the resulting estimates to have equal precision."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12diii_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12diii_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nThe standard errors (SE) were calculated using the Taylor expansion method to estimate the sampling errors of estimators based on the complex sample design. (…) The overall design effect for diastolic blood pressure was found to be 1.9 for men and 1.8 for women and, for systolic blood pressure, it was 1.9 for men and 2.0 for women\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12e_statistical_methods-1",
    "href": "guidelines/strobe/index.html#sec-12e_statistical_methods-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nSensitivity analyses are useful to investigate whether or not the main results are consistent with those obtained with alternative analysis strategies or assumptions [121]. Issues that may be examined include the criteria for inclusion in analyses, the definitions of exposures or outcomes [122], which confounding variables merit adjustment, the handling of missing data [120,123], possible selection bias or bias from inaccurate or inconsistent measurement of exposure, disease and other variables, and specific analysis choices, such as the treatment of quantitative variables (see item 11). Sophisticated methods are increasingly used to simultaneously model the influence of several biases or assumptions [124–126].\nIn 1959 Cornfield et al. famously showed that a relative risk of 9 for cigarette smoking and lung cancer was extremely unlikely to be due to any conceivable confounder, since the confounder would need to be at least nine times as prevalent in smokers as in non-smokers [127]. This analysis did not rule out the possibility that such a factor was present, but it did identify the prevalence such a factor would need to have. The same approach was recently used to identify plausible confounding factors that could explain the association between childhood leukaemia and living near electric power lines [128]. More generally, sensitivity analyses can be used to identify the degree of confounding, selection bias, or information bias required to distort an association. One important, perhaps under recognised, use of sensitivity analysis is when a study shows little or no association between an exposure and an outcome and it is plausible that confounding or other biases toward the null are present."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-12e_statistical_methods-2",
    "href": "guidelines/strobe/index.html#sec-12e_statistical_methods-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nBecause we had a relatively higher proportion of ‘missing’ dead patients with insufficient data (38/148=25.7%) as compared to live patients (15/437=3.4%) (…), it is possible that this might have biased the results. We have, therefore, carried out a sensitivity analysis. We have assumed that the proportion of women using oral contraceptives in the study group applies to the whole (19.1% for dead, and 11.4% for live patients), and then applied two extreme scenarios: either all the exposed missing patients used second generation pills or they all used third-generation pills\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-13a_participants-1",
    "href": "guidelines/strobe/index.html#sec-13a_participants-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nDetailed information on the process of recruiting study participants is important for several reasons. Those included in a study often differ in relevant ways from the target population to which results are applied. This may result in estimates of prevalence or incidence that do not reflect the experience of the target population. For example, people who agreed to participate in a postal survey of sexual behaviour attended church less often, had less conservative sexual attitudes and earlier age at first sexual intercourse, and were more likely to smoke cigarettes and drink alcohol than people who refused [130]. These differences suggest that postal surveys may overestimate sexual liberalism and activity in the population. Such response bias (see Box 3) can distort exposure-disease associations if associations differ between those eligible for the study and those included in the study. As another example, the association between young maternal age and leukaemia in offspring, which has been observed in some case-control studies [131,132], was explained by differential participation of young women in case and control groups. Young women with healthy children were less likely to participate than those with unhealthy children [133]. Although low participation does not necessarily compromise the validity of a study, transparent information on participation and reasons for non-participation is essential. Also, as there are no universally agreed definitions for participation, response or follow-up rates, readers need to understand how authors calculated such proportions [134].\nIdeally, investigators should give an account of the numbers of individuals considered at each stage of recruiting study participants, from the choice of a target population to the inclusion of participants’ data in the analysis. Depending on the type of study, this may include the number of individuals considered to be potentially eligible, the number assessed for eligibility, the number found to be eligible, the number included in the study, the number examined, the number followed up and the number included in the analysis. Information on different sampling units may be required, if sampling of study participants is carried out in two or more stages as in the example above (multistage sampling). In case-control studies, we advise that authors describe the flow of participants separately for case and control groups [135]. Controls can sometimes be selected from several sources, including, for example, hospitalised patients and community dwellers. In this case, we recommend a separate account of the numbers of participants for each type of control group. Olson and colleagues proposed useful reporting guidelines for controls recruited through random-digit dialling and other methods [136].\nA recent survey of epidemiological studies published in 10 general epidemiology, public health and medical journals found that some information regarding participation was provided in 47 of 107 case-control studies (59%), 49 of 154 cohort studies (32%), and 51 of 86 cross-sectional studies (59%) [137]. Incomplete or absent reporting of participation and non-participation in epidemiological studies was also documented in two other surveys of the literature [4,5]. Finally, there is evidence that participation in epidemiological studies may have declined in recent decades [137,138], which underscores the need for transparent reporting [139]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-13a_participants-2",
    "href": "guidelines/strobe/index.html#sec-13a_participants-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nOf the 105 freestanding bars and taverns sampled, 13 establishments were no longer in business and 9 were located in restaurants, leaving 83 eligible businesses. In 22 cases, the owner could not be reached by telephone despite 6 or more attempts. The owners of 36 bars declined study participation. (…) The 25 participating bars and taverns employed 124 bartenders, with 67 bartenders working at least 1 weekly daytime shift. Fifty-four of the daytime bartenders (81%) completed baseline interviews and spirometry; 53 of these subjects (98%) completed follow-up\n\n\nFlow diagram from Hay et al (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/figure/pmed-0040297-g001/)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-13b_participants-1",
    "href": "guidelines/strobe/index.html#sec-13b_participants-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nExplaining the reasons why people no longer participated in a study or why they were excluded from statistical analyses helps readers judge whether the study population was representative of the target population and whether bias was possibly introduced. For example, in a cross-sectional health survey, non-participation due to reasons unlikely to be related to health status (for example, the letter of invitation was not delivered because of an incorrect address) will affect the precision of estimates but will probably not introduce bias. Conversely, if many individuals opt out of the survey because of illness, or perceived good health, results may underestimate or overestimate the prevalence of ill health in the population."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-13b_participants-2",
    "href": "guidelines/strobe/index.html#sec-13b_participants-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nThe main reasons for non-participation were the participant was too ill or had died before interview (cases 30%, controls &lt; 1%), nonresponse (cases 2%, controls 21%), refusal (cases 10%, controls 29%), and other reasons (refusal by consultant or general practitioner, non-English speaking, mental impairment) (cases 7%, controls 5%)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-13c_participants-1",
    "href": "guidelines/strobe/index.html#sec-13c_participants-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nAn informative and well-structured flow diagram can readily and transparently convey information that might otherwise require a lengthy description [142], as in the example above. The diagram may usefully include the main results, such as the number of events for the primary outcome. While we recommend the use of a flow diagram, particularly for complex observational studies, we do not propose a specific format for the diagram."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-14a_-1",
    "href": "guidelines/strobe/index.html#sec-14a_-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nReaders need descriptions of study participants and their exposures to judge the generalisability of the findings. Information about potential confounders, including whether and how they were measured, influences judgments about study validity. We advise authors to summarize continuous variables for each study group by giving the mean and standard deviation, or when the data have an asymmetrical distribution, as is often the case, the median and percentile range (e.g., 25th and 75th percentiles). Variables that make up a small number of ordered categories (such as stages of disease I to IV) should not be presented as continuous variables; it is preferable to give numbers and proportions for each category (see also Box 4). In studies that compare groups, the descriptive characteristics and numbers should be given by group, as in the example above.\nInferential measures such as standard errors and confidence intervals should not be used to describe the variability of characteristics, and significance tests should be avoided in descriptive tables. Also, P values are not an appropriate criterion for selecting which confounders to adjust for in analysis; even small differences in a confounder that has a strong effect on the outcome can be important [144,145].\nIn cohort studies, it may be useful to document how an exposure relates to other characteristics and potential confounders. Authors could present this information in a table with columns for participants in two or more exposure categories, which permits to judge the differences in confounders between these categories.\nIn case-control studies potential confounders cannot be judged by comparing cases and controls. Control persons represent the source population and will usually be different from the cases in many respects. For example, in a study of oral contraceptives and myocardial infarction, a sample of young women with infarction more often had risk factors for that disease, such as high serum cholesterol, smoking and a positive family history, than the control group [146]. This does not influence the assessment of the effect of oral contraceptives, as long as the prescription of oral contraceptives was not guided by the presence of these risk factors—e.g., because the risk factors were only established after the event (see also Box 5). In case-control studies the equivalent of comparing exposed and non-exposed for the presence of potential confounders (as is done in cohorts) can be achieved by exploring the source population of the cases: if the control group is large enough and represents the source population, exposed and unexposed controls can be compared for potential confounders [121,147]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-14a_-2",
    "href": "guidelines/strobe/index.html#sec-14a_-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nTable: Characteristics of the Study Base at Enrolment, Castellana G (Italy) (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t002/(\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-14b_-1",
    "href": "guidelines/strobe/index.html#sec-14b_-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nAs missing data may bias or affect generalisability of results, authors should tell readers amounts of missing data for exposures, potential confounders, and other important characteristics of patients (see also item 12c and Box 6). In a cohort study, authors should report the extent of loss to follow-up (with reasons), since incomplete follow-up may bias findings (see also items 12d and 13) [148]. We advise authors to use their tables and figures to enumerate amounts of missing data."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-14b_-2",
    "href": "guidelines/strobe/index.html#sec-14b_-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nSymptom End Points Used in Survival Analysis (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t003/)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-14c_-1",
    "href": "guidelines/strobe/index.html#sec-14c_-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nReaders need to know the duration and extent of follow-up for the available outcome data. Authors can present a summary of the average follow-up with either the mean or median follow-up time or both. The mean allows a reader to calculate the total number of person-years by multiplying it with the number of study participants. Authors also may present minimum and maximum times or percentiles of the distribution to show readers the spread of follow-up times. They may report total person-years of follow-up or some indication of the proportion of potential data that was captured [148]. All such information may be presented separately for participants in two or more exposure categories. Almost half of 132 articles in cancer journals (mostly cohort studies) did not give any summary of length of follow-up [37]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-14c_-2",
    "href": "guidelines/strobe/index.html#sec-14c_-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nDuring the 4366 person-years of follow-up (median 5.4, maximum 8.3 years), 265 subjects were diagnosed as having dementia, including 202 with Alzheimer’s disease\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-15_outcome_data-1",
    "href": "guidelines/strobe/index.html#sec-15_outcome_data-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nBefore addressing the possible association between exposures (risk factors) and outcomes, authors should report relevant descriptive data. It may be possible and meaningful to present measures of association in the same table that presents the descriptive data (see item 14a). In a cohort study with events as outcomes, report the numbers of events for each outcome of interest. Consider reporting the event rate per person-year of follow-up. If the risk of an event changes over follow-up time, present the numbers and rates of events in appropriate intervals of follow-up or as a Kaplan-Meier life table or plot. It might be preferable to show plots as cumulative incidence that go up from 0% rather than down from 100%, especially if the event rate is lower than, say, 30% [153]. Consider presenting such information separately for participants in different exposure categories of interest. If a cohort study is investigating other time-related outcomes (e.g., quantitative disease markers such as blood pressure), present appropriate summary measures (e.g., means and standard deviations) over time, perhaps in a table or figure.\nFor cross-sectional studies, we recommend presenting the same type of information on prevalent outcome events or summary measures. For case-control studies, the focus will be on reporting exposures separately for cases and controls as frequencies or quantitative summaries [154]. For all designs, it may be helpful also to tabulate continuous outcomes or exposures in categories, even if the data are not analysed as such."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-15_outcome_data-2",
    "href": "guidelines/strobe/index.html#sec-15_outcome_data-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nCohort study: Table: Rates of HIV-1 Seroconversion by Selected Sociodemographic Variables: 1990–1993 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t004/)\n\n\nCase-control study: Table: Exposure among Liver Cirrhosis Cases and Controls (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t006/)\n\n\nCross-sectional study: Table: Prevalence of Current Asthma and Diagnosed Hay Fever by Average Alternaria alternata Antigen Level in the Household (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t007/)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-16a_main_results-1",
    "href": "guidelines/strobe/index.html#sec-16a_main_results-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nIn many situations, authors may present the results of unadjusted or minimally adjusted analyses and those from fully adjusted analyses. We advise giving the unadjusted analyses together with the main data, for example the number of cases and controls that were exposed or not. This allows the reader to understand the data behind the measures of association (see also item 15). For adjusted analyses, report the number of persons in the analysis, as this number may differ because of missing values in covariates (see also item 12c). Estimates should be given with confidence intervals.\nReaders can compare unadjusted measures of association with those adjusted for potential confounders and judge by how much, and in what direction, they changed. Readers may think that ‘adjusted’ results equal the causal part of the measure of association, but adjusted results are not necessarily free of random sampling error, selection bias, information bias, or residual confounding (see Box 5). Thus, great care should be exercised when interpreting adjusted results, as the validity of results often depends crucially on complete knowledge of important confounders, their precise measurement, and appropriate specification in the statistical model (see also item 20) [157,158].\nAuthors should explain all potential confounders considered, and the criteria for excluding or including variables in statistical models. Decisions about excluding or including variables should be guided by knowledge, or explicit assumptions, on causal relations. Inappropriate decisions may introduce bias, for example by including variables that are in the causal pathway between exposure and disease (unless the aim is to asses how much of the effect is carried by the intermediary variable). If the decision to include a variable in the model was based on the change in the estimate, it is important to report what change was considered sufficiently important to justify its inclusion. If a ‘backward deletion’ or ‘forward inclusion’ strategy was used to select confounders, explain that process and give the significance level for rejecting the null hypothesis of no confounding. Of note, we and others do not advise selecting confounders based solely on statistical significance testing [147,159,160].\nRecent studies of the quality of reporting of epidemiological studies found that confidence intervals were reported in most articles [4]. However, few authors explained their choice of confounding variables [4,5]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-16a_main_results-2",
    "href": "guidelines/strobe/index.html#sec-16a_main_results-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nWe initially considered the following variables as potential confounders by Mantel-Haenszel stratified analysis: (…) The variables we included in the final logistic regression models were those (…) that produced a 10% change in the odds ratio after the Mantel-Haenszel adjustment\n\n\nTable: Relative Rates of Rehospitalisation by Treatment in Patients in Community Care after First Hospitalisation due to Schizophrenia and Schizoaffective Disorder (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t008/)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-16b_main_results-1",
    "href": "guidelines/strobe/index.html#sec-16b_main_results-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nCategorizing continuous data has several important implications for analysis (see Box 4) and also affects the presentation of results. In tables, outcomes should be given for each exposure category, for example as counts of persons at risk, person-time at risk, if relevant separately for each group (e.g., cases and controls). Details of the categories used may aid comparison of studies and meta-analysis. If data were grouped using conventional cut-points, such as body mass index thresholds [162], group boundaries (i.e., range of values) can be derived easily, except for the highest and lowest categories. If quantile-derived categories are used, the category boundaries cannot be inferred from the data. As a minimum, authors should report the category boundaries; it is helpful also to report the range of the data and the mean or median values within categories."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-16b_main_results-2",
    "href": "guidelines/strobe/index.html#sec-16b_main_results-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nTable: Polychlorinated Biphenyls in Cord Serum (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t005/)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-16c_main_results-1",
    "href": "guidelines/strobe/index.html#sec-16c_main_results-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nThe results from studies examining the association between an exposure and a disease are commonly reported in relative terms, as ratios of risks, rates or odds (see Box 8). Relative measures capture the strength of the association between an exposure and disease. If the relative risk is a long way from 1 it is less likely that the association is due to confounding [164,165]. Relative effects or associations tend to be more consistent across studies and populations than absolute measures, but what often tends to be the case may be irrelevant in a particular instance. For example, similar relative risks were obtained for the classic cardiovascular risk factors for men living in Northern Ireland, France, the USA and Germany, despite the fact that the underlying risk of coronary heart disease varies substantially between these countries [166,167]. In contrast, in a study of hypertension as a risk factor for cardiovascular disease mortality, the data were more compatible with a constant rate difference than with a constant rate ratio [168].\nWidely used statistical models, including logistic [169] and proportional hazards (Cox) regression [170] are based on ratio measures. In these models, only departures from constancy of ratio effect measures are easily discerned. Nevertheless, measures which assess departures from additivity of risk differences, such as the Relative Excess Risk from Interaction (RERI, see item 12b and Box 8), can be estimated in models based on ratio measures.\nIn many circumstances, the absolute risk associated with an exposure is of greater interest than the relative risk. For example, if the focus is on adverse effects of a drug, one will want to know the number of additional cases per unit time of use (e.g., days, weeks, or years). The example gives the additional number of breast cancer cases per 1000 women who used hormone-replacement therapy for 10 years [163]. Measures such as the attributable risk or population attributable fraction may be useful to gauge how much disease can be prevented if the exposure is eliminated. They should preferably be presented together with a measure of statistical uncertainty (e.g., confidence intervals as in the example). Authors should be aware of the strong assumptions made in this context, including a causal relationship between a risk factor and disease (also see Box 7) [171]. Because of the semantic ambiguity and complexities involved, authors should report in detail what methods were used to calculate attributable risks, ideally giving the formulae used [172].\nA recent survey of abstracts of 222 articles published in leading medical journals found that in 62% of abstracts of randomised trials including a ratio measure absolute risks were given, but only in 21% of abstracts of cohort studies [173]. A free text search of Medline 1966 to 1997 showed that 619 items mentioned attributable risks in the title or abstract, compared to 18,955 using relative risk or odds ratio, for a ratio of 1 to 31 [174]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-16c_main_results-2",
    "href": "guidelines/strobe/index.html#sec-16c_main_results-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\n10 years’ use of HRT [hormone replacement therapy] is estimated to result in five (95% CI 3–7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15–23) additional cancers per 1000 users of oestrogen-progestagen combinations\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-17_other_analyses-1",
    "href": "guidelines/strobe/index.html#sec-17_other_analyses-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nIn addition to the main analysis other analyses are often done in observational studies. They may address specific subgroups, the potential interaction between risk factors, the calculation of attributable risks, or use alternative definitions of study variables in sensitivity analyses.\nThere is debate about the dangers associated with subgroup analyses, and multiplicity of analyses in general [4,104]. In our opinion, there is too great a tendency to look for evidence of subgroup-specific associations, or effect-measure modification, when overall results appear to suggest little or no effect. On the other hand, there is value in exploring whether an overall association appears consistent across several, preferably pre-specified subgroups especially when a study is large enough to have sufficient data in each subgroup. A second area of debate is about interesting subgroups that arose during the data analysis. They might be important findings, but might also arise by chance. Some argue that it is neither possible nor necessary to inform the reader about all subgroup analyses done as future analyses of other data will tell to what extent the early exciting findings stand the test of time [9]. We advise authors to report which analyses were planned, and which were not (see also items 4, 12b and 20). This will allow readers to judge the implications of multiplicity, taking into account the study’s position on the continuum from discovery to verification or refutation.\nA third area of debate is how joint effects and interactions between risk factors should be evaluated: on additive or multiplicative scales, or should the scale be determined by the statistical model that fits best (see also item 12b and Box 8)? A sensible approach is to report the separate effect of each exposure as well as the joint effect—if possible in a table, as in the first example above [183], or in the study by Martinelli et al. [185]. Such a table gives the reader sufficient information to evaluate additive as well as multiplicative interaction (how these calculations are done is shown in Box 8). Confidence intervals for separate and joint effects may help the reader to judge the strength of the data. In addition, confidence intervals around measures of interaction, such as the Relative Excess Risk from Interaction (RERI) relate to tests of interaction or homogeneity tests. One recurrent problem is that authors use comparisons of P-values across subgroups, which lead to erroneous claims about an effect modifier. For instance, a statistically significant association in one category (e.g., men), but not in the other (e.g., women) does not in itself provide evidence of effect modification. Similarly, the confidence intervals for each point estimate are sometimes inappropriately used to infer that there is no interaction when intervals overlap. A more valid inference is achieved by directly evaluating whether the magnitude of an association differs across subgroups.\nSensitivity analyses are helpful to investigate the influence of choices made in the statistical analysis, or to investigate the robustness of the findings to missing data or possible biases (see also item 12b). Judgement is needed regarding the level of reporting of such analyses. If many sensitivity analyses were performed, it may be impractical to present detailed findings for them all. It may sometimes be sufficient to report that sensitivity analyses were carried out and that they were consistent with the main results presented. Detailed presentation is more appropriate if the issue investigated is of major concern, or if effect estimates vary considerably [59,186].\nPocock and colleagues found that 43 out of 73 articles reporting observational studies contained subgroup analyses. The majority claimed differences across groups but only eight articles reported a formal evaluation of interaction (see item 12b) [4]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-17_other_analyses-2",
    "href": "guidelines/strobe/index.html#sec-17_other_analyses-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nAnalysis of Oral Contraceptive Use, Presence of Factor V Leiden Allele, and Risk for Venous Thromboembolism (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t009/)\n\n\nSensitivity of the Rate Ratio for Cardiovascular Outcome to an Unmeasured Confounder (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2020496/table/pmed-0040297-t010/)\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-18_key_results-1",
    "href": "guidelines/strobe/index.html#sec-18_key_results-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nIt is good practice to begin the discussion with a short summary of the main findings of the study. The short summary reminds readers of the main findings and may help them assess whether the subsequent interpretation and implications offered by the authors are supported by the findings."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-18_key_results-2",
    "href": "guidelines/strobe/index.html#sec-18_key_results-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nWe hypothesized that ethnic minority status would be associated with higher levels of cardiovascular disease (CVD) risk factors, but that the associations would be explained substantially by socioeconomic status (SES). Our hypothesis was not confirmed. After adjustment for age and SES, highly significant differences in body mass index, blood pressure, diabetes, and physical inactivity remained between white women and both black and Mexican American women. In addition, we found large differences in CVD risk factors by SES, a finding that illustrates the high-risk status of both ethnic minority women as well as white women with low SES\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-19_limitations-1",
    "href": "guidelines/strobe/index.html#sec-19_limitations-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nThe identification and discussion of the limitations of a study are an essential part of scientific reporting. It is important not only to identify the sources of bias and confounding that could have affected results, but also to discuss the relative importance of different biases, including the likely direction and magnitude of any potential bias (see also item 9 and Box 3).\nAuthors should also discuss any imprecision of the results. Imprecision may arise in connection with several aspects of a study, including the study size (item 10) and the measurement of exposures, confounders and outcomes (item 8). The inability to precisely measure true values of an exposure tends to result in bias towards unity: the less precisely a risk factor is measured, the greater the bias. This effect has been described as ‘attenuation’ [201,202], or more recently as ‘regression dilution bias’ [203]. However, when correlated risk factors are measured with different degrees of imprecision, the adjusted relative risk associated with them can be biased towards or away from unity [204–206].\nWhen discussing limitations, authors may compare the study being presented with other studies in the literature in terms of validity, generalisability and precision. In this approach, each study can be viewed as contribution to the literature, not as a stand-alone basis for inference and action [207]. Surprisingly, the discussion of important limitations of a study is sometimes omitted from published reports. A survey of authors who had published original research articles in The Lancet found that important weaknesses of the study were reported by the investigators in the survey questionnaires, but not in the published article [192]."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-19_limitations-2",
    "href": "guidelines/strobe/index.html#sec-19_limitations-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nSince the prevalence of counseling increases with increasing levels of obesity, our estimates may overestimate the true prevalence. Telephone surveys also may overestimate the true prevalence of counseling. Although persons without telephones have similar levels of overweight as persons with telephones, persons without telephones tend to be less educated, a factor associated with lower levels of counseling in our study. Also, of concern is the potential bias caused by those who refused to participate as well as those who refused to respond to questions about weight. Furthermore, because data were collected cross-sectionally, we cannot infer that counseling preceded a patient’s attempt to lose weight\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-20_interpretation-1",
    "href": "guidelines/strobe/index.html#sec-20_interpretation-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nThe heart of the discussion section is the interpretation of a study’s results. Over-interpretation is common and human: even when we try hard to give an objective assessment, reviewers often rightly point out that we went too far in some respects. When interpreting results, authors should consider the nature of the study on the discovery to verification continuum and potential sources of bias, including loss to follow-up and non-participation (see also items 9, 12 and 19). Due consideration should be given to confounding (item 16a), the results of relevant sensitivity analyses, and to the issue of multiplicity and subgroup analyses (item 17). Authors should also consider residual confounding due to unmeasured variables or imprecise measurement of confounders. For example, socioeconomic status (SES) is associated with many health outcomes and often differs between groups being compared. Variables used to measure SES (income, education, or occupation) are surrogates for other undefined and unmeasured exposures, and the true confounder will by definition be measured with error [208]. Authors should address the real range of uncertainty in estimates, which is larger than the statistical uncertainty reflected in confidence intervals. The latter do not take into account other uncertainties that arise from a study’s design, implementation, and methods of measurement [209].\nTo guide thinking and conclusions about causality, some may find criteria proposed by Bradford Hill in 1965 helpful [164]. How strong is the association with the exposure? Did it precede the onset of disease? Is the association consistently observed in different studies and settings? Is there supporting evidence from experimental studies, including laboratory and animal studies? How specific is the exposure’s putative effect, and is there a dose-response relationship? Is the association biologically plausible? These criteria should not, however, be applied mechanically. For example, some have argued that relative risks below 2 or 3 should be ignored [210,211]. This is a reversal of the point by Cornfield et al. about the strength of large relative risks (see item 12b) [127]. Although a causal effect is more likely with a relative risk of 9, it does not follow that one below 3 is necessarily spurious. For instance, the small increase in the risk of childhood leukaemia after intrauterine irradiation is credible because it concerns an adverse effect of a medical procedure for which no alternative explanations are obvious [212]. Moreover, the carcinogenic effects of radiation are well established. The doubling in the risk of ovarian cancer associated with eating 2 to 4 eggs per week is not immediately credible, since dietary habits are associated with a large number of lifestyle factors as well as SES [213]. In contrast, the credibility of much debated epidemiologic findings of a difference in thrombosis risk between different types of oral contraceptives was greatly enhanced by the differences in coagulation found in a randomised cross-over trial [214]. A discussion of the existing external evidence, from different types of studies, should always be included, but may be particularly important for studies reporting small increases in risk. Further, authors should put their results in context with similar studies and explain how the new study affects the existing body of evidence, ideally by referring to a systematic review."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-20_interpretation-2",
    "href": "guidelines/strobe/index.html#sec-20_interpretation-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nAny explanation for an association between death from myocardial infarction and use of second generation oral contraceptives must be conjectural. There is no published evidence to suggest a direct biologic mechanism, and there are no other epidemiologic studies with relevant results. (…) The increase in absolute risk is very small and probably applies predominantly to smokers. Due to the lack of corroborative evidence, and because the analysis is based on relatively small numbers, more evidence on the subject is needed. We would not recommend any change in prescribing practice on the strength of these results\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-21_generisability-1",
    "href": "guidelines/strobe/index.html#sec-21_generisability-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nGeneralisability, also called external validity or applicability, is the extent to which the results of a study can be applied to other circumstances [216]. There is no external validity per se; the term is meaningful only with regard to clearly specified conditions [217]. Can results be applied to an individual, groups or populations that differ from those enrolled in the study with regard to age, sex, ethnicity, severity of disease, and co-morbid conditions? Are the nature and level of exposures comparable, and the definitions of outcomes relevant to another setting or population? Are data that were collected in longitudinal studies many years ago still relevant today? Are results from health services research in one country applicable to health systems in other countries?\nThe question of whether the results of a study have external validity is often a matter of judgment that depends on the study setting, the characteristics of the participants, the exposures examined, and the outcomes assessed. Thus, it is crucial that authors provide readers with adequate information about the setting and locations, eligibility criteria, the exposures and how they were measured, the definition of outcomes, and the period of recruitment and follow-up. The degree of non-participation and the proportion of unexposed participants in whom the outcome develops are also relevant. Knowledge of the absolute risk and prevalence of the exposure, which will often vary across populations, are helpful when applying results to other settings and populations (see Box 7)."
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-21_generisability-2",
    "href": "guidelines/strobe/index.html#sec-21_generisability-2",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Examples",
    "text": "Examples\n\nHow applicable are our estimates to other HIV-1-infected patients? This is an important question because the accuracy of prognostic models tends to be lower when applied to data other than those used to develop them. We addressed this issue by penalising model complexity, and by choosing models that generalised best to cohorts omitted from the estimation procedure. Our database included patients from many countries from Europe and North America, who were treated in different settings. The range of patients was broad: men and women, from teenagers to elderly people were included, and the major exposure categories were well represented. The severity of immunodeficiency at baseline ranged from not measureable to very severe, and viral load from undetectable to extremely high\n\nBack to top"
  },
  {
    "objectID": "guidelines/strobe/index.html#sec-22_funding-1",
    "href": "guidelines/strobe/index.html#sec-22_funding-1",
    "title": "The STROBE guideline for writing a observational study.",
    "section": "Read More",
    "text": "Read More\nSome journals require authors to disclose the presence or absence of financial and other conflicts of interest [100,218]. Several investigations show strong associations between the source of funding and the conclusions of research articles [219–222]. The conclusions in randomised trials recommended the experimental drug as the drug of choice much more often (odds ratio 5.3) if the trial was funded by for-profit organisations, even after adjustment for the effect size [223]. Other studies document the influence of the tobacco and telecommunication industries on the research they funded [224–227]. There are also examples of undue influence when the sponsor is governmental or a non-profit organisation.\nAuthors or funders may have conflicts of interest that influence any of the following: the design of the study [228]; choice of exposures [228,229], outcomes [230], statistical methods [231], and selective publication of outcomes [230] and studies [232]. Consequently, the role of the funders should be described in detail: in what part of the study they took direct responsibility (e.g., design, data collection, analysis, drafting of manuscript, decision to publish) [100]. Other sources of undue influence include employers (e.g., university administrators for academic researchers and government supervisors, especially political appointees, for government researchers), advisory committees, litigants, and special interest groups."
  },
  {
    "objectID": "guidelines/consort/discussion/1a_title.html",
    "href": "guidelines/consort/discussion/1a_title.html",
    "title": "Discussion for CONSORT item: 1a. Title",
    "section": "",
    "text": "Do you have questions or feedback about this SRQR reporting guideline item? Do you want to ask other researchers for help? Or give feedback to the guideline developers?\nLeave a comment below! This website uses Giscus, an open source commenting system powered by GitHub Discussions. To use it, you will need an account with GitHub, the world leading repository platform used by academics globally."
  },
  {
    "objectID": "guidelines/consort/discussion/1a_title.html#discussion-for-consort-item-1a.-title",
    "href": "guidelines/consort/discussion/1a_title.html#discussion-for-consort-item-1a.-title",
    "title": "Discussion for CONSORT item: 1a. Title",
    "section": "",
    "text": "Do you have questions or feedback about this SRQR reporting guideline item? Do you want to ask other researchers for help? Or give feedback to the guideline developers?\nLeave a comment below! This website uses Giscus, an open source commenting system powered by GitHub Discussions. To use it, you will need an account with GitHub, the world leading repository platform used by academics globally."
  },
  {
    "objectID": "guidelines/consort/items/1a_title.html",
    "href": "guidelines/consort/items/1a_title.html",
    "title": "1a. Title",
    "section": "",
    "text": "Identification as a randomized trial in the title.",
    "crumbs": [
      "Full guidance",
      "Title and Abstract",
      "1a. Title"
    ]
  },
  {
    "objectID": "guidelines/consort/items/1a_title.html#read-more",
    "href": "guidelines/consort/items/1a_title.html#read-more",
    "title": "1a. Title",
    "section": "Read More",
    "text": "Read More\nThe ability to identify a report of a randomised trial in an electronic database depends to a large extent on how it was indexed. Indexers may not classify a report as a randomised trial if the authors do not explicitly report this information.64 To help ensure that a study is appropriately indexed and easily identified, authors should use the word “randomised” in the title to indicate that the participants were randomly assigned to their comparison groups",
    "crumbs": [
      "Full guidance",
      "Title and Abstract",
      "1a. Title"
    ]
  },
  {
    "objectID": "guidelines/consort/items/1a_title.html#examples",
    "href": "guidelines/consort/items/1a_title.html#examples",
    "title": "1a. Title",
    "section": "Examples",
    "text": "Examples\n\nSmoking reduction with oral nicotine inhalers: double blind, randomised clinical trial of efficacy and safety",
    "crumbs": [
      "Full guidance",
      "Title and Abstract",
      "1a. Title"
    ]
  },
  {
    "objectID": "guidelines/consort/items/1a_title.html#discuss-this-item",
    "href": "guidelines/consort/items/1a_title.html#discuss-this-item",
    "title": "1a. Title",
    "section": "Discuss this item",
    "text": "Discuss this item\nVisit this items’ discussion page to ask questions and give feedback.",
    "crumbs": [
      "Full guidance",
      "Title and Abstract",
      "1a. Title"
    ]
  }
]